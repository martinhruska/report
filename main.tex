\documentclass[12pt,a4paper]{report}
\usepackage{graphicx}
\usepackage[usenames,dvipsnames]{color}

%\let\iint\undefined 
%\let\iiint\undefined 
%\let\iiiint\undefined 
%\let\idotsint\undefined

%\usepackage{amsmath} 
%\usepackage{amsxtra} 
\usepackage{amssymb}
\usepackage{colortbl}
%\usepackage{mathabx}
\usepackage{mathtools}
\usepackage{stmaryrd}
%\usepackage{textcomp}
%\usepackage{subcaption}

%\usepackage{latexsym}
%\usepackage{pslatex}
\usepackage{times}
%\usepackage{epsfig}
%\usepackage{wrapfig}
%\usepackage{graphics}
%\usepackage{enumerate}
%\usepackage{cancel}
\usepackage{paralist}

%\usepackage{listings}
\usepackage[utf8]{inputenc}
\usepackage{algorithm}
%\usepackage{algorithmicx}
%\usepackage[noend]{algpseudocode}
\let\Asterisk\undefined
\usepackage[draft]{commenting}
%\usepackage{fancyvrb}
%\usepackage{lscape}
%\usepackage{adjustbox}
%\usepackage{tabularx}

\usepackage{hyperref}
% \usepackage{pgffor}
% \usepackage[version=latest]{pgf}
% \usepackage{tikz}
% \usetikzlibrary{arrows,shapes,decorations,automata,positioning,backgrounds,shapes,fit,patterns,calc}

\usepackage[inline]{enumitem}

\newcommand\sepimp{\mathrel{-\mkern-6mu*}}
\newtheorem{lemma}{Lemma}[section]
\newtheorem{example}{Example}[section]

%\include{macrosMartin}

\hyphenation{ana-ly-sis}
\include{macros}

\begin{document}
\begin{titlepage}
	\centering
	{\scshape\LARGE Brno University of Technology \par}
	{\scshape\Large Faculty of Information Technology \par}
	\vspace{5cm}
	{\scshape\Large Report on PhD Thesis:\par}
	\vspace{1cm}
	{\huge\bfseries Automated Reasoning about Programs with Dynamic Data Structures\par}
	\vspace{5cm}
	{\Large\itshape Martin Hruška\par}
	{\Large ihruska@fit.vutbr.cz\par}
	\vfill
	supervised by\par
	Prof. Ing. Tomáš \textsc{Vojnar}, Ph.D.,\par
	Mgr. Lukáš \textsc{Holík}, Ph.D.\par

	\vfill

% Bottom of the page
	{\large \today\par}
\end{titlepage}


\clearpage
\vspace*{\fill}
\thispagestyle{empty} % optional -- suppress showing of page number
\begin{quotation}
	{\em % optional -- to switch to emphasis (italics) mode
Experience without theory is blind, but theory without experience is mere intellectual play
	}

\medskip
\raggedleft
Immanuel Kant 
\end{quotation}
\vspace*{\fill}



\begin{abstract}
The Ph.D. thesis deals with \emph{shape analysis}\,---\,a field of static analysis
aimed to reasoning about programs with dynamic data structures.
The goal of this thesis is to introduce new techniques for shape analysis
making it possible to verify more complex software systems.
It consists of improving the existing methods for shape analysis based on automata
(such as refinement for abstraction over forest automata or enhancing the algorithms
for manipulation with the various automata used in shape analysis)
and proposing a new formalism capable of analysis of programs on which the current analyses fail.
The report also contains a discussion of a related work and plans of the future work.
\end{abstract}

\cleardoublepage
\pagenumbering{gobble}
\tableofcontents
\cleardoublepage

\pagenumbering{arabic}
\chapter{Introduction}

One of eternal quests of computer science is to achieve
as high quality of software as possible.
This goal can be found in different parts of the field\,---\,
from critical software in e.g. aircraft industry where even formal correctness
is desired to enterprise applications where a hunt for bugs is driven by a desire
to provide the best user experience.

The various needs of guaranteeing software quality lead to development of
different techniques addressing the problem.
Some of the approaches are formal and provide high guarantees (such as proving correctness
of a program using a proof assistant or programming in a language
with an expressive and safe type system).
However, they require highly specialized developers and are often not fully automatic.
Both of these facts lead to higher costs of such techniques.
Then there are techniques with formal bases and higher or even full automation.
They provide some degree of formal guarantees of code quality and can be run by a developer
without a special effort.
As a trade-off, they suffer with problems in scaling to large software systems and often
produce false positives, i.e. detect an error which is not in fact in the analysed system.
This class of methods includes different model checking and static analysis techniques.
On the other end of scale, there are light-weight testing methods which can be fully
automatized, scale well and can often be used in development by users without a deep expertise
(such as a Ph.D. in formal methods).
However, they do not provide the reliable guarantees of an achieved quality.

This thesis approaches software quality from a perspective of formal verification belonging to
the second class of the mentioned approaches.
I.e., the studied methods have a formal basis and can provide guarantees about correctness of analysed programs.
Particularly, we aim to static analysis which works directly with a source
code of an analysed system.
Since no model of a system is needed, it is easier to automatize verification.
Static analysis algorithms also does not rely on help from a user as theorem
proving which sometimes needs an advice to choose the right proof rule.
Even if the methods are not fully automatic, a user can often easily parametrize
a tool manually to achieve the best possible results of verification.

In static analysis, it is common that the particular methods focus on particular
properties of programs which is also the case of this work. We focus on so called
\emph{shape analysis} which deals with programs manipulating dynamic data structures (allocated on the heap)
and verifies memory-manipulation-related properties, such as absence of memory leaks, invalid dereferences,
or invalid free operations.
Programs with manual dynamic memory management are highly used in areas where efficiency is needed,
such as the kernel of an operating system.

Dynamic data structures may have an unbounded number of possible shapes.
E.g., consider a number of packets waiting to be processed in a queue (implemented
as a linked list) of a network router with an arbitrary hardware.
We do not know in advance how long the list can be.
The unboudness makes the analysis difficult since we need to model and reason about systems with
infinite state spaces.

We address the mentioned challenges (formal correctness, automation and infinite state spaces)
in shape analysis using automata theory.
We build on the tree automata theory which is used to represent data structures
allocated on the heap.
Since the heap structures allocated on the heap can be viewed as graphs decomposable
to a set of trees, we can represent them by languages of tree automata.
In particular, we continue in a research on forest automata \cite{boxes13, forester12}
which are basically tuples of tree automata (will be formally described in Chapter \ref{ch:vmcai}).
Forest automata accept tuples of (interconnected) trees as members of their languages.
When the trees in a tuple are connected, we obtain one of the heap graph represented
by a forest automaton.

The automata based approaches combines expressiveness, flexibility, and efficiency.
The generality of automata theory leads to expressiveness strong enough to represent most of the practically
used data structures. Moreover, since the automata theory is well-established, we can build on the existing
results about expressiveness and complexity of various automata variations.
A reasoning about infinite systems is possible thanks to the abstraction techniques for automata.
The flexibility comes also from the used automata abstractions techniques that are not in advance fixed for a particular
class of data structures.
The abstraction can learn a suitable way of representing a given structure automatically for many useful cases.
The efficiency comes from many algorithmic heuristics developed to deal with the state explosion
in the needed operations over automata.

The goals of this thesis are to further improve the automata-theoretical approach to shape analysis
by
\begin{enumerate*}[label=(\alph*)]
	\item improving the abstraction (and refinement) techniques to bring a better compromise between precision and efficiency,
	\item designing a new kind of automata with a higher expressivity but also with decidable important
		operations such as language inclusion, and
	\item to improve the efficiency of the existing algorithms for tree automata.
\end{enumerate*}

The outline of this document is as follows. Chapter \ref{ch:state-of-the-art} provides a summary of
existing methods for shape analysis.
Chapter \ref{ch:goals} summarizes the goals of the proposed thesis.
Chapter \ref{ch:vmcai} describes our already achieved results on abstraction refinement for forest automata.
% and the Chapter \ref{ch:svcomp} provides an overview of forest automata implementation in the Forester tool.

\chapter{State of the Art}
\label{ch:state-of-the-art}
This section provides a summary of the state-of-the-art methods for shape analysis.
First, an overview of the chosen methods for analysis of programs with
dynamic data structures is given.
We will describe the most successful methods and those based on automata.
Then refinement techniques for abstraction over various formalisms are summarized
followed by a brief description of efficient algorithms for automata manipulation.
Finally, an existing work on automata for graph languages is presented.

\section{Shape Analysis}
\emph{Shape analysis} deals with analysis of shapes allocated on the heap by a program.
Many different approaches to shape analysis have been proposed, using various
underlying formalisms, such as logics
\cite{pale97,Sagiv02,InvaderCAV08,thor10,dragoi:atva12,sleek13}, automata
\cite{bhrv06b,deg06,forester12,boxes13,lists-counters}, graphs with summary nodes and edges
\cite{sas07:chang_rival_necula,dudka13}, or graph grammars \cite{juggrnaut10}.
% Apart from the underlying formalisms, the approaches differ in their degree of
% automation, in the heap structures they can handle, and in their scalability.

In the following text, we abstract data structures allocated on heap to graphs (so called \emph{heap graphs}
or \emph{heap shapes}).
An allocated memory heap cell corresponds to a node of graph and a pointer pointing from one memory cell
to another is represented by the edges between nodes.
The selectors are represented by the labels of the edges.
Formally, a heap graph $G$ is a tuple $(V,E,\alpha)$ where $V$ is a set of nodes, $E \subseteq V \times V$ is
a set of edges, $\alpha: E \rightarrow \selectors$ is a labelling function, and $\selectors$ is a set
of selector names.

	  Shape analysis heavily relies on the formal model used to represent the set of the heap shapes
	  reachable in the program.
	  The requirements on the model are the following:
	  \begin{enumerate*}[label=(\alph*)]
	  	\item genericity and expressivity\,---\,the more general the model will be the more data structures can be
	  		represented by it, and more programs can be analyzed,
	  	\item automation\,---\,the model can be derived from a program automatically and have decidable
			properties important for reasoning about the program,
	  	\item efficiency and scalability\,---\,there exist efficient algorithms manipulating the model
			even when it is applied to big systems.
	  \end{enumerate*}

	  \subsection{Three-valued Predicate Logic with Transitive Closure}
	  \label{subsec:tvl}
	  The approach of \cite{Sagiv02} uses predicates to express relations between nodes of heap graphs.
	  Moreover, it introduces the third logical value (\emph{unknown}) to the standard
	  boolean values \emph{true, false}. The \emph{unknown} value is used when
	  more items from a given universe may but need not to be in a relation.
	  This is needed when an abstraction (merging some nodes) is performed. E.g., consider
	  an abstraction $\alpha: V \rightarrow V$, where $V$ is a set of nodes
	  of heap graphs, and the predicate $\emph{NEXT}: V \times V\rightarrow\{\emph{true}, \emph{false}, \emph{unknown}\}$.
	  Then when $\alpha(u) = s$ and $\alpha(v) = s$, where $s$ is a so called summary node,
	  and there exists $w \in V$ such that $\emph{NEXT}(u,w) = \emph{true} \wedge
	  \emph{NEXT}(v,w) = \emph{false}$, then $\emph{NEXT}(s,w) = \emph{unknown}$.

	  The work of \cite{Sagiv02} that build the TVLA shape analyser on the top of 3-valued
	  predicate logic with transitive closure was one of the first works on shape analysis.
	  The framework is general, it can found some basic predicates describing shapes in the analysed
	  program automatically but it needs to be parametrized manually by predicates to
	  represent more complex data structures.
	  The precision of the used abstraction by refinement was addressed in \cite{cav05, beyer:lazy_shape_analysis}.
	  Scalability of the method has not been studied.

	  \subsection{Separation Logic}

	  \emph{Separation logic} was first introduced by Reynolds \cite{reynolds02} as an extension
	  of \emph{Hoare logic} for reasoning about programs manipulating dynamic data structures.
	  Hoare logic builds on so-called \emph{Hoare triple}. A triple has form $\{P\}C\{Q\}$ where
	  $P,Q$ are assertions in predicate logic and $C$ is a command in an imperative programming language.
	  When $P$ assertion is satisfied before an execution of $C$ then the $Q$ assertion should hold
	  when $C$ terminates.
	  Another possible formulation is that predicates from the set $P$ are transformed to the set $Q$
	  with respect to semantics of $C$.

	  While the assertions in Hoare logic consist of standard connectives and symbols of predicate logic,
	  separation logic extends the framework with several new ones: $emp$ (representing
	  the empty heap), $P*Q$ (saying that the heap can be split to two separated parts where one satisfies $P$ and the second $Q$),
	  $e \mapsto e'$ (an address defined by the expression $e$ is mapped to a value defined
	  by the expression $e'$, and the rest of the heap is empty, i.e. $*emp$ is implicit),
	  and $P\sepimp Q$ (states that a heap $h'$ satisfying the assertion $P$ will, after union with some heap $h$,
	  satisfy the assertion $Q$).

	  An interest in separation logic has started raising with an introduction of the automated,
	  abstract-interpretation-based approaches associated with Space Invader \cite{InvaderCAV08}.
	  Separation logic has also been extended to a concurrent version \cite{brookes16}.
	  The scalability of the approach based on separation logic was significantly improved by bi-abduction \cite{popl09}.
	  Further, the second-order bi-abduction provided ability to learn the new predicates and so made possible analysis
	  of more complex data structures such as skiplists \cite{cav14}.
	  The principles similar to second-ordered bi-abduction enabling analysis of complex data structures
	  were used in \cite{pldi07}.
	  The main downside of the bi-abduction based methods is inability to provide a counterexample breaking
	  the given specification.
	  The separation-logic-based approaches also suffer from the need to manually provide inductive predicates
	  describing the heaps shapes (even for some list structures).

	  Separation logic has found its way to practice which is demonstrated by its application
	  in Facebook \cite{www:fbinfer}.

	  \subsection{Symbolic Memory Graphs}

	  \emph{Symbolic Memory Graphs (SMG)} \cite{dudka13} were designed as
	  an abstract domain for the framework of abstract interpretation \cite{cousot:popl77}.
	  They model a state of heap precisely but can perform \emph{widening} by introducing
	  summary nodes in the form of singly/doubly-linked lists nodes to
	  accelerate analysis and enable representation of infinite state spaces.
	  Since the representation is quite straightforward it is easy to model
	  semantics of the concrete program operations in the abstract domain.
	  These practical advantages are confirmed by the repeated wins of the tool in the competition on software verification SV-COMP \cite{www:svcomp}.
	  The formalism was designed mainly for list structures aiming at verification
	  of system level programs (e.g. Linux kernel) using such structures.

	  Therefore it can also handle low level memory operations with byte precision \cite{dudka13}.
	  However, the domain has not been yet generalized to the tree structures.
	  The scalability of the method has not been studied yet and but the principles of bi-abduction
	  should be applicable to the domain just as for the separation logic-based methods.

	  \subsection{Abstract Regular Model Checking}
	  \label{subsection:armc}
	  The \emph{abstract regular model checking} \cite{artmc12} is an automata based method for verification of parametrized and infinite state systems.
	  It employs automata over words and trees to represent the reachable configurations of system being verified
	  and a regular transition relation (represented by transducer or operations over automata) to model the semantics of an analysed system.
	  An (e.g., height or predicate language) abstraction is used to
	  overapproximate the set of reachable configurations.
	  The counterexample-guided refinement is applied to
	  refine the abstraction and to validate the found counterexamples when needed.

	  The verification procedure starts with an automaton representing
	  initial configurations of an analysed system.
	  An abstraction is applied to the automaton followed by an application
	  of a transition in each step of the verification procedure.
	  An intersection of the automaton representing so far computed reachable configurations with an automaton representing
	  the bad configurations of the system is also done in each step.
	  When the intersection is empty, the verification procedure continues
	  until a fixpoint is reached (the set of system configurations represented by an automaton
	  is not enlarged after the application of a transition relation).
	  When the intersection is not empty, a backward run is started to validate the counterexample.
	  If the counterexample is not real, then the abstraction is refined to avoid reaching
	  the counterexample again, and the verification procedure is restarted.
	  Otherwise the real counterexample is reported to a user.

	  Abstract regular model checking is a general verification method was applied to various kinds of systems
	  including pointer programs \cite{sas06, cav11, boxes13} where automata are used as a domain
	  for representation of the allocated data structures on the heap.
	  In \cite{sas06}, the whole heap is encoded in one tree automaton and semantics of
	  programs is represented by a tree transducer.
	  The approach was able to verify tree structures but since it encodes the whole
	  heap in one automaton, even a small change in one part of a heap may
	  be propagated over the whole model which negatively effects the scalability of the method.
	  The scalability problem was improved in \cite{cav11} where the heap is represented by a tuple of 
	  tree automata, so called forest automata, which localize a change in one part of heap
	  to a change in a particular tree automaton.
	  The approach needed forest automata representing the repeating sub-graphs of a heap
	  to be provided manually.
	  This was solved by \cite{boxes13} where the shape analysis based on forest automata became
	  fully automated and was able to verify structures such as skiplists.

	  The approach was applied to verification of the C programs with dynamic data structures in
	  the work on forest automata-based shape analysis \cite{forester12}.
	  The \forester{} tool implementing the methods is able to verify complex data structures
	  such as various tree and skiplists of the second and third level \cite{boxes13, holik:2017} which
	  are not analysable by any other tool fully automatically.

	  \subsection{Bounded Model Checking}

	  So far, we introduced domains for representation of shapes allocated on the heap and
	  assumed that a used verification procedure will be sound.
	  However, when the requirement on soundness is relaxed we will obtain a bug hunting method
	  still able to detect many errors in program.
	  One of such methods is \emph{bounded model checking (BMC)} which achieved many achievements
	  in the various editions of the SV-COMP competition \cite{www:svcomp}.

	  An exploration of state space is limited up to some bound in BMC.
	  The bound can be given on a number of interleavings in a parallel program,
	  on a number of the loop unfoldings, or on the size of the memory.
	  
	  BMC systematically explores the state space of (a model of) the analysed systems up
	  to a given bound and checks whether the given specification holds in each possible state.
	  From the perspective of shape analysis it means that the methods explores which shape
	  may be possibly allocated on the heap in a given state of the program
	  and checks whether it does not lead to a memory manipulation related error.
	  
	  A model of the analysed system can be automatically derived from an analysed program.
	  Therefore the approach may be fully automated.
	  It can be also easily combined with other domains of interest in program analysis, e.g., interval analysis.
	  It is also general and scales to large software systems.
	  On the other hand, because the approach is unsound it can only find bugs
	  but it can not prove a program to be correct.
	  There are attempts to get over this bottleneck by \emph{k-induction} but they are still not mature
	  as the original bounded approach.

	  \section{Counterexample Validation and Automatic Refinement of Abstraction for Shape Analysis}

	  As noted in the recent work \cite{splinter15}, a common weakness of the
	  current approaches to shape analysis is a lack of proper support for checking
	  spuriousness of counterexample traces, possibly followed by automated refinement
	  of the employed abstraction. This is one of the problems we tackle in this work.
	  Below, we characterize previous attempts on the problem and compare our
	  approach with them.

	  A well-known approach to refinement of abstraction is the \emph{counterexample-guided
	  refinement (CEGAR)} principle \cite{CEGAR} which works as follows:
	  \begin{enumerate}
		\item Set a default (overapproximating) abstraction.
		\item Perform an analysis of the given program.
		\item If a counterexample is found:
		\begin{enumerate}
			\item start a validation of the counterexample,
			\item if it is valid, report an error,
			\item otherwise refine the abstraction and go to Point $2$.
		\end{enumerate}
		\item If no counterexample is found, report the program as correct.
	  \end{enumerate}
	  CEGAR has been quite well elaborated in the context of software verification.
	  In the following text, we discuss the application of CEGAR in the different
	  approaches to shape analysis.

	  As we briefly mentioned in Section \ref{subsec:tvl},
	  the work \cite{beyer:lazy_shape_analysis} adds a CEGAR loop on top of the TVLA
	  analyzer \cite{Sagiv02}, which is based on \emph{3-valued predicate logic with
	  transitive closure}. The refinement is, however, restricted to adding more
	  pointer variables and/or data fields of allocated memory cells to be tracked
	  only (together with combining the ana\-ly\-sis with classic predicate analysis on
	  data values). The analysis assumes the other necessary heap predicates (i.e.,
	  the so-called core and instrumentation relations in terms of \cite{Sagiv02}) to
	  be fixed in advance and not refined.
	  The work \cite{Loginov:AbstrRefViaInductLearning:05} also builds on TVLA but goes
	  further by learning more complex instrumentation relations using
	  inductive logic programming. The core relations are still fixed in
	  % further by allowing more complex instrumentation relations to be learnt using
	  % inductive logic programming. The core relations are, however, still fixed in
	  advance though. Moreover, the approach of
	  \cite{Loginov:AbstrRefViaInductLearning:05} is not CEGAR-based---it refines the
	  % abstraction whenever it hits a~possible counterexample trace in whose analysis
	  abstraction whenever it hits a~possible counterexample in which
	  some loss of precision happened, regardless of whether the counterexample is
	  real or not.

	  In \cite{podelski:popl10}, a CEGAR-based approach was proposed for automated
	  refinement of the so-called \emph{Boolean heap abstraction} using disjunctions
	  of universally quantified Boolean combinations of first-order predicates with
	  free variables and transitive closure.
	  %
	  % The work uses CEGAR to both add new predicates and to refine the abstract post
	  % operator. 
	  %
	  The approach assumes the analyzed programs to be annotated by
	  procedure contracts and representation invariants of data structures. New
	  predicates are inferred using finite-trace weakest preconditions on the
	  annotations, and hence new predicates with reachability constraints can only be
	  inferred via additional heuristic widening on the inferred predicates. Moreover,
	  the approach is not appropriate for handling nested data structures, such as
	  lists of lists, requiring nested reachability predicates.

	  In the context of approaches based on \emph{separation logic}, several attempts
	  to provide counterexample validation and automated abstraction refinement have
	  appeared. In \cite{slayer12}, the \textsc{SLAyer} analyzer was extended by a method to
	  check spuriousness of counterexample traces via bounded model checking and SMT.
	  The approach may, however, fail in recognizing that a given
	  trace represents a real counterexample. Moreover, the associated refinement can
	  only add more predicates to be tracked from a pre-defined set of such
	  predicates.
	  
	  In \cite{splinter15}, another counterexample analysis for the
	  context of separation logic was proposed within a computation loop based on the
	  Impact algorithm \cite{impact06}. The approach uses bounded backwards abduction
	  to derive so-called spatial interpolants and to distinguish between real and
	  spurious counterexample traces. It allows for refinement of the predicates used
	  but only by extending them by data-related properties. The basic predicates
	  describing heap shapes are provided in advance and fixed.
	  
	  Another work based on backwards abduction is \cite{botincan15}. The work assumes working with a
	  parametrized family of predicates, and the refinement is based on refining the
	  parameter. Three concrete families of this kind are provided, namely,
	  singly-linked lists in which one can remember bigger and bigger multisets of
	  chosen data values, remember nodes with certain addresses, or track ordering
	  properties. The basic heap predicates are again fixed. The approach does not
	  guarantee recognition of spurious and real counterexamples nor progress of the
	  refinement.


	\section{Efficient Algorithms for Automata}

	So far described methods for shape analysis based on automata theory heavily
	rely on the efficiency of operations used for automata manipulation.
	Unlike in the other fields of computer science, the formal verification methods
	work mainly with nondeterministic automata which provide more concise representation
	of the analysed/verified systems.
	A naive implementation of the crucial operations such language inclusion or equivalence checking
	may lead to the explicit determinisation of an automaton causing an exponential
	blow up of the number of the automaton states.
	Particularly, language inclusion checking is an EXPTIME-complete operation
	thus it is not possible to implement a generally efficient algorithm.
	The various heuristics preventing the state explosion during language inclusion were introduced,
	either based on so-called antichains \cite{ac:2006}, their combination with the simulation
	relation \cite{tacas10}, or bisimulation up-to congruence \cite{bonchi2013}.
	When building so-called product automaton from the automata under inclusion checking
	all of the mentioned techniques do not continue from some product states
	which are not needed to be further explored to confirm or disprove that inclusion holds.
	The approach based on antichains exists for word and tree automata \cite{tacas10} but the one based
	on bisimulation up-to congruence is currently available only for classical word automata.

	Another important factor in verification is the size of an automaton.
	It is desirable to work with a minimal automaton to maximize efficiency
	of the verification procedure.
	Unfortunately, a textbook approach consists of determinisation of
	automaton followed by minimization based on Myhill-Nerode theorem.
	Therefore the simulation relation-based techniques are used for reduction
	of automata states.
	It relies on computation of simulation relation over the states of an automaton
	and then pruning out the states which are simulated by another states.
	The simulation relation can be computed in polynomial time \cite{ilie:nfa, focs95, tacas10}
	for word and tree automata.
	It basically says that if one state is simulated by another state then all string (or trees)
	accepted from the first state can be also accepted form the second state.
	The simulation relation is weaker than the classical language equivalence relation (determining
	equivalence classes of the automata states) thus the reduction based on simulation does not yield
	the minimal automaton.

	The mentioned heuristics are used in the tool Forester implementing forest automata-based shape analysis.
	They significantly help in dealing with the state explosion and so contributed to verification of
	complex data structures such as skip-lists of the second and third level which Forester verified
	as the first tool fully automatically \cite{boxes13}.

	Therefore enhancing the existing heuristics for operations such language inclusion checking and
	developing new one can also contribute to the main goal of the proposed thesis\,---\,improvement
	of the state-of-the-art in shape analysis.

	\section{Work on Graph Automata}

	The generality of a verification method for shape analysis crucially depends on the choice
	of the underlying formalism enabling representation of various heap graphs.
	Moreover, some data structures are defined with special relations
	between nodes or sets of nodes (e.g., red-black trees have red and black nodes with
	the special rules how they can alternate).
	Therefore the formalism should make it possible to represent of these such relations over graphs.

	In the field of formal logic, a natural choice is monadic second order logic on graphs.
	It allows one to quantify over sets of nodes of graphs.
	Unfortunately, the logic is undecidable.
	This implies that automata accepting such graphs would have undecidable
	crucial properties, e.g., emptiness of the automata language.
	This is exactly what happens in works by \cite{thomas91, reiter15} where the designed automata
	suffer from the undecidability of some properties.

	The undecidability does not necessarily imply that formalism is not usable (since sufficient
	heuristics may exists) but it is better to target decidability, or at least a formalism
	allowing for a design of efficient algorithmic heuristics).

	When accepting a graph, an automaton needs to remember which nodes have already been
	processed and which will be processed further.
	This is a difference compared to the classical word or tree automata where an automaton runs over
	a given input in a particular direction.
	Contrarily, remembering the so far processed parts of the graphs is more complicated for graph automata.
	In \cite{thomas91}, the path through a processed graph is encoded in symbols.
	In \cite{reiter15}, there is a special automaton for each node of the graph, the automata
	communicate in rounds and the computation continues until all automata reach their stable state.

	However, when the domain is restricted to a special class of graphs, it is possible to design
	automata with much more useful properties.
	It has been shown~by Courcelle \cite{courcelle12} that when we restrict MSO to graphs 
	with bounded, tree width it is possible to decide satisfiability of MSO formulas.
	A decision procedure is then implemented by encoding the formula to a tree automaton
	and checking its emptiness.
	Unfortunately, the tree automaton has an exponential number of states
	compared to the size of the formula which makes the manipulation with it inefficient.

	Another approach to the definition of graph automata is from an algebraic point of view.
	In the work \cite{blume:2012}, the automata were defined using concepts
	of \emph{cospans} from category theory.
	Intuitively, the automata have as symbols the basic graph operations which can create
	an arbitrary graph with a bounded tree width.
	Such a definition implies that word and graph automata are basically the same
	because the graph operations can be viewed just as standard letters from an alphabet of word automata.
	Then a word automaton accepts a word consisting of letters mapped to the graph operations.
	When the operations are concatenated, we obtain the encoded graph.
	However, the authors have not found an efficient automatic derivation of their model
	from a system description.

	Grammars are a standard counterpart to automata in the formal language theory.
	For instance, context-free grammars characterize the class of context-free languages just
	as pushdown automata.
	The paper \cite{brandenburg05} explores the relation between automata working over
	graphs and graph grammars and shows that they describe the same class of graph languages as
	the NCE graph grammars.
	
	The natural comparison of graph grammars is also to the separation logic which was originally designed
	for reasoning about programs with dynamic data structures.
	The relation has been shown in Jansen et. all \cite{matheja2015}.
	They show that so-called \emph{tree-like separation logic} can describe the same graphs
	as those that can be generated by the so-called \emph{tree-like grammars (TLG)}.
	Both formalisms are meant to describe tree-like data structures (i.e. data structures
	decomposable to trees).
	Further, a TLG formula can be transformed to the $MSO_2$ logic which is a variant of MSO
	on graphs where the quantification is allowed not only over sets of nodes but also
	over edges.

	Both of the works comparing graph automata to grammars and separation logic
	explore the expressive power of the automata and their relation to the other formalisms
	but do not concern efficient algorithms and their properties.
	Hence, they are not really suitable for applications in shape analysis.

	Graph automata on graphs with bounded tree width can be applied for shape analysis
	indirectly as a decision procedure for separation logic.
	This is illustrated by \cite{iosif2013} where a variation of automata
	accepting graphs with bounded tree width are used to encode graphs represented
	by a fragment of separation logic.

	The notion of graph automata on graphs with bounded tree width has also been used
	for proving properties of other abstract machines.
	An example is emptiness of automata with auxiliary storage in \cite{popl11}.

\chapter{Goals of the Thesis}
\label{ch:goals}
	The main goal of this thesis is to improve the state of the art of shape analysis.
	Moreover, some of the proposed methods that we intend to develop to achieve this goal
	may yield new contributions to other fields than shape analysis as well.
	The following section summarizes how we want to improve the current state of shape analysis.

	Currently, we see three main sub-goals of the main goal.
	Each of sub-goals should be fulfilled during the work on the thesis, however,
	the directions and the goals of the research may change to some degree according
	to the actual development in the field.

	\section{Refinement of Abstraction over Forest Automata}
	Forest automata are used for representing sets of (certain class of) graphs
	using their tree decomposition.
	A formal description of forest automata will be provided in Chapter \ref{ch:vmcai}.
	An abstraction based on abstract regular model checking over forest automata
	is performed during the verification procedure to overapproximate the set of reachable
	heap configurations.
	The abstraction also accelerates the verification procedure.
	On the other hand, the overapproximation may lead to the spurious counterexamples,
	i.e., counterexamples not presented in the system under verification.

	Reporting bugs found in a program in a reliable way is possible only when the counterexample is validated.
	Therefore one of the sub-goals of the thesis is to enable a program to be executed backwards
	(without abstraction) over the possible counterexample to distinguish between real
	and spurious counterexamples.
	Once a found counterexample is spurious, it is necessary to refine the abstraction
	(i.e. to make it more precise) and restart the analysis again.
	A lack of refinement causes inability to analyse all programs where a spurious counterexample is detected
	using a default abstraction.
	Therefore another sub-goal of this thesis is to design a refinement of the abstraction
	used in forest-automata-based shape	analysis.

	In fact, this sub-goal has already been fulfilled and published in \cite{holik:2017}
	and will be described deeply in Chapter \ref{ch:vmcai}.
	The approach is based on CEGAR \cite{CEGAR} and is inspired by the application of the CEGAR to ARTMC.
	
	As follows from the previous text, this approach enabled a reliable reporting of the found bugs
	to a user for forest automata based shape analysis.
	It also made possible to verify data structures with more sophisticated properties (based on
	relations between the nodes) requiring a more precise abstraction to capture the property.

	\section{Efficient Algorithms for Tree Automata}
	\label{section:autoalgs}
	Although we want to design a new kind of automata as a part of this work,
	many existing approaches (such as mentioned abstract regular tree model checking)
	relies on tree (or word) automata.
	Therefore efficient algorithms for automata manipulation are needed.
	In this work, we will focus on the efficiency of algorithms needed in formal verification
	including language inclusion checking, reduction of automata states, or product of two automata.
	
	As we mentioned in the previous section, the inclusion operation is EXPTIME-complete complexity class
	therefore no efficient algorithm exists in general.
	Thus the verification methods rely on the different heuristics \cite{ac:2006, henzinger:1995, tacas10}
	to avoid the state explosion in many practical cases.

	The goal of this thesis is to design new and to improve the existing
	algorithms for (not only) the mentioned operations.
	An improvement in the efficiency could help to deal with the state explosion and enable
	verification of more complex software.

	Particularly, we will focus on generalization of computation of congruence closure used
	in language inclusion checking \cite{bonchi2013} to tree automata.
	We expect that it could improve a performance of language inclusion checking for tree automata
	as it helped for classical word automata in \cite{bonchi2013}.
	We implemented the congruence-based approach for word automata in the VATA library \cite{libvata}
	(a highly efficient library	for automata manipulation) so we have practical
	experiences with this algorithm which we can further employ for the generalization to trees.

	We will also aim to development of the new techniques for symbolic automata.
	Symbolic automata use logical formulas as the symbols.
	It enables an efficient representation of the large, or even infinite alphabets still having
	the nice algorithmic properties of the classical finite automata \cite{veanes2012}.
	There is currently intensive research in this field and we suppose
	that symbolic automata can also found an application in the field of shape analysis.
	As the starting point, we began a development (in cooperation with one bachelor student)
	of a library for symbolic automata.
	The main goal of the library is to provide a platform for easy prototyping of the new algorithms
	for symbolic automata what will be useful for further research.


	\section{Automata on Graphs with Bounded Tree Width}
	Although forest automata can represent a certain class of graphs (more precisely described in the
	following chapter), there are data structures (such as B+ trees) which need a more
	general formalism to express them properly.
	Within this sub-goal, we will address this need by designing a new kind of automata
	which will work over graphs with bounded tree width.

	The generality should not be the only advantage of the new automata.
	Their design should also benefit from the lessons learnt during the work on forest automata.
	Forest automata have bottlenecks leading to their clumsy manipulation, e.g.,
	they are not closed under union, so one has to work with a set of forest automata instead
	of one wrapping automaton.
	A concept of hierarchical forest automata (forest automata having other forest automata as symbols)
	may be theoretically tempting but it leads to not elegant implementation of
	the various needed operations over the automata.
	For example, an implementation of many of the automata transformers corresponding to the concrete C
	statements (such as the C function \emph{memset}) becomes quite cumbersome and not easy to design
	for hierarchical forest automata.

	The new automata should address both of the problems.
	They should be theoretically elegant, having decidable important properties (e.g., language inclusion),
	and be closed under important operations such as union or intersection.
	We will keep the automata design simple to make their implementation straightforward.
	The abstraction of the heap will not be stronger than necessary
	to make modelling of practical operations semantics easy.

	Although the mentioned implementation aspects are important for the practical applications
	the main scientific contribution of the thesis will be a design efficient algorithms for a manipulation with the new automata.
	The automata for accepting graphs introduced so far were mainly used for
	the theoretical purposes as it was described in the chapter on the related work.
	An interest put into an exploration of efficient heuristics and algorithms
	for their manipulation is not so high.
	The goal of this work is to change the current state and propose a new class of automata
	together with efficient algorithms for their manipulation.
	The algorithms will include, for example, efficient inclusion checking or automata reduction.
	The efficiency should make an application of graph automata to shape analysis computationally feasible.

	We will build on the work of \cite{iosif2013, iosif2014} where the automata on
	graphs with bounded tree width are used in a decision procedure for separation logic.
	The automata defined in these works are basically tree automata with symbols encoding
	how they run over a processed graph accepting all the spanning trees of the represented graphs.
	A symbol contains the tags used to denote which nodes have been
	already processed and which nodes of an accepted spanning tree are the same node in the original graph.
	Using this encoding, automata accept all possible spanning trees of the graphs represented by their languages.
	
	We will use the same approach for our new automata.
	The paths through a graph will be encoded in symbols
	and we will adapt the existing algorithms for tree automata to the new formalism.

\chapter{Pushing the Frontiers of Shape Analysis with Forest Automata}
\label{ch:vmcai}
The following chapter describes how the first goal of the thesis which is
an application of CEGAR loop for forest automata has been achieved.
The resulting work has been published at the VMCAI 2017 conference \cite{holik:2017},
and the following text is based on the paper.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}\label{sec:intro}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

In~\cite{forester12,boxes13}, \emph{forest automata} (FAs) were proposed as a
formalism for representing sets of heap graphs within a fully-automated and
scalable \emph{shape analysis} of programs with complex \emph{dynamic linked
data structures}. FAs were implemented in the \forester{} tool and successfully
used to verify programs over a wide range of data structures, such as different
kinds of lists (singly- and doubly-linked, circular, nested, and/or having
various additional pointers), different kinds of trees, as well as skip lists.
FAs have the form of tuples of \emph{tree automata} (TAs), allowing abstract
transformers corresponding to heap operations to have a \emph{local impact}
(i.e., to change just a few component TAs instead of the entire heap
representation), leading to scalability. To handle complex nested data
structures, FAs may be \emph{hierarchically nested}, i.e., lower-level FAs can
be used as (automatically derived) alphabet symbols of higher-level FAs.

Despite \forester{} managed to verify a number of programs, it suffered from two
important deficiencies.
Namely, due to using abstraction and the lack of
mechanisms for checking validity of possible counterexamples, it could report
\emph{spurious errors}, and, moreover, it was unable to refine the abstraction
using the spurious counterexample.
% Despite \forester{} managed to verify a number of programs, it suffered from one
% important deficiency. Namely, due to using abstraction, it could report
% \emph{spurious errors},
% but it lacked a mechanism for checking validity of
% possible counterexamples as well as a mechanism for a counterexample-guided
% refinement of the abstraction used.
Interestingly, as was discussed in the previous chapter,
this problem is common for many other approaches to shape
analysis, which may perhaps be attributed to the complexity of heap
abstractions. In our work, we tackle the above problem by providing a novel
method for \emph{validation of possible counterexample traces} as well as a
\emph{counterexample guided abstraction refinement} (CEGAR) loop for shape
analysis based on FAs.

%!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
\enlargethispage{6mm}
%!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

Our counterexample validation is based on \emph{backward symbolic execution} of
a candidate counterexample trace on the level of FAs (with no abstraction on the
FAs) while checking \emph{non-emptiness of its intersection} with the forward
symbolic execution (which was abstracting the FAs). For that, we have to revert
not only abstract transformers corresponding to program statements but also
various meta-operations that are used in the forward symbolic execution and that
significantly influence the way sets of heap configurations are represented by
FAs. In particular, this concerns \emph{folding} and \emph{unfolding} of nested
FAs (which we call \emph{boxes}) as well as \emph{splitting}, \emph{merging},
and \emph{reordering} of component TAs, which is used in the forward run for the
following two reasons: to
prevent the number of component TAs from growing and to obtain a canonic
FA representation. 

If the above meta-operations were not reverted, we would not only have problems
in reverting some program statements but also in intersecting FAs obtained from
the forward and backward run. Indeed, the general problem of checking emptiness
of intersection of FAs that may use different boxes and different component TAs
(i.e., intuitively, different decompositions of the represented heap graphs) is
open. When we carefully revert the mentioned operations, it, however, turns out
that the FAs obtained in the forward and backward run use \emph{compatible}
decomposition and hierarchical structuring of heap graphs, and so checking
emptiness of their intersection is possible. Even then, however, the
intersection is not trivial as the boxes obtained in the backward run may
represent smaller sets of sub-heaps, and hence we cannot use boxes as symbols
and instead have to perform the intersection \emph{recursively} on the boxes as
well.

Our abstraction on FAs is a modification of \emph{predicate
language abstraction} \cite{artmc12} already mentioned in Section \ref{subsection:armc}.
This particular abstraction collapses those states of component TAs that
have non-empty intersection with the same predicate languages, which are
obtained from the backward execution.
We show that, in
case the intersection of the set of configurations of the above described forward and backward symbolic runs
is empty, we can derive from it an \emph{automata interpolant} allowing us to
get more predicate languages and to refine the abstraction such that progress of
the CEGAR loop is guaranteed (in the sense that  we do not repeat the same
abstract forward run).

We have implemented the proposed approach in \forester{} and tested it on a
number of small but challenging programs. Despite there is, of course, a lot of
space for further optimisations, the experimental results are 
% 
% simply amazing (no need to be unnecessarily humble).
%
very encouraging.
%
\forester{} can now not only verify correct programs with complex dynamic data
structures but also reliably report errors in such programs. For some classes of
dynamic data structures (notably skip lists), \forester{} is, to the best of our
knowledge, the only tool that can provide both sound verification as well as
reliable error reporting in a fully automated analysis (i.e., no manually
provided heap predicates, no invariants, etc.). Moreover, for some classes of
programs (e.g., various kinds of doubly-linked lists, trees, and nested lists),
the only other tool that we are aware to be able to provide such functionality
is our older automata-based tool \cite{bhrv06b}, which is, however, far less
scalable due to the use of a~monolithic heap encoding based on a single TA. Finally,
the refinement mechanism we introduced allowed us to verify some programs that
were before out of reach of \forester{} due to handling finite domain data
stored in the heap (which can be used by the programs themselves or introduced
by tagging selected elements in dynamic data structures when checking properties
such as sortedness, reordering, etc.).

%!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
\enlargethispage{6mm}
%!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\vspace*{-2mm}
%\section{Related Work}
%\vspace*{-1mm}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%Many different approaches to shape analysis have been proposed, using various
%underlying formalisms, such as logics
%\cite{pale97,Sagiv02,InvaderCAV08,thor10,dragoi:atva12,sleek13}, automata
%\cite{bhrv06b,deg06,forester12,boxes13,lists-counters}, graphs
%\cite{sas07:chang_rival_necula,dudka13}, or graph grammars \cite{juggrnaut10}.
%Apart from the underlying formalisms, the approaches differ in their degree of
%automation, in the heap structures they can handle, and in their scalability.
%The shape analysis based on forest automata proposed in \cite{boxes13} that we
%build on in this paper belongs among the most general, fully automated
%approaches, still having decent scalability.
%
%As noted also in the recent work \cite{splinter15}, a common weakness of the
%current approaches to shape analysis is a lack of proper support for checking
%spuriousness of counterexample traces, possibly followed by automated refinement
%of the employed abstraction. This is exactly the problem that we tackle in this
%paper. Below, we characterize previous attempts on the problem and compare our
%approach with them. 
%
%The work \cite{beyer:lazy_shape_analysis} adds a CEGAR loop on top of the TVLA
%analyzer \cite{Sagiv02}, which is based on \emph{3-valued predicate logic with
%transitive closure}. The refinement is, however, restricted to adding more
%pointer variables and/or data fields of allocated memory cells to be tracked
%only (together with combining the ana\-ly\-sis with classic predicate analysis on
%data values). The analysis assumes the other necessary heap predicates (i.e.,
%the so-called core and instrumentation relations in terms of \cite{Sagiv02}) to
%be fixed in advance and not refined. The work
%\cite{Loginov:AbstrRefViaInductLearning:05} also builds on TVLA but goes
%further by learning more complex instrumentation relations using
%inductive logic programming. The core relations are still fixed in
%% further by allowing more complex instrumentation relations to be learnt using
%% inductive logic programming. The core relations are, however, still fixed in
%advance though. Compared with both of these works, we do not assume any predefined
%fixed predicates. Moreover, the approach of
%\cite{Loginov:AbstrRefViaInductLearning:05} is not CEGAR-based---it refines the
%% abstraction whenever it hits a~possible counterexample trace in whose analysis
%abstraction whenever it hits a~possible counterexample in which
%some loss of precision happened, regardless of whether the counterexample is
%real or not.
%
%In \cite{podelski:popl10}, a CEGAR-based approach was proposed for automated
%refinement of the so-called \emph{Boolean heap abstraction} using disjunctions
%of universally quantified Boolean combinations of first-order predicates with
%free variables and transitive closure.
%%
%% The work uses CEGAR to both add new predicates and to refine the abstract post
%% operator. 
%%
%Unlike our work, the approach assumes the analyzed programs to be annotated by
%procedure contracts and representation invariants of data structures. New
%predicates are inferred using finite-trace weakest preconditions on the
%annotations, and hence new predicates with reachability constraints can only be
%inferred via additional heuristic widening on the inferred predicates. Moreover,
%the approach is not appropriate for handling nested data structures, such as
%lists of lists, requiring nested reachability predicates.
%
%In the context of approaches based on \emph{separation logic}, several attempts
%to provide counterexample validation and automated abstraction refinement have
%appeared. In \cite{slayer12}, the \textsc{SLAyer} analyzer was extended by a method to
%check spuriousness of counterexample traces via bounded model checking and SMT.
%Unlike our work, the approach may, however, fail in recognising that a given
%trace represents a real counterexample. Moreover, the associated refinement can
%only add more predicates to be tracked from a pre-defined set of such
%predicates. In \cite{splinter15}, another counterexample analysis for the
%context of separation logic was proposed within a computation loop based on the
%Impact algorithm \cite{impact06}. The approach uses bounded backwards abduction
%to derive so-called spatial interpolants and to distinguish between real and
%spurious counterexample traces. It allows for refinement of the predicates used
%but only by extending them by data-related properties. The basic predicates
%describing heap shapes are provided in advance and fixed. Another work based on
%backwards abduction is \cite{botincan15}. The work assumes working with a
%parametrized family of predicates, and the refinement is based on refining the
%parameter. Three concrete families of this kind are provided, namely,
%singly-linked lists in which one can remember bigger and bigger multisets of
%chosen data values, remember nodes with certain addresses, or track ordering
%properties. The basic heap predicates are again fixed. The approach does not
%guarantee recognition of spurious and real counterexamples nor progress of the
%refinement.
%
%%!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
%\enlargethispage{5mm}
%%!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
%
%Unlike our approach, none of the so-far presented works is based on automata,
%and all of the works require some fixed set of shape predicates to be provided
%in advance. Among \emph{automata-based approaches}, counterexample analysis and
%refinement was used in \cite{bhrv06b} (and also in some related, less general
%approaches like \cite{bhmv05}). In that case, however, a single tree automaton
%was used to encode sets of memory configurations, which allowed standard
%abstraction refinement from abstract regular (tree) model checking
%\cite{artmc12} to be used. On the other hand, due to using a single automaton,
%the approach did not scale well and had problems with some heap transformations.
%
%% Finally, the Predator analyzer \cite{php15} avoids spurious errors by running a
%% sound, over-approximating analysis together with a precise one, allowing only
%% the latter to report counterexamples. This does not, however, allow the
%% abstraction used to be refined, possibly preventing correct programs from being
%% verified.
%
%The basic formalism of forest automata using fixed abstraction and
%user-provided database of boxes was introduced in~\cite{forester12}.
%We later extended the basic framework with automatic learning of boxes
%in~\cite{boxes13}.
%The work~\cite{forester-data-acta} added ordering relations into forest
%automata to allow verification of
%programs whose safety depends on relations among data values
%from an unbounded domain.
%In \cite{forester12,boxes13}, we conjectured that counterexample validation and
%abstraction refinement should be possible in the context of forest
%automata too. However, only now, do we show that this is indeed the case, but also that much
%more involved methods than those of \cite{artmc12} are needed.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\vspace*{-2mm}
\section{Forest Automata and Heaps}
\vspace*{-1mm}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% \td{OL: talk only about heaps}

We consider sequential non-recursive C programs, operating on a set of pointer
variables and the heap, using standard statements and control flow constructs.
%Variables are either \emph{data variables} or \emph{pointer variables}.
Heap cells contain zero or several pointer or data fields.
%(our framework and implementation extends easily to several data fields).
% \comment[mh]{Why do you speak about commands here?}
%The supported statements include allocation and deallocation of heap memory,
%tests between data variables or fields of heap cells, as well as assignments
%between data variables, pointer variables, or fields of heap cells.

%\begin{figure}
%% \vspace{10mm}
%% \hspace{-4mm}
%\begin{center}
%\begin{tikzpicture}[%
%  codeblock/.style={text width=0.4\linewidth,rounded corners,inner xsep=12pt,inner ysep=0pt,below right,draw=gray!3!white},%
%  property/.style={rounded corners=1pt,inner xsep=1mm,draw=black!50,fill=white,double}%
%  ]
%  \node[codeblock] (code) {\small\VerbatimInput{code.txt}};
%\end{tikzpicture}%
%\end{center}
%\vspace*{-1mm}
%\caption{A function which inserts a~new node into a BST and returns a~pointer to
%its root node.}
%\label{fig:bst-code}
%\end{figure}
%
%Fig.~\ref{fig:bst-code} shows an example of a C function inserting a new node
%into a~BST (recall that in BSTs, the data value in a node is larger than all
%the values of its left subtree and smaller than all the values of its right
%subtree). Variable $\code{x}$ descends the BST to find the position at which
%the node $\code{newNode}$ with a new data value $\code{d}$ should be inserted.

Configurations of the considered programs consist of
memory-allocated data and an assignment of variables.
\emph{Heap memory} can be viewed as a~(directed) graph whose nodes correspond
to allocated memory cells.
Every node contains a~set of named pointer and data fields.
Each pointer field points to another node (we model the
$\code{NULL}$ and undefined locations as special memory nodes pointed by variables
$\code{NULL}$ and $\code{undef}$, respectively), and the same holds for pointer variables of the program.
Data fields of memory nodes hold a data value.
We use the term \emph{selector} to talk both about pointer and data fields.
For simplification, we model data variables as pointer variables pointing to
allocated nodes that contain a single data field with the value of the
variable, and therefore consider only pointer
variables hereafter.
%In our terminology, a~\emph{heap} consists of a~heap memory and mapping of
%(pointer) variables to memory nodes.

%% We represent heap memory as a~composition of trees as follows. We first identify the
%% \emph{cut-points} of the heap, i.e., nodes that are either referenced by a
%% pointer variable or by several selectors. We then split the heap into
%% (cut-point-free) tree
%% components such that each cut-point becomes the root of a tree component. To
%% represent the interconnection of tree components, we introduce a set of
%% \emph{root references}, one for each tree component. After decomposition of the
%% heap, selectors and variables that point to cut-points in the heap are redirected to
%% point to the corresponding root references. Such a tuple of tree components
%% (together with the mapping of variables) is called a~\emph{forest}.
%% The decomposition of a~heap into tree components can be
%% performed canonically as described at the end of Section~\ref{sec:fa}.

We represent heap memory by partitioning it into a~tuple of trees, the
so-called \emph{forest}.
The leaves of the trees contain information about roots of which trees they should be merged with to recover the original heap. 
Our \emph{forest automata} symbolic representations of sets of heaps is based
on representing sets of forests using tuples of tree automata.
%

% \td{OL: keep the example? START}
% \td{OL: maybe substitute with Fig.~\ref{fig:forest_rep}?}
% Fig.~\ref{fig:bst-graph}(a) shows a possible heap of the program in
% Fig.~\ref{fig:bst-code}. Nodes are shown as circles, labeled by their data
% values. Selectors are shown as edges. Each selector points either to a~node or
% to $\nullconst$ (denoting \texttt{NULL}). Some nodes are labeled by a~pointer
% variable that points to them. The node with data value $15$ is a cut-point since
% it is referenced by variable $\code{x}$. Fig.~\ref{fig:bst-graph}(b) shows a
% tree decomposition of the graph into two trees, one rooted at the node
% referenced by $\code{root}$, and the other rooted at the node pointed by
% $\code{x}$. The $\code{right}$ selector of the root node in the first tree
% points to root reference $\rr{2}$ ($\rr{i}$ denotes a reference to the $i$-th
% tree $\tree_i$) to indicate that in the graph, it points to the corresponding
% cut-point.
% \td{OL: keep the example? END}

%%% kicked out for the submission
%%% Fig.~\ref{fig:forest_rep_graph} shows an example of a~(data-free) heap;
%%% nodes are shown as circles, selectors are shown as edges.
%%% Each selector points either to a~node or to $\nullconst$ (denoting
%%% an edge to the \texttt{NULL} node).
%%% Some nodes are labeled by a~pointer variable that points to them.
%%% The nodes labelled with 1 and 3 are cut-points because they are pointed by
%%% variables (\texttt{x} and \texttt{y} respectively) and the node labelled with 2
%%% is a cut-point because it has two incoming edges.
%%% Fig.~\ref{fig:forest_rep_forest} shows a~forest representation of the heap from
%%% Fig.~\ref{fig:forest_rep_graph}.

Let us now formalize these ideas.
% \lukas{formulation sounds as it was a part of contribution, which it is not}
%  We will define heaps as parameterized by
% a~set $\abcd$ of selectors.
% E.g., when representing heaps, $\leaflab$ will contain the special value
% $\nullconst$; in tree components, $\leaflab$ will also include root references.
In the following, we use $f: A \partialto B$ to denote a partial function from
$A$ to $B$ (also
viewed as a~total function $f: A \to (B \cup \set{\top})$, assuming that $\top
\not\in B$).
We also assume a bounded data domain $\dset$. 
% \lukas{unbounded data domain frmo ACTA replaced by bounded data domain}
%with a total ordering
%relation $\preceq$.

% \begin{figure}[t]
%   \begin{minipage}[b]{5.6cm}
%     \centering
%     \vspace{-2mm}
%     \input{figs/bst_graph.tex}
%
%     \vspace{-1mm}
%     \small (a) A~graph.
%   \end{minipage}
%   \begin{minipage}[b]{6.8cm}
%     \begin{minipage}[t]{2.8cm}
%       \input{figs/bst_forest.tex}
%     \end{minipage}
%     \hspace{-0.0cm}
%     \begin{minipage}[t]{1.5cm}
%       \input{figs/bst_tree.tex}
%     \end{minipage}
%
%     \vspace{-1mm}
%     \centering
%    \small (b) A forest decomposition.
%   \end{minipage}
%   \vspace{-1mm}
%   \caption{Decomposition of a graph into trees.}
% \label{fig:bst-graph}
% \end{figure}

%% kicked out for the first submission
%% \begin{figure}[t]
%%   \begin{subfigure}[b]{0.48\textwidth}
%%   \centering
%%   \input{figs/fa-tree-decomp-graph.tikz}
%%   \caption{A~heap}
%%   \label{fig:forest_rep_graph}
%%   \end{subfigure}
%%   \hfill
%%   \begin{subfigure}[b]{0.48\textwidth}
%%   \centering
%%   \input{figs/fa-tree-decomp-forest.tikz}
%%   \caption{Its forest representation}
%%   \label{fig:forest_rep_forest}
%%   \end{subfigure}
%% \caption{A~heap and its forest representation.  For simplification, edges to
%% the dedicated $\nil$ node are represented using $\nullconst$ (we omit the
%% node from the graphical representation).}
%% \label{fig:forest_rep}
%% \end{figure}

%\bigskip
%\lukas{throw away $\leaflab$ completely? We can assume that $\abcd$ does not intersect with $\{\bar i\mid i\in\nat\}$ and use trees over $\abcd\cup\{\bar 1\,\ldots\bar n\}$ It looks like the only instantiation of $\leaflab$ is the $\{\bar 1,\ldots,\bar n\}$ anyway.}

%------------------------------------------------------------------------------
\vspace*{-1mm}\paragraph{Graphs and Heaps.}
%------------------------------------------------------------------------------

Let $\abcd$ be a finite set of \emph{selectors} and $\leaflab$ be a~finite set
of \emph{references} s.t.~$\leaflab \cap \dset = \emptyset$.
A~\emph{graph}~$\graph$ over $\tuple{\abcd,\leaflab}$ is
% A~\emph{graph}~$\graph$ over $\abcd$ is
a tuple $\tuple{\nodesof{\graph},\selmapof{\graph}}$ where
$\nodesof{\graph}$ is a~finite set  of \emph{nodes} and $\selmapof{\graph}: \abcd \to (\nodesof{\graph}
\partialto (\nodesof{\graph}\cup \leaflab \cup \dset))$ maps each selector $a \in \abcd$
to a~partial mapping $\selmapof{\graph}(a)$ from nodes to nodes, references, or
data values.
%
References and data values are treated as special terminal
nodes that are not in the set of regular nodes, i.e., $V_g \cap (\leaflab \cup
\dset) = \emptyset$.
%
For a~graph~$\graph$, we use $\nodesof \graph$ to denote the nodes of~$\graph$,
and for a selector $a \in \abcd$, we
use $\selof{\graph}$ to denote the mapping $\selmapof{\graph}(a)$.
Given a finite set of variables~$\gvars$,
a~\emph{heap}~$\heap$ over $\tuple{\abcd, \gvars}$ is
a tuple $\tuple{\nodesof{\heap},\selmapof{\heap}, \asgnheap}$ where
$\tuple{\nodesof{\heap}, \selmapof{\heap}}$ is a~graph over $\tuple{\abcd,
\emptyset}$ and $\asgnheap: \gvars \to \nodesof{\heap}$ is a~(total)
map of variables to nodes.

% Let $\abcd$ be a finite set of {\em selectors} and $\leaflab$ be a~finite set
% of \emph{references}.  A~\emph{graph}~$\graph$ over $\tuple{\abcd,\leaflab}$ is
% a tuple $\tuple{\nodesof{\graph},\selmapof{\graph},\datmapof{\graph}}$ where
% $\nodesof{\graph}$ is a~finite set  of \emph{nodes} (assuming $\nodesof{\graph}
% \cap \leaflab = \emptyset$), $\selmapof{\graph}: \abcd \to (\nodesof{g}
% \partialto (\nodesof{\graph} \cup \learlab))$ maps each selector $a \in \abcd$
% to a partial mapping $\selmapof{\graph}(a)$ from nodes to nodes and references,
% and $\datmapof{g}:(\nodesof{g}\cup\leaflab) \partialto \dset$ is a~partial
% \emph{data labelling} of nodes and references. For a selector $a \in \abcd$, we
% use $\selof{\graph}$ to denote the mapping $\selmapof{\graph}(a)$.
% \lukas{can we have simpler handling of data? Any ideas?}


%------------------------------------------------------------------------------
\vspace*{-1mm}\paragraph{Forest representation of heaps.}
%------------------------------------------------------------------------------
A graph~$\tree$ is a \emph{tree} if its nodes and pointers (i.e., not
references nor data fields) form a tree with a unique root node, denoted
$\rootof{\tree}$.
A~\emph{forest} over $\tuple{\abcd, \gvars}$ is a~pair
$\tuple{\tree_1\cdots\tree_n, \asgnforest}$ where  $\tree_1\cdots\tree_n$ is
a~sequence of trees over
$\tuple{\abcd,\set{\rr{1}, \ldots , \rr{n}}}$
and $\asgnforest$ is a~(total) mapping $\asgnforest: \gvars \to \set{\rr{1}, \ldots , \rr{n}}$.
The elements in $\set{\rr{1}, \ldots , \rr{n}}$ are called
\emph{root references} (note that $n$ must be the number of trees in the
forest). 
%
% The $\undef$ is a special reference which is used to model undefined pointer value.
%
% A~forest $\trees$ is {\em composable} if $\datmapof{\tree_k}(\rr{j})
% = \datmapof{\tree_j}(\rootof{\tree_j})$ for any $k,j$, i.e., the data labeling
% of root references agrees with that of roots.
A~forest $\tuple{\trees, \asgnforest}$ over
$\tuple{\abcd, \gvars}$ represents a~heap over $\tuple{\abcd, \gvars }$,
denoted $\graphof{\tuple{\trees, \asgnforest}}$, obtained by taking the union of the trees of
$\trees$ (assuming w.l.o.g.\ that the sets of nodes of the trees are disjoint),
connecting root references with the corresponding roots, and mapping every
defined variable~$x$ to the root of the tree indexed by~$x$.
Formally,
$\graphof{\tuple{\trees, \asgnforest}}$ is the heap $\heap = \tuple{\nodesof \heap,
\selmapof \heap, \asgnheap}$ defined by
%
\begin{inparaenum}[(i)]
  \item $\nodesof{\heap} = \ourbigcup_{i=1}^n \nodesof{\tree_i}$, and
  \item for $a \in \abcd$ and $v\in\nodesof{\tree_k}$, if $a_{\tree_k}(v) \in
    \set{\rr{1}, \ldots , \rr{n}}$ then $a_{\heap}(v) =
    \rootof{\tree_{a_{\tree_k}(v)}}$ else $a_{\heap}(v) = a_{\tree_k}(v)$, and
    finally
  \item for every $x \in \gvars$,  $\asgnheapof x
    = \rootof{t_{\asgnforestof x}}$.
\end{inparaenum} 
%We will use the following notation to talk about relations of data values of
%nodes within a forest. Given nodes $u,v$ of trees $\tree,\tree'$, respectively,
%of a~forest and a~relation ${\datarel}\in  \{\prec, \preceq, =, \succ, \succeq
%\}$, we denote by $u \datarel_{\code{rr}} v$ that $\datmapof \tree (u) \datarel
%\datmapof {\tree'} (v)$ and we denote by $u \datarel_{\code{ra}} v$ that 
%$\datmapof \tree (u) \datarel \datmapof {\tree'} (w)$ for all nodes $w$ in the subtree of $\tree'$ rooted at $v$. We call these two types of relationships \emph{root-root} and \emph{root-all} relations, respectively.
%\footnote{$\mathit{rr}$ and $\mathit{ra}$ abbreviate ``root-root'' and ``root-all'', respectively.}. 

% A graph $\tree$ is a \emph{tree} if its nodes and selectors (i.e., not
% references) form a tree with a unique root node, denoted $\rootof{\tree}$. A
% \emph{forest} over $\tuple{\abcd,\leaflab}$ is a sequence
% $\tree_1\cdots\tree_n$ of trees over $\tuple{\abcd,(\leaflab\uplus\set{\rr{1},
% \ldots , \rr{n}})}$. The elements in $\set{\rr{1}, \ldots , \rr{n}}$ are called
% \emph{root references} (note that $n$ must be the number of trees in the
% forest). 
% A~forest $\trees$ is {\em composable} if $\datmapof{\tree_k}(\rr{j})
% = \datmapof{\tree_j}(\rootof{\tree_j})$ for any $k,j$, i.e., the data labeling
% of root references agrees with that of roots. A~composable forest $\trees$ over
% $\tuple{\abcd, \leaflab}$ represents a~graph over $\tuple{\abcd, \{ \nullconst
% \} }$, denoted $\graphof{\trees}$, obtained by taking the union of the trees of
% $\trees$ (assuming w.l.o.g.\ that the sets of nodes of the trees are disjoint),
% and connecting root references with the corresponding roots.  Formally,
% $\graphof{\trees}$ is the graph $\graph$ defined by \begin{inparaenum}[(i)]
% \item $\nodesof{\graph} = \cup_{i=1}^n \nodesof{\tree_i}$, and \item for $a \in
% \abcd$ and $v\in\nodesof{\tree_k}$, if $a_{\tree_k}(v) \in \set{\rr{1}, \ldots
% , \rr{n}}$ then $a_{\graph}(v) = \rootof{\tree_{a_{\tree_k}(v)}}$ else
% $a_{\graph}(v) = a_{\tree_k}(v)$, and finally \item $\datmapof{\graph}(v) =
% \datmapof{\tree_k}(v)$ for $v\in\nodesof{\tree_k}$. \end{inparaenum} 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\vspace*{-2mm}
\subsection{Forest Automata}\label{sec:fa}
\vspace*{-1mm}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

A forest automaton is essentially a tuple of tree automata accepting a set of
tuples of trees that represents a set of graphs via their forest decomposition,
associated with a~mapping of variables to root references.

%-------------------------------------------------------------------------------
\vspace*{-1mm}\paragraph{Tree automata.}
%-------------------------------------------------------------------------------

A (finite, non-deterministic) \emph{tree automaton} (TA) over
$\tuple{\abcd,\leaflab}$
%extended with data constraints
is a triple $\ta =
(\states, \rstate, \Delta)$ where $\states$ is a finite set of \emph{states}
(we assume $Q \cap (\dset \cup \leaflab) = \emptyset$),
$\rstate \in \states$ is the \emph{root state} (or initial state), denoted
$\rootof{\ta}$, and $\Delta$ is a~set of \emph{transitions}. Each transition is
of the form $\trans{q}{q_1, \dots, q_m}$ where $m \geq 0$, $q \in Q$,
$q_1,\ldots,q_m\in (Q \cup \leaflab \cup \dset)$\footnote{For
simplicity, data values and references are used as special leaf states accepting the
data values and references they represent, instead of having additional leaf
transitions to~accept~them.}, and $\edgesymb = a^1 \cdots a^m$ is a
sequence of different symbols from~$\abcd$. 
%, and $c$ is a set of \emph{local
%constraints}. Each local constraint is of the form $0 \datarel_{\code{r}x} i$  where
%${\datarel} \in \{\prec, \preceq, \succ, \succeq \}$ (with $=$ 
%viewed as syntactic sugar\footnote{%
%The use of $\neq$ is forbidden because it would lead to a~disjunction of
%constraints, which we do not support in this work.}),
%$i \in \nset{m}$, and $x \in \{\code{r},\code{a}\}$.

%Intuitively, a local constraint of the form $0 \datarel_{\code{rr}} i$ associated with
%a transition of the form $\trans{q}{q_1, \dots, q_m}$ of a TA $\ta = (\states,
%\rstate, \Delta)$ states that, for each tree $t'$ accepted by $\ta$ at
%$\rstate$, the data value of the \emph{root} of the subtree $t$ of $t'$ that is
%accepted at $q$ is related by $\datarel$ with the data value of the \emph{root}
%of the $i$-th subtree of $t$ accepted at $q_i$. A~local constraint of the form
%$0 \datarel_{\code{ra}} i$ states that, for each tree $t'$ accepted by $\ta$, the data
%value of the \emph{root} of the subtree $t$ of $t'$ that is accepted at $q$ is
%related by $\datarel$ to the data values of \emph{all} nodes of the $i$-th
%subtree of $t$ accepted at $q_i$.

%Intuitively, a local constraint of the form $0 \datarel_{rr} i$ states that for each tree accepted the
%data value of the \emph{root} of every tree $t$ accepted at $q$ is related by
%$\datarel$ with the data value of the \emph{root} of the $i$-th subtree of $t$
%accepted at $q_i$. A~local constraint of the form $0 \datarel_{ra} i$ states
%that the data value of the \emph{root} of every tree $t$ accepted at $q$ is
%related by $\datarel$ to the data values of \emph{all} nodes of the $i$-th
%subtree of $t$ accepted at $q_i$.

Let $\tree$ be a tree over $\tuple{\abcd,\leaflab}$, and let $\ta = (\states,
\rstate, \Delta)$ be a~TA over $\tuple{\abcd,\leaflab}$.  A \emph{run} of~$\ta$
over $\tree$ is a total map $\run: \nodesof{\tree} \to Q$ where
$\run(\rootof{\tree}) = \rstate$ and for each node $\node \in \nodesof{\tree}$
there is a transition $\trans{q}{q_1, \dots, q_m}$ in $\Delta$ with
$\edgesymb = a^1 \cdots a^m$ such that $\runof{\node} = q$ and for all $1
\leq i \leq m$, we have (i) if $q_i \in Q$, then $a_{\tree}^i(\node) \in
\nodesof{\tree}$ and $\run(a_{\tree}^i(\node)) = q_i$, and (ii) if $q_i \in
\leaflab \cup \dset$, then $a_{\tree}^i(\node) = q_i$. 
%
%and (3)~for each constraint in $c$,
%the following holds: \begin{itemize}
%
%  \item if the constraint is of the form $0 \datarel_{rr} i$, then
%  $\datmapof{\tree}(\node) \datarel \datmapof{\tree}(a_{\tree}^i(\node))$, and
%
%  \item if the constraint is of the form $0 \datarel_{ra} i$, then
%  $\datmapof{\tree}(\node) \datarel \datmapof{\tree}(\nodepp)$ for all nodes
%  $\nodepp$ in $\nodesof{\tree}$ that are in the subtree of $\tree$ rooted at
%  $a_{\tree}^i(\node)$.
%
%\end{itemize} 
We define the \emph{language} of $\ta$ as $\langof{\ta}= \{\tree
\mid \mbox{there is a run of $\ta$ over $\tree$} \}$, and the language of a~state~$q \in Q$ as $\langof{A, q} = \langof{(Q, q, \Delta)}$.

%\begin{example} BSTs, such as the tree labeled by $\code{root}$ but without the variable $\code{x}$  in
%Fig.~\ref{fig:bst-graph}(a), are accepted by the TA over
%$\tuple{\abcd,\leaflab}$ with one state $q_1$, which is
%also the root state (denoted by $\finalstate{q_1}$), and the following four transitions:
%
%{\small
%\[
%\begin{array}{ll}
%  \transover{\finalstate{q_1}}{\bstsym}{q_1, q_1} & : 0 \succ_{\code{ra}} 1, 0 \prec_{\code{ra}} 2\\
%  \transover{\finalstate{q_1}}{\bstsym}{\nullconst, q_1} & : 0 \prec_{\code{ra}} 2
%\end{array}
%\qquad
%\begin{array}{ll}
%  \transover{\finalstate{q_1}}{\bstsym}{q_1,\nullconst} & : 0 \succ_{\code{ra}} 1\\
%\transover{\finalstate{q_1}}{\bstsym}{\nullconst,\nullconst}
%\end{array}
%\]
%}%
%The local constraints of the transitions  express that the data value in a node
%is always greater than the data values of all nodes in its left subtree and
%less than the data values of all nodes in its right subtree.
%\qed
%\end{example}

%-------------------------------------------------------------------------------
\vspace*{-1mm}\paragraph{Forest automata.}
%-------------------------------------------------------------------------------

A \emph{forest automaton} (FA) over $\tuple{\abcd, \gvars}$ is a tuple of the
form $\fa = \tuple{\tas, \asgn}$ where $\tas$, with $n \geq 0$, is a sequence of TAs
over $\tuple{\abcd, \set{\rr{1}, \ldots , \rr{n}}}$ whose sets
of states $\states_1$, \dots, $\states_n$ are mutually disjoint, and $\asgn:
\gvars \to \set{\rr{1}, \ldots , \rr{n}}$ is a~mapping of variables to
root references.
%
A forest $\tuple{\trees,\\ \asgnforest}$ over $\tuple{\abcd,\gvars}$ is
\emph{accepted} by $\fa$ iff $\asgnforest = \asgn$ and there are runs $\run_1, \dots, \run_n$ such that
for all $1 \leq i \leq n$, $\run_i$ is a run of $\ta_i$ over $\tree_i$.
%\begin{itemize}
%
%  \item if $rx = rr$, then $\datmapof{\tree_i}(v) \datarel
%  \datmapof{\tree_j}(v')$ whenever $\run_i(v) = q$ and $\run_j(v') = q'$,
%
%  \item if $rx = ra$, then $\datmapof{\tree_i}(v) \datarel
%  \datmapof{\tree_j}(w)$ whenever $\run_i(v) = q$ and $w$ is in a subtree
%  rooted at some $v'$ with $\run_j(v') = q'$.
%
%\end{itemize}
%
The \emph{language} of~$\fa$, denoted as $\langof{\fa}$, is the set of heaps
over $\tuple{\abcd, \gvars}$ obtained by applying $\otimes$ on
forests accepted by $\fa$.
% An FA $\fa$ over $\tuple{\abcd, \gvars}$
% represents a set of heaps $\heap$ over~$\tuple{\abcd, $.
%\footnote{Note that from the
%definitions of languages of TAs and FAs, the effect of the $\datarel_{ra}$ data
%constraint (both local and global) does not cross boundaries of the TAs it is
%related to.}.

%!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
\enlargethispage{5mm}
%!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

%-------------------------------------------------------------------------------
\vspace*{-1mm}
\paragraph{Cut-points and the dense form. }
%-------------------------------------------------------------------------------
A \emph{cut-point} of a heap $\heap$ is its node that is either pointed by some
variable or is a target of more than one selector edge.
%A forest $\forest$ is a \emph{minimal decomposition} if all its roots are cut-points of $\graphof\forest$. 
% The roots which are not cut-points are called \emph{false cut-points}.
% %
% A forest automaton is \emph{false cut-point free} if its accepted forest are false cut-point free.
% Every forest automaton can be transformed to a set of forest automata which together have the original language and accept only minimal decompositions.
% %
% This property is a part of canonicity, which can be achieved by normalization, introduced in \cite{forester12} to check entailment of forest automata.
% %
% A transformation to false cut-point free form is essential in a symbolic execution of pointer program.
% %
The roots of forests that are not cut-points in the represented heaps are called \emph{false roots}.
%
A forest automaton is \emph{dense} if its accepted forests do not have false roots.
Each forest automaton can be transformed into a~set of dense forest automata that
together have the same language as the original.
%
This property is a part of canonicity, which can be achieved by normalization,
introduced in~\cite{forester12} for the purpose of checking entailment
of forest automata.
%
A~transformation to the dense form is essential in the symbolic execution of a~program.
%


%The other roots are \emph{true cut-points}.

%In our analysis, we will represent only {\em garbage-free} heaps in which all
%nodes are reachable from some pointer variable by following some sequence of
%selectors. In practice, this is not a restriction since emergence of garbage is
%checked for each statement in our analysis; if some garbage arises, an error
%message can be issued, or the garbage removed. 
%
%The representation of a garbage-free heap $\heap$ as a~forest
%$\tuple{\trees,\asgn}$ can be made canonical by assuming a total order on
%variables and the set containing both selectors and boxes (we order selectors
%before boxes, and boxes are ordered by their lowest input port selector, which
%is unique, as guaranteed by the box folding procedure~\cite{boxes13}).
%Such an ordering induces a canonical
%ordering of cut-points using a depth-first traversal of~$\heap$ starting from
%pointer variables, taken in their order, and exploring~$\heap$ according to the
%order of selectors. The representation of~$\heap$ as $\tuple{\trees,
%\asgnforest}$ is called \emph{canonical}
%iff the roots of the trees in $\trees$ are the cut-points of
%$\heap$, and the trees are ordered according to their canonical ordering.  An
%FA $\fa = \tuple{\tas,\asgn}$ is \emph{canonicity respecting} iff all
%forests $\tuple{\trees, \asgnforest}$ accepted by~$\fa$ are canonical representations of heaps obtained as~$\graphof{\tuple{\trees, \asgnforest}}$.
%% $\heap \in \langof{\fa}$, formed as $\heap = \graphof{\tuple{\trees, \asgnforest}}$ for  $\tuple{\trees,\asgnforest}$ accepted by $\fa$, is canonical.
%% \td{OL: change to the new def. of FA as a pair}
%% \td{OL: note that the FAs themselves are not canonical}
%The canonicity respecting form allows us
%to check inclusion on the sets of heaps represented by FAs by checking inclusion
%component-wise on the languages of the component TAs%
%\footnote{The inclusion check is sound, though incomplete (see~\cite{forester12} for more details).}
%(used in testing fixpoint of symbolic execution)
%and to compute intersection by computing component-wise intersection of tree automata.
% \td{OL: this is used for testing fixpoint of symbolic execution}




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\vspace*{-2mm}
\subsection{Boxes}\label{sec:boxes}
\vspace*{-1mm}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \lukas{make a note about that this is a simplified version of general boxes which can have mutliple outputs}\\
%Forest automata, as defined in Section~\ref{sec:fa}, can represent graphs with
%a bounded number of cut-points even if the in-degree of them is unbounded as
%e.g.~in SLLs with head/tail pointers (indeed there can be any number of
%references from leaf nodes to a certain root).
Forest automata, as defined in Section~\ref{sec:fa}, can represent heaps with
cut-points of an unbounded in-degree as,
e.g.,~in singly-linked lists (SLLs) with head/tail pointers (indeed there can be any number of
references from leaf nodes to a certain root).
The basic definition of FAs cannot, however, deal with
heaps with an unbounded number of cut-points since this would require
an unbounded number of TAs within FAs.
An example of such a set of heaps is the
set of all doubly-linked lists (DLLs) of an arbitrary length, where each internal node is a cut-point.
The solution provided in \cite{forester12} is to allow FAs to use
other nested FAs, called \emph{boxes}, as symbols to ``hide'' recurring
subheaps 
%with designated \emph{input/output ports} 
and in this way eliminate
cut-points. The alphabet of a~box itself may also include boxes, these
boxes are, however, required to form a~finite hierarchy---they cannot be recursively nested.
% To make the semantics of a~box clear, we will need to extend the definitions of an FA from Section~\ref{sec:fa} to allow so-called ports. 
% Ports are nodes of a graph hidden within a box at which should be the hidden graph connected to its surroundings. 
The language of a~box is a~set of heaps over two special variables, $\iport$
and $\oport$, which correspond to the input and the output port of the box.
For simplicity of presentation, we give only a simplified version of boxes;
see~\cite{forester12} for a~more general definition that allows boxes with an
arbitrary number of output ports.

% Formally, we define an \emph{io-graph} over $\tuple{\abcd, \leaflab}$ to be a
% tuple $\iographof{\graph} = \tuple{\graph, \iport, \oport}$ where $\graph$ is
% a~graph with two designated distinct nodes $\iport$ and $\oport$ called the
% \emph{input} and \emph{output port} respectively.  An \emph{io-forest}
% $\ioforestof{\trees}$ over $\tuple{\abcd, \leaflab}$ is defined as
% $\ioforestof{\trees} = \tuple{\trees, \iport, \oport}$ where $\trees$ is a
% forest and $\iport, \oport \in \nset{n}, \iport \neq \oport$, are the
% \emph{input port} and \emph{output port indices}. The composition operator
% $\compositionoperator$ is extended to io-forests in the following way:
% $\graphof{\tuple{\trees, \iport, \oport}} = \tuple{\graphof{\trees},
% \rootof{\tree_{\iport}}, \rootof{\tree_{\oport}}}$, so the composition of an
% io-forest is an io-graph.

A~\emph{nested forest automaton} over $\tuple{\abcd, \gvars}$ is an FA
over $\tuple{\abcd \cup \boxes, \gvars}$ where $\boxes$ is a finite set of
\emph{boxes}. A \emph{box} $\botox$ over $\abcd$ %, where
%$\abcd$ does not contain $\botox$,
% is a triple $\fabox = \tuple{\fa_{\fabox},
% \iport, \oport}$ such that $\fa_{\fabox}$
is a nested FA $\tuple{\tas, \asgnbox}$ over $\tuple{\abcd, \set{ \iport, \oport}}$
% $\iport \in \nset{n}$ is
% the \emph{input port index}, and $\oport \in \nset{n}$ is the \emph{output port
% index}
such that $\asgnboxof \iport \neq \asgnboxof \oport$ and
$\tas$ do not contain an occurrence of $\botox$ (even a~nested one).
% The set of boxes of an NFA is required
% to form a~finite hierarchy, i.e. a box cannot recursively contain itself.
% \td{OL: this has already been said}
Unless stated otherwise, the FAs in the rest of the work are nested.

% The
% \emph{io-language} $\boxlangof{\fabox}$ of a box $\fabox = \tuple{\fa_{\fabox},
% \iport, \oport}$ is the set of io-graphs $\boxlangof{\fabox} =
% \{\graphof{\tuple{\trees, \iport, \oport} \mid \mbox{$\trees$ is accepted by
% $\fa_{\fabox}$}}\}$.

%% In the case of an NFA $\fa$, we need to distinguish between its \emph{macro-language}
%% $\langof{\fa}$, which is a set of heaps over $\tuple{\abcd \cup \boxes,
%% \gvars}$ and its \emph{semantics}~$\semof \fa$, which is a set of heaps over
%% $\tuple{\abcd, \gvars}$ that emerges when all boxes in the heaps of the
%% language are recursively \emph{unfolded} in all possible ways.
%% Formally, given
%% heaps $\heap$ and $\heapprime$, the heap $\heapprime$ is an \emph{unfolding} of $\heap$
%% (written as $\heap \unfold \heapprime$) if there is an occurrence $(\nodep,
%% \fabox, \node) \in \selmapof{\heap}$ of a~box $\fabox = \tuple{\tas, \asgnbox}$ in $\heap$ (which may
%% be seen as an edge from $\nodep$ to $\node$ over $\fabox$ in $\heap$), such
%% that $\heapprime$ can be constructed from $\heap$ by substituting $(\nodep,
%% \fabox, \node)$ with $\heap_{\fabox}$, which is done by removing $(\nodep,
%% \fabox, \node)$ from $\heap$, uniting $\heap$ with $\heap_{\fabox}$, and
%% associating $\asgnboxof \iport$ with $\nodep$ and $\asgnboxof \oport$  with
%% $\node$, where $\heap_{\fabox} \in
%% \langof{\fabox}$. We use $\unfold^{*}$ to denote the reflexive transitive
%% closure of~$\unfold$.
%% The \emph{semantics} of $\fa$, written as $\semof{\fa}$,
%% is the set of all heaps $\heapprime$ over $\tuple{\abcd, \gvars}$ for which
%% there is a heap $\heap$ in $\langof{\fa}$ such that $\heap \unfold^{*}
%% \heapprime$.

In the case of a~nested FA $\fa$, we need to distinguish between its language
$\langof{\fa}$, which is a set of heaps over $\tuple{\abcd \cup \boxes,
\gvars}$, and its \emph{semantics}~$\semof \fa$, which is a set of heaps over
$\tuple{\abcd, \gvars}$ that emerges when all boxes in the heaps of the
language are recursively \emph{unfolded} in all possible ways.
Formally, given
heaps $\heap$ and~$\heapprime$, the heap $\heapprime$ is an \emph{unfolding} of $\heap$
 if there is an edge $(\botox, \nodep, \node) \in \selmapof{\heap}$
 with a~box $\botox = \tuple{\tas, \asgnbox}$ in $\heap$, 
such that $\heapprime$ can be constructed from $\heap$ by substituting
$(\botox, \nodep, \node)$ with some $\heap_{\botox} \in
%\langof{\botox}$ such that $\asgnboxof \iport = u$ and $\asgnboxof \oport = v$. 
\semof{\botox}$ such that $\asgnboxof \iport = u$ and $\asgnboxof \oport = v$. 
The substitution is done by removing 
$(\botox, \nodep, \node)$ from $\heap$ and uniting the heap-graph of $\heap$ with that of $\heap_{\botox}$. 
%, and
%associating $\asgnboxof \iport$ with $\nodep$ and $\asgnboxof \oport$  with
%$\node$. 
We then write $\heap \unfoldof{(\botox,u,v)}{\heap_{\botox}} \heapprime$, or only $\heap\unfold\heapprime$ if the
% $(\botox,u,v)$
precise edge $(\botox, u, v)$ and heap~$\heap_{\botox}$
are not relevant.
We use $\unfold^{*}$ to denote the reflexive transitive
closure of~$\unfold$.
The \emph{semantics} of~$\fa$, written as~$\semof{\fa}$,
is the set of all heaps $\heapprime$ over $\tuple{\abcd, \gvars}$ for which
there is a heap $\heap$ in $\langof{\fa}$ such that $\heap \unfold^{*}
\heapprime$.

%\td{OL: the next is maybe useless here}
%\lukas{ok, killing it}
%In a verification run, boxes are automatically inferred  using the techniques
%presented in~\cite{boxes13}. Abstraction is combined with \emph{folding}, which
%substitutes substructures of FAs by TA transitions that use boxes as labels.
%On the other hand, \emph{unfolding} is required by abstract transformers that
%refer to nodes or selectors encoded within a box to expose the content of the
%box by making it a part of the top-level FA. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\vspace*{-2mm}
\section{Program Semantics}
\vspace*{-1mm}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

The dynamic behaviour of a~program is defined by its control flow graph,
a mapping $\prog: \transfs \to (\locs \times \locs)$ where $\transfs$ is a set of
program statements, and $\locs$ is a~set of program locations.
Statements are partial functions $\transf:\confs\partialto\confs$ where
$\confs$ is the set of heaps over the selectors $\abcd$ and variables~$\pvars$
occurring in the program, which are used as representations of program configurations.
The initial configuration is~$\initconf = \tuple{\emptyset,\emptyset,\emptyset}$.
%
%
%
%Formally, let~$\locs$ be the set of \emph{program locations} of a~program
%and~$\abstransfs$ be the set of \emph{abstract transformers} that over-approximate
%the statements of the program in the abstract domain of FAs.
We assume that statements are indexed by their line of code, so that no two
statements of a~program are equal.
% We assume that each occurence of a~statement in a~program yields a~distint
% command, so
% each command can be unambiguously paired
% with a~concrete statement in the program source.
%
If~$\progof \transf = (\loc, \loc')$,
% denotes that an execution of
then the program $\prog$ can move from $\loc$ to $\loc'$ while modifying 
the heap $\conf$ at location~$\loc$ into~$\transf(\conf)$. 
%
We assume that $\pvars$ contains a special variable $\pc$ that always evaluates
to a~location from~$\locs$, and that every statement updates its value
according to the target location.
%
%$\progof \transf = (\loc, \loc')$ denotes that if
%an execution of the given program is in a~program location~$\loc$, the program
%can, after executing command $\transf$, proceeds to the program
%location~$\loc'$.
%
%An (abstract) \emph{program}~$\prog$ is a~mapping between program locations and
%transformers, $\prog: \abstransfs \to (\locs \times \locs)$,
%
Note that a single program location can have multiple succeeding program
locations (which corresponds, e.g., to conditional statements), or no successor
(which corresponds to exit points of a~program).
%
We use~$\srcof \transf$ to denote~$\loc$ and~$\tgtof \transf$ to
denote~$\loc'$ in the pair above.
Every program~$\prog$ has a~designated location $\initloc$ called its
\emph{entry point}
and $\errorloc\in\locs$ called the error location%
\footnote{
For simplification, we assume checking the error line (un-)reachability property
only,
which is, anyway, sufficient in most practical cases.
For detection of garbage (which is not directly expressible as line
reachability), we can extend the formalism and check for garbage after every
command, and if a~garbage is found, we jump to $\errorloc$.
}.
% \td{OL: note that detection of garbage cannot be easily encoded as
% location reachability, its more of a configuration reachability.
% Solution: after interpretation of every statement, add an operation checking
% for garbage and in case it finds it, makes a transition to $\errorloc$.}


% \td{OL: this needs to be synchronized with the symbolic version (if at all)}
A~\emph{program path}~$\pth$ in~$\prog$ is a~sequence of statements
$\pth = \transf_1 \cdots \transf_n \in \transfs^*$ such that
%~$\srcof {\progof {\abstrans_1}}$ is the entry point of~$\prog$ and 
$\srcof{\abstrans_1} = \initloc$, and,
for all $1 < i \leq n$, it holds that
$\srcof{\transf_i} = \tgtof{\transf_{i-1}}$.
%
We say that $\pth$ is \emph{feasible}
%from a configuration $\conf\in\confs$
iff
$\transf_n\circ\cdots\circ\transf_1(\initconf)$ is defined.
%
% Let $\initloc\in\locs$ be the entry point of~$\prog$ and $\errorloc\in\locs$ be an error location in~$\prog$.
%The error transformer is any transformer with $\tgtof{\transf} = \errorloc$.
The program~$\prog$ is safe if it contains no feasible program path with
$\tgtof{\tau_n} = \errorloc$.
In the following, we fix a~program~$\prog$ with locations~$\locs$, variables~$\pvars$, and selectors~$\psels$.

% \td{OL: I don't know whether we can start only with $\tuple{\emptyset, \emptyset, \emptyset}$ due to some special things (data variables are pointer variables, \texttt{null} is a special pointer to a special location}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\vspace{-3.0mm}
\section{Symbolic Execution with Forest Automata} \label{sec:analysis}
\vspace{-2.0mm}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


Safety of the program $\prog$ is verified using symbolic execution in the domain $\sconfs$ of forest automata 
over $\tuple{\psels,\pvars}$.
%
The program is executed symbolically by iterating abstract execution of program statements and 
a generalization step.
%
% Generalization consists of
%of normalization, which transforms automata to canonicity respecting form, 
% box folding and regular abstraction.
%
% These three high-level operations (symbolic execution of program statements, 
%  folding, abstraction)
These high-level operations
%These four high-level operations (symbolic execution of program statements, 
%normalization, folding, regular abstraction)
are implemented as sequences of atomic operations and splitting.
% which we discuss in detail in Section~\ref{sec:fwd_run}. %
Atomic operations are functions of the type $\sop:\sconfs\partialto {\sconfs}$.
%
Splitting splits a~forest automaton $\fa$ into a set $\calS$ of forest automata such that $\semof\fa =\ourbigcup_{F' \in \calS} \semof{F'}$.
%
Splitting is necessary for some operations since forest automata are not
closed under union, i.e.,
some sets of heaps expressible by a finite union of forest automata 
are not expressible by a single forest automaton.
%

To show an example of sets of heaps not expressible using a single FA, assume that the statement $\code{x = y\text{\texttt{->}}sel}$ is
executed on a~forest automaton that encodes
cyclic singly linked lists of an arbitrary length where \code{y} points to
the~head of the list.
%
If the list is of length~$1$, then $\code{x}$ will, after execution of the
statement, point to the same location
as~$\code{y}$.
If the list is longer, $\code{x}$~and $\code{y}$ will point to different
locations.
%
In the former case, the configuration has a~single tree component, with both variables pointing to it.
In the latter case, the two variables point to two different components.
%
These two configurations cannot be represented using a~single forest automaton.

% Splitting is therefore performed prior to other operations to achieve that the result of the operation applied on each of the splits is expressible as a single forest automaton.

%We note that symbolic execution performs also a counterpart of folding, called unfolding, 
%to materialize selectors accessed by the symbolic commands that are hidden within boxes (cf. Section~\ref{sec:imaginary}).
%For the purpose of this section, 
%%we can, however, keep unfolding hidden as a component of symbolic commands.
%
%Folding, symbolic commands, and regular abstraction are symbolic
%\td{OL: macro?}
%\emph{language operations} of the type $\sop:\sconfs\to 2^{\sconfs}$.
%We call them
%\td{OL: macro?}
%language operations because they operate on the level of languages,
%they do not take into account semantics of boxes.
%%
%The reason why an operation returns a set of forest automata instead of a single one is that
%forest automata are not closed under union, 
%hence some sets of heaps that are expressible by a finite union of forest automata 
%are not expressible by a single forest automaton.
%
%
Symbolic execution explores the program's
\emph{abstract reachability tree} (ART).
%\tomas{Denote as abstract
%reachability tree (ART), common in other works?}
Elements of the tree are forest automata corresponding to sets of reachable configurations
at particular program locations.
The tree is rooted by the forest automaton $\initsconf$ s.t. $\semof{\initsconf} = \{\initconf\}$. 
Every other node is a result of an application of an atomic operation or a split on its parent,
and the applied operation is recorded on the tree edge between the two.
The atomic operation corresponds to one of the following: symbolic execution of an effect of
% a~program statement, generalization using regular abstraction, or to an auxiliary meta-operation that modifies
a~program statement, generalization, or an auxiliary meta-operation that modifies
the FAs while keeping its semantics (e.g., connects or cuts its components).
Splitting appears in the tree as a~node with several children connected via edges labelled by a special operation $\splitting$. 
The said operations are described in more detail in Section~\ref{sec:fwd_run}.
%
%There are two reasons why a node can have more than one child.
%First, when there are more than one control flow edges leading from the control location.
%Second, when the symbolic execution needs to perform so called splitting. 
%%splitting is performed. 
%Splitting transforms a forest automaton $\fa$ into a set of forest automata $S$ such that $\langof{\fa} = \langof{S}$.
%
%
%\td{OL: $\alpha$ not yet defined, we should say something about it if it is here}
%

%!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
\enlargethispage{6mm}
%!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

The tree is expanded starting from the root as follows:
First, a~symbolic configuration in the parent node is generalized by iterating
the following three operations:
%
\begin{inparaenum}[(i)]
  \item  transformation to the dense form, 
  \item  application of regular abstraction over-ap\-prox\-imating sets of sub-graphs between
    cut-points of the represented heaps,
  \item  folding boxes to decrease the number of cut-points in the represented
    heaps,
\end{inparaenum}
%
until fixpoint.
% regular abstraction followed by box folding until fixpoint.
% That is, the iteration stops when folding followed by abstraction has no
% further effect.
The transformation into the dense form is performed in order to obtain the most
general abstraction in the subsequent step.
A~configuration where one more loop of the transformation-abstraction-folding sequence has
no further effect is called \emph{stable}.
%
Operations implementing effects of statements are then applied on stable configurations.
%
Exploration of a branch is terminated if its last configuration is entailed
by a~symbolic configuration with the same program location reached previously 
elsewhere in the tree.

A \emph{symbolic path} is a path between a~node and one of its
descendants in the ART, i.e., a sequence of FAs and operations
$\fwrun = \sconf_0 \sop_1 \sconf_1 \ldots \sop_n \sconf_n$
such that $\sconf_i = \sop_i(\sconf_{i-1})$.
A~\emph{forward run} is a symbolic path where $\sconf_0 = \initsconf$.
We write $\prefix \fwrun i$ to denote the prefix of~$\fwrun$ ending by $\sconf_i$ and 
$\suffix \fwrun i$ to denote its suffix from~$\sconf_i$. 
% A \emph{forward run} is a path in the execution tree, that is, it is a sequence of FAs and operations
% $\fwrun = \sconf_0 \sop_1 \sconf_1 \ldots \sop_n \sconf_n$
% such that $\sconf_0 = \initsconf$ and $\sconf_i \in \sop_i(\sconf_{i-1})$.
% %
% We write $\prefix \fwrun i$ to denote its prefix ending by $\sconf_i$ and 
% $\suffix \fwrun i$ to denote its suffix starting in~$\sconf_i$. 
%
A~forward run that reaches~$\errorloc$ is called an~\emph{abstract
counterexample}.
We associate every operation~$\sop$ with its \emph{exact semantics} $\sopex$,
defined as $\sopexof H = \ourbigcup_{\heap \in H}\{\transfof \heap\}$
if $\sop$ implements the~program statement~$\transf$,
and as the identity for all other operations (operations implementing
generalization, splitting, etc.), for a~set of heaps~$H$.
%
The \emph{exact execution} of $\fwrun$ is a~sequence $\conf_0\cdots\conf_n$
such that 
$\conf_0\in \semof{\sconf_0}$ and    
$\conf_i\in\sopexof{\{\conf_{i-1}\}}\cap\semof{\sconf_i}$ for $0 < i\leq n$.
%
We say that $\fwrun$ is \emph{feasible} if it has an exact execution, 
otherwise it is \emph{infeasible/spurious}.
The atomic operations are either semantically precise, or over-approximate
their exact semantics, i.e.,
it always holds that $\sopexof{\semof \sconf} \subseteq \semof{\sop(\sconf)}$.
Therefore,
if the exploration of the program's ART finds no abstract counterexample, there
is no exact counterexample, and
the program is safe.



The regular abstraction mentioned above is based on over-approximating sets
of reachable configurations using some of the methods described later in
Section~\ref{sec:abstraction}.
The analysis starts with some initial abstraction function, which may, however,
be too rough and introduce spurious counterexamples.
The main contribution of the presented work is that we are able to analyse
abstract counterexamples for spuriousness using the so-called \emph{backward run}
(cf.~Section~\ref{sec:bwd_run}), and if the counterexamples are indeed
spurious, we can \emph{refine} the abstraction used to avoid the given spurious error
symbolic path, and continue with the analysis,
potentially further repeating the analyse-refine steps.
We will describe the backward run and abstraction refinement shortly in the
following section and give a more thorough description in
Section~\ref{sec:bwd_run} and~Section~\ref{sec:abstraction}.

% Our refinement on abstraction is based on the framework of
% \emph{counter-example guided abstraction refinement} (CEGAR)
%
%
% \td{OL: talk about abstraction here}
%
% \td{OL: talk about folding here}
% a little
% \cite{boxes13}


% The previous algorithm generates forward runs in the analyzed program \td{OL: blah}
% \td{OL: talk about CEGAR}
%

%For every command $\transf\in\transfs$, 
%the symbolic operation $\stransf$ is its symbolic version such that 
%$\cup_{\sconf'\in \stransf(\sconf)}\semof{\sconf'} = \{\transf(\conf)\mid\conf\in\semof{\sconf}\}$.
%Unfolding is, as folding, semantically identity. 
%On the level of languages, it maps configurations to their more unfolded versions.
%

%\td{OL: move this elsewhere}
%Our implementation in \forester{} explores the tree depth first.%\lukas{say this elsewhere?}  
%\td{OL: how about the DFS? we should emphasize it, because for other search order, this termination property might make the analysis unsound}


%!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
\enlargethispage{5mm}
%!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\vspace*{-2mm}
\subsection{Counterexample Analysis and Abstraction Refinement}\label{sec:CEXanalysis}
\vspace*{-1mm}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\lukas{random blabla}
%When an error in the analysed program is detected,
%it is necessary to check whether is it real or spurious.
%A~spurious error is caused by an overapproximating abstraction.
%The~analysis of spuriousness can be done by a \emph{backward run}.
%In its pure form, 
%it starts from the configuration reached on the error location and runs inverted symbolic statements from the path reaching the counterexample.
%It either ends by reaching the initial location with a nonempty symbolic state, in which the error path is indeed feasible and the program is not safe,
%or it ends by reaching a set of configurations disjoint with the set reached at the point of the path by the forward run, indicating that path was made feasible by overapproximation due to abstraction at that point and that the path does not represent a real conterexample. 
%\begin{figure}[t]
%	\centering
%	\includegraphics[width=\textwidth]{figs/artmc.png}
%	\caption{
%		Illustration (borrowed from \cite{artmc12}) of the principles of the forward and the backward run and
%		the detection of a spurious counterexample.
%		}
%	\label{fig:bwrun}
%\end{figure}
%
Assume that the forward run $\fwrun = \sconf_0\sop_1\sconf_1\cdots\sop_n\sconf_n$ is spurious. 
Then there must be an index $i>0$ 
such that the symbolic path $\suffix \fwrun {i}$ is feasible 
but $\suffix \fwrun {i-1}$ is not.
This means that the operation $\sop_i$  over-approximated the semantics of $\omega$ and 
introduced into $\semof{\sconf_{i}}$ some heaps that are not in $\sopexiof{\semof{\sconf_{i-1}}}$ 
and that are \emph{bad} in the sense that they make $\suffix \fwrun {i}$ feasible.
%at the $i$th step. 
%
An \emph{interpolant for $\fwrun$}
%\td{OL: for sth? for the run $\fwrun$?} \tomas{Shouldn't it mention position $i$
%too? Usually, interpolants can be defined for any position of a spurious path. But for us, it is
%related to that unique one only, right? Perhaps to be mentioned so that people do not complain that we do not
%know what an interpolant is. In general, we should stress that our notion is
%special.}
is then a forest automaton $\interp_i$ representing
%\td{OL: language?} 
the bad heaps
of $\semof{\sconf_i}$ that were introduced into $\semof{\sconf_{i}}$ by the
over-approximation in $\sop_i$ and are
disjoint from $\sopexiof{\semof{\sconf_{i-1}}}$.
% and does represent any configurations from $\sop_i$%
%\td{OL: I don't get it}
Formally,
%
\begin{enumerate}
\item
$\semof{\interp_i} \cap \sopexiof{\semof{\sconf_{i-1}}} = \emptyset$ and 
\item
$\fwrun_i$ is infeasible from all $\conf\in\semof{\sconf_i} \setminus \semof{\interp_i}$.
\end{enumerate}
%
%\td{OL: I still don't get why we're talking about the complement}
%
%\tomas{Not sure either. Couldn't we say that (1) $\semof{\interp_i} \supseteq
%\semof{\sop_i}{\semof{\sconf_{i-1}}}$ and (2) $\fwrun_i$ is infeasible from all
%$\conf\in \semof{\interp_i}$? That would be closer to the classical case, I
%think. But we get the other from the backward computation, right? So, then just
%again explain explicitly that it is so and that it is for pragmatic reasons.}

In the following, we describe how to use backward run, which reverts operations
of the forward run on the semantic level, to check spuriousness of an abstract
counterexample.
Moreover, we show how to derive interpolants from backward runs reporting
spurious counterexamples, and how to use those interpolants to refine the
operation of abstraction so that it will not introduce the bad configurations
in the same way again.
% In the following, we describe how to compute the interpolant using a backward run that reverts the operations on the semantic level, and how to use the interpolant to refine the operation of abstraction so that it will not introduce the bad configurations in the same way again.
%
%
A~\emph{backward run} for $\fwrun$ 
is the sequence 
$\bwrun = \bwsconf_0 \cdots \bwsconf_n$
such that\vspace*{-0.5mm}
%
\begin{enumerate}
\item
$\bwsconf_n = \sconf_n$ 
and
\item
$\semof{\bwsconf_{i-1}} = \sopexiinvof{\semof{\bwsconf_{i}}} \cap \semof{\sconf_{i-1}}$, 
that is, ${\bwsconf_{i-1}}$ represents the \emph{weakest precondition} of
$\semof{\bwsconf_{i}}$ w.r.t.~$\sopexi$ that is \emph{localized} to
$\semof{\sconf_{i-1}}$.\vspace*{-0.5mm}
\end{enumerate}
%
If there is an $\bwsconf_i$ such that $\semof{\bwsconf_i} = \emptyset$ (and,
consequently, $\semof{\bwsconf_0} = \emptyset, \ldots, \semof{\bwsconf_{i-1}} =
\emptyset$), the forward run is spurious.
In such a~case,
an interpolant $\interp_i$ for $\fwrun$ can be obtained as $\bwsconf_{i+1}$ where $i+1$ is
the smallest index such that $\semof{\bwsconf_{i+1}}\neq~\emptyset$. 
%
We elaborate on the implementation of the backward run in Section~\ref{sec:bwd_run}.

We note that our use of interpolants differs from that of McMillan
\cite{mcmillanCAV03} in two aspects. First, due to the nature of our backward
run, we compute an interpolant over-approximating the source of the suffix of a
spurious run, not the effect of its prefix. Second, for simplicity of
implementation in our prototype, we do not compute a~sequence of localized
%implementation in our prototype tool, we do not compute a~sequence of localized
interpolants but use solely the interpolant obtained from the beginning of the
longest feasible suffix of the counterexample for a global refinement. 
%We note,
%however, that it would also be possible to use the sequence
%$\bwsconf_i,\ldots,\bwsconf_n$ as localized interpolants.
It would also, however, be possible to use the sequence
$\bwsconf_i,\ldots,\bwsconf_n$ as localized interpolants.


In Section~\ref{sec:abstraction}, we show that
using the interpolant $\interp_{i}$, 
it is possible to refine regular abstraction $\sop_i$ (the only over-approximating operation)
%into $\sop_i'$ 
to exclude the spurious run.
%\tomas{Say that it guarantees progress of the analysis which is a notion
%commonly used in the related work.}
The \emph{progress guarantees} for the next iterations of the CEGAR loop are then the 
following:\vspace*{-0.5mm}
%
\begin{enumerate}
\item
for any FA $\fa$ such that  
%$\sconf$ is forest compatible with $\sconf_{i-1}$
$\semof{\sconf}\subseteq\semof{\sconf_{i-1}}$ 
that is compatible with $\sconf_{i-1}$ (as defined in Section~\ref{sec:intersection})
it holds that
$\semof{\sop_i(\sconf)} \cap \semof{\interp_i} = \emptyset$,
%
%\tomas{I'm not getting this at all. What is $F$? The phrase ``in certain sense''
%sounds strange.}
\item
forward runs $\fwrun' = \sconf_0'\sop_1\sconf_1'\cdots\sop_n\sconf_n'$ such
that for all $1\leq j \leq n$, $\semof{\sconf_i'}\subseteq\semof{\sconf_i}$
and $\sconf_i'$ is compatible with $\sconf_i$ are excluded from the
ART.\vspace*{-0.5mm}
\end{enumerate}
%
The compatibility intuitively means that boxes are folding the same sub-heaps of represented heaps and that the TA components are partitioning them in the same way.
%
%Based on this, we can then give the following progress guarantee for the CEGAR loop.
%Let  $\fwrun$ languages entail $\fwrun' = \sconf_0'\sop_1'\cdots\sop_n'\sconf_n'$ if 
%$\langof{\sconf_i'}\subseteq\langof{\sconf_i}$ for all $0\leq i \leq n$. 
%\begin{equation}
%\text{There can be at most $n-i$ futher forward runs language-entailed by $\fwrun$.}
%\text{No further run language-entailed by $\fwrun$ can be bad until $i$.}
%\end{equation}
%\bigskip
%
%
%
%\lukas{Add some discussion about guarantees on the semantic level: If folding folds the same subgraphs into the same boxes, then we have also high-level semantic guarantees analogous to the above low-level ones.}
%
%\lukas{how to call better the high-level/low-level/language semantics? Better names?}
%
%\lukas{good names for notions: abstract commands/abstract transformers/symbolic commands/symbolic transformers, operations/symbolic operations/... ?}

%\td{OL: talk about CEGAR here}

%!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
\enlargethispage{5mm}
%!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

%*******************************************************************************
\vspace*{-2mm}
\section{Intersection of Forest Automata}\label{sec:intersection}
\vspace*{-1mm}
%*******************************************************************************

%
%It is box compatible with a folding sequence of $\heap'$ in $\fa'$  
%%$\folding' = 
%$\heap_0'\unfold_{(u_1,B_1',v_1)}\cdots\unfold_{(u_n,B_n',v_n)}\heap_n'$
%iff for every $1\leq i\leq n$,
%$\heap_i$ and $\heap_i'$ differ only in boxes on their edges.
%%
%The two sequences are forest compatible if also the following additional condition holds. 
%Let for all $1\leq i \leq n$, 
%$g_i$ be the graph which replaces the box when creating $h_{i+1}$ from $\heap_{i}$,
%and let $g_i'$ be the replaces the box when creating $h_{i+1}'$ from $\heap_{i}'$.
%%
%Then it must hold that
%$\heap_0 = \graphof \forest$ 
%and $\heap_0'=\graphof\forest'$ 
%where $\forest$ is accepted by $\fa$ and $\forest'$ by $\fa'$ and the two forests differ only in boxes on transitions,
%and the analogous relationship must hold 
%between $g_i$, $g_i'$, $\botox_i$, and $\botox_i'$ for every $1\leq i\leq n$.
%
%Two forest automata $\fa$ and $\fa'$ are box compatible/forest compatible iff 
%for every heap $\heap$ from $\semof{\fa}\cap\semof{\fa'}$,
%there is a pair of box compatible/forest compatible folding sequences of $\heap$, 
%one in $\fa$ and on in $\fa'$. 

% %-------------------------------------------------------------------------------
% \vspace{-0.0mm}
% % \subsection{The Algorithm for Computing Intersection of Forest Automata}
% \label{sec:isect_alg}
% \vspace{-0.0mm}
% %-------------------------------------------------------------------------------

The previous section used intersection of semantics of forest automata to
detect spuriousness of a~counterexample.
In this section, we give an algorithm that computes an under-approximation of
the intersection of semantics of a~pair of FAs, and later give conditions
(which are, in fact, met by the pairs of FAs in our backward run analysis) on
the intersected FAs to guarantee that the computed intersection is precise.

A simple way to compute 
%
% TV: What is ``semantic'' intersection???
%
% semantic 
%
the intersection of semantics of two FAs, denoted as $\cap$, is com\-po\-nent-wise, 
that is, for two FAs $\fa = \tuple{\tas,\asgn}$ and $\fa' = \tuple{\tasprime,\asgn}$,
we compute the FA $\fa\cap\fa' =
\tuple{(\ta_1\cap\ta_1')\cdots(\ta_n\cap\ta_n'), \asgn}$---note that the assignments need to be equal.
%
The tree automata product construction for our special kind of tree automata
synchronizes on data values and on references.
That is, a pair $(a,b)$ that would be computed by a~classical product
construction where $a$ or $b$ is a reference or a data value is replaced by~$a$
if $a = b$, and removed otherwise.

The algorithm described above is, however, incomplete, i.e., it only guarantees $\semof{\fa\cap\fa'}\subseteq\semof\fa\cap~\semof{\fa'}$.
%
To increase the precision, we take into account the semantics of the boxes in
the product construction, yielding a construction denoted using~$\isectfa$.
When synchronising two rules in the TA product, we recursively call intersection of forest automata.
%
That is, we compute the FA $\fa\isectfa\fa'$ in a~similar way as $\cap$, but replace the tree
automata product $\ta\cap\ta'$ by its variant $\ta\isectta\ta'$.
For $\ta = (Q, q_0, \Delta)$ and $\ta' = (Q',q_0', \Delta')$, it computes the  TA
$\ta\isectta\ta' = (Q \times Q', (q_0, q_0'), \Delta\isectta\Delta')$ where
$\Delta\isectta\Delta'$ is built as follows:\vspace*{-0.5mm}
    %
    \begin{align*}
    \Delta\isectta\Delta' = \big\{ & \transover{(q, q')}{\edgesymb\isectta\edgesymb'}{(q_1, q'_1), \ldots,
      (q_m, q'_m)} \mid \transover{q}{\edgesymb}{q_1, \ldots, q_m}
      \in \Delta,\\
      &
      \transover{q'}{\edgesymb'}{q'_1, \ldots, q'_m} \in \Delta'
      \big\}.
    \end{align*}
    %
    %The vector $\edgesymb \isectta \edgesymb'$ is defined in the following way.
    Suppose $\edgesymb = a_1 \cdots a_m$, $\edgesymb' = a_1' \cdots
    a_m'$, and that there is an index $0 \leq i \leq m$ such that if $
    j \leq i$, $a_j$ and $a_j'$ are not boxes, and if $i < j
    $, $a_j$ and $a_j'$ are boxes.
    The vector of symbols $\edgesymb \isectta \edgesymb'$ is created as
    $(a_1\isectta a_1') \cdots (a_m\isectta a_m')$ if $a_i\isectta a_i'$ is
    defined for all $i$'s, otherwise the transition is not created.
    The symbol $a_i\isectta a_i'$ is defined as follows:
    %
    \begin{enumerate}
      \item  for $j \leq i$, $a_j\isectta a_j'$ is defined as $a_j$ if $a_j = a_j'$ and is undefined otherwise,
      \item  for $j > i$, $a_j\isectta a_j'$ is the intersection of FAs (both
        $a_j$ and $a_j'$ are boxes, i.e., FAs).
    \end{enumerate}


%%% \td{OL: some intro why this is needed?}
%%% We now provide an algorithm for computing intersection of a~pair of FAs $\fa_L$
%%% and $\fa_R$. The algorithm may in general under-approximate the semantic intersection. 
%%% After presenting the algorithm, we will define 
%%% when $\fa_L$ and $\fa_R$ compatible,
%%% which is a sufficient condition for the algorithm to be precise. 
%%% %algorithm is precise if $\fa_L$ and $\fa_R$ are box-compatible, 
%%% %which is a property that we define after exposing the algorithm.
%%% %
%%% % This section gives an algorithm for computing intersection of a~pair of FAs
%%% % $\fa_L$ and $\fa_R$ that is precise if $\fa_L$ and $\fa_R$ are box-compatible.
%%% %
%%% 
%%% Intuitively, the algorithm
%%% %
%%% % for computing intersection of a~pair of box-compatible FAs 
%%% %
%%% performs
%%% %
%%% % , in general, 
%%% %
%%% two actions.
%%% %
%%% First, it maps the cut-points of the sets of heaps represented by the FAs on each
%%% other, which induces a~mapping between the TAs representing the sub-heaps
%%% %
%%% % between
%%% %
%%% delimited by 
%%% %
%%% these cut-points.
%%% %
%%% Second, it constructs TAs representing the intersection of the pairs of TAs
%%% given by this mapping.
%%% %
%%% % This intersection is computed by 
%%% %
%%% For that, an extension of the classical intersection
%%% algorithm for TAs, constructing new states as pairs of states of the
%%% original TAs, is used. The extension checks consistency of the obtained
%%% transition function
%%% %
%%% % compatibility of the obtained product pairs \tomas{What is a product pair????}
%%% %
%%% w.r.t. our extended definition of TAs (so that, e.g., a~data value or a~root
%%% reference is not paired with a~regular state) and deals with boxes by calling the FA
%%% intersection on them recursively.
%%% 
%%% The intersection 
%%% of a~pair of (non-nested) forest automata $\fa_L = \tuple{\tasin L ,
%%% \asgn^L}$ and $\fa_R = \tuple{\tasin R, \asgn^R}$ over $\tuple{\abcd, \vars}$,
%%% written as $\fa_R \isectfa \fa_L$ 
%%% is a set of FA which contains for the FA for every permutation of $\perm = \{1,\ldots,n\}$ such that $\perm(\asgn^R(x)) = \asgn^L(x)$ for all $x\in\vars$ contains the FA 
%%% $\fa_\perm = \tuple{\ta_1^L \cap \perm(\ta_{\perm(1)}^R),\ldots,\ta_n^L \cap \perm(\ta_{\perm(n)}^R),\valuation}$,
%%% if it has a non-empty language.
%%% %
%%% The notation $\perm(\ta)$ denotes the \emph{permutation of the TA $\ta$} where every occurrence in of a root reference $\rr i$ in a leaf rule is replace by $\rr {\perm(i)}$.
%%% %
%%% The tree automata product construction for our special kind of tree automata synchronizes on data values and on references. That is, a pair $(a,b)$ that would be computed by a classical product construction where $a$ or $b$ is a reference or a data value is replaced by $a$ if $a = b$, and removed otherwise.
%%% %
%%% Note that the number of TAs of $\fa_L$ and $\fa_R$ is required to be the same,
%%% otherwise~$\emptyset$ is immediately returned.
%%% 
%%% %
%%% %\begin{enumerate}
%%% %\item 
%%% %$\perm(\asgn^R(x)) = \asgn^L(x)$ for all $x\in\vars$
%%% %\item
%%% %$\fa_\perm = \tuple{\ta_1^R \cap \perm(\ta_1^R),\ldots,\ta_n^R \cap \perm(\ta_n^R),\valuation}$
%%% %has non-empty language. 
%%% %$\ta_1^R \cap \perm(\ta_1^R)$
%%% %The 
%%% 
%%% 
%%% 
%%% %%
%%% %\begin{enumerate}
%%% %  \item  Compute the relation $\isbij ~\subseteq \{\rr 1, \ldots, \rr n\}^2$
%%% %    s.t.~$l \isbij r \iff \exists x \in \vars: \asgn^L(x) = l \land
%%% %    \asgn^R(x) = r$.
%%% %    % We assume $\top \isbij \top$.
%%% %    In case $\isbij$ 
%%% %    %
%%% %    % is not injective in both directions,
%%% %    is not a partial bijection (i.e., injective in both directions),
%%% %    %
%%% %    % restricted to its domain and co-domain is not bijective,
%%% %    %
%%% %    return~$\emptyset$.
%%% %    This step creates a mapping between cut-points referenced by variables.
%%% %
%%% %  \item  \label{step:product}
%%% %    % \comment[ar]{Asi by to chtelo zduraznit, ze $A_{(l,r)}$ budujeme pouze pro $l \isbij r$}
%%% %    In the next step, we build component TAs of the resulting FA by doing
%%% %    a~component-wise product construction.
%%% %    Consider TAs~$\ta^L_l$ and~$\ta^R_r$, for $l \isbij r$, and
%%% %    let~$\ta_{(l,r)}$ be the TA constructed from $\ta^L_l$ and $\ta^R_r$ using
%%% %    the standard procedure for TA intersection~\cite{tata}.
%%% %    We define $\reachcpof{l,r}$ to be the set of pairs $(l', r') \in \rrs^2$
%%% %    s.t.~$(l', r')$ is reachable in~$\ta_{(l,r)}$.
%%% %    We now extend $\isbij$ to $\isbij'$ such that $\isbij'$ contains~$\isbij$, and, for
%%% %    any $l \isbij' r$, it also holds that~$l' \isbij' r'$
%%% %    for all $(l',r') \in \reachcpof{l,r}$.
%%% %    If $\isbij'$ is not 
%%% %    %
%%% %    % a~bijection on its support,
%%% %    %
%%% %    % injective in both directions,
%%% %    a~(total) bijection
%%% %    %
%%% %    we, again, return~$\emptyset$.
%%% %    This step creates a~mapping between the cut-points of the heaps of
%%% %    $\fa_L$ and $\fa_R$ not reachable directly from $\vars$.
%%% %    % \td{OL: deal with $(\top, \top)$}
%%% %
%%% %  \item In the final step, we create the resulting FA $\fa$ for the intersection.
%%% %    We start with an arbitrary injective partial mapping $\order: \rrs^2 \partialto
%%% %    \rrs$ defined for all elements of $\isbij'$.
%%% %    The FA $\fa$ is then constructed as the FA $\tuple{\tas, \asgn}$ where
%%% %    every $\ta_{i}$ is obtained from $\ta_{(l,r)}$ (for~$\orderof{l,r} = i$)
%%% %    as follows:
%%% %    \begin{enumerate}
%%% %      \item  any pair $(l',r') \in \rrs^2$ occurring in $\ta_{(l,r)}$ is
%%% %        substituted with $\orderof{l',r'}$,
%%% %      \item  any pair $(d_l,d_r) \in \dset^2$ occurring in
%%% %        $\ta_{(l,r)}$ is substituted either with $d_l$ (for $d_l = d_r$), or
%%% %        with~$\top$ (if $d_l \neq d_r$),
%%% %      \item  any pair $(l',r') \notin (Q_l \times Q_r) \cup \dset \cup \rrs$
%%% %        is substituted with~$\top$ (compatible pairs of data values
%%% %        and references were reduced to singletons before),
%%% %      \item  any transition where $\top$ occurs is removed,
%%% %      \item  $\asgn$ is obtained as $\asgnof x =
%%% %        \orderof{\asgn^L(x),\asgn^R(x)}$ for $x \in \gvars$.
%%% %        %
%%% %        % $\asgnof x = \top$.
%%% %    \end{enumerate}
%%% %    %
%%% %    If the language of any TA of $\fa$ is empty, we return~$\emptyset$,
%%% %    otherwise we return~$\fa$.
%%% %
%%% %\end{enumerate}
%%% %
%%% The previous procedure can also be extended to pairs of nested FAs over
%%% $\tuple{\abcd \cup \boxes, \vars}$ by replacing the standard product construction $\cap$ in 
%%% $\ta_i^L \cap \perm(\ta_{\perm(i)}^R)$ by the operator $\nestedcap$ which, when synchronizes two automata rules, does not compare their symbols on identity, but calls recursively the forest automata intersection construction $\isectfa$ on boxes.
%%% Particularly, for two TA  $\ta_l = (Q_l, q^0_l, \Delta_l)$ and $\ta_r = (Q_r, q^0_r,
%%%     \Delta_r)$ over $\tuple{\abcd\cup\boxes,\vars}$, $\ta_l\nestedcap\ta_r$ is the TA
%%%      $(Q_l \times Q_r, (q^0_l, q^0_r),
%%%     \Delta_{(l,r)})$ where $\Delta$ is built as follows:
%%%     %
%%%     \begin{align*}
%%%     \Delta_{(l,r)} = \big\{ & \transover{(q^l, q^r)}{\edgesymb}{(q^l_1, q^r_1), \ldots,
%%%       (q^l_m, q^r_m)} \mid \transover{q^l}{\edgesymb_l}{q^l_1, \ldots, q^l_m}
%%%       \in \Delta_l,\\
%%%       &
%%%       \transover{q^r}{\edgesymb_r}{q^r_1, \ldots, q^r_m} \in \Delta_r,
%%%       \edgesymb \in \edgesymb_l \capbox \edgesymb_r  \big\} .
%%%     \end{align*}
%%%     %
%%%     The operation $\edgesymb_l \capbox \edgesymb_r$ is defined in the following way.
%%%     Suppose $\edgesymb_l = a^1_l \cdots a^m_l$, $\edgesymb_r = a^1_r \cdots
%%%     a^m_r$, and that there is an index $0 \leq i \leq m$ such that for every $1
%%%     \leq j \leq i$, $a^j_l$ and $a^j_r$ are not boxes, and for every $i < j
%%%     \leq m$, $a^j_l$ and $a^j_r$ are boxes.
%%%     We create $\edgesymb = a^1 \cdots a^m$ as follows:
%%% The $\edgesymb_l \capbox \edgesymb_r$ is the set of vector of symbols defined as follows:
%%%     %
%%%     \begin{enumerate}
%%%       \item  for $j \leq i$, $a^j$ is defined as $\{a^j_l\}$ if $a^j_l = a^j_r$,
%%%         and as $\emptyset$ otherwise,
%%%       \item  for $j > i$, $a^j$ is defined as $a^j_l \isectfa  a^j_r$ (both
%%%         $a^j_l$ and $a^j_r$ are boxes, i.e., FAs),
%%%       \item  in case any $a^j$ is $\emptyset$, we set $\edgesymb = \emptyset$.
%%%     \end{enumerate}


%------------------------------------------------------------------------------
%\paragraph{Component decompositions.}
\vspace*{-1mm}\paragraph{Compatibility of forest automata.}
For a forest automaton $\fa = \tuple{\tas,\valuation}$, its version with marked components 
is the FA 
$\decof\fa = \tuple{\tas,\valuation\cup\valuation_\rootvar}$ 
where
$\valuation_\rootvar$ is the mapping $\{\rootvar_1\mapsto
1,\ldots,\rootvar_n\mapsto n\}$.
%
% $\rootvar_i$'s are fresh \emph{root variables} 
%
%\tomas{Stress even more that the root variables point explicitly to each root.
%Stress that this is meaningful when the roots need not be cut-points? I was
%quite confused here for a while---I just hope it is for the case of having
%non-cut-point roots.} \lukas{hm, maybe it is}
%
The \emph{root variables} $\rootvar_i$ are fresh variables that
point to the roots of the tree components in $\langof{\fa}$. 
%
$\semof{\decof\fa}$ then contains the same heaps as $\semof\fa$, but the
roots of the components from $\langof{\fa}$ remain visible as they are explicitly marked by the root variables.
%
In other words, the root variables track how the forest decomposition of heaps
in $\langof{\fa}$ partitions the heaps from~$\semof{\fa}$. 
%
By removing the root variables of $\decof\heap\in\semof{\decof\fa}$, we get the
original heap $\heap\in\semof\fa$. We call $\decof\heap$ the \emph{component
decomposition of $\heap$ by $\fa$}.
%The elements from $\semcompof{\fa}$ are called \emph{component decompositions}.
%
%For a~set~$S$ of component decompositions, we can come back to the standard semantics
%by removing the root variables, which is denoted by~$\semofcd{S}$.
%
%We say that two forest automata~$\fa$ and~$\fa'$ are \emph{component-compatible} iff
%$\semof{\fa}\cap\semof{\fa'} = \semofcd{\semcompof\fa\cap\semcompof{\fa'}}$.
%
%Intuitively, it means that the heaps in the semantic intersection have the same
%sub-heaps encoded by the components of the FAs at the same
%positions.

%\paragraph{Representation compatibility.}


%!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
\enlargethispage{5mm}
%!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

Using the notion of component decomposition, we further introduce a notion of
the \emph{representation} of a~heap by an FA. Namely, the \emph{representation}
of a~box-free heap~$\heap$ by an FA $\fa$ with $\heap\in\semof\fa$ records how
$\fa$ represents $\heap$, i.e., (i) how $\fa$ decomposes $\heap$ into
components, and (ii) how its sub-graphs enclosed in boxes are represented by the
boxes. 
%
Formally, the representation of $\heap$ by $\fa$ is a pair $\repre =
(\decof\heap,\{\repre_1,\ldots,\repre_n\})$ such that $\decof\heap$ is the
component decomposition of $\heap$ by $\fa$, and $\repre_1,\ldots,\repre_n$ are
obtained from the sequence of unfoldings\vspace*{-0.5mm}
%
\begin{equation*} \heap_0\unfoldofi{1} \heap_1 \unfoldofi{2}  \cdots
\unfoldofi{n} \heap_n \end{equation*}
%
with $\heap_0 = \decof\heap$ and $\heap_n\in\langof{\decof{\fa}}$, such that for
each $1\leq i\leq n$, $\repre_i$ is (recursively) the representation of $g_i$ in
$\botox_i$.

We write $\semof\repre$ to denote $\{\heap\}$, and,
%
for a set of representations~$\repres$, we let $\semof\repres =
\ourbigcup_{\repre\in\repres} \semof{\repre}$.
% \{\semof\dec\mid\dec\in\decs\}$.
%
The set of \emph{representations accepted by a forest automaton} $\fa$
is the set $\represof\fa$ of all representations of heaps from
$\semof\fa$ by $\fa$. 
%
We say that a~pair of FAs $\fa$ and $\fa'$ is \emph{(representation) compatible} iff $\semof \fa \cap
\semof {\fa'} = \semof{\represof \fa \cap \represof{\fa'}}$.
%
The compatibility of a~pair of FAs intuitively means that for every heap from the semantic intersection of the two FAs,
at least one of its representations is shared by them.
%

\begin{lemma}
  %
  % Suppose $\fa_L$ and $\fa_R$ is a~pair of box-compatible FAs. Then
  % $\semof{\fa_L \isectfa \fa_R} = \semof{\fa_L} \cap \semof{\fa_R}$.
  %
  For a pair $\fa$ and $\fa'$ of compatible FAs,
  it holds that
  $\semof{\fa \isectfa \fa'} = \semof{\fa} \cap \semof{\fa'}$.
\end{lemma}

%\begin{proof}
%Left as an exercise for the kind reader.
%(Please send the solution to the address of the authors if you manage.)
%\qed
%\end{proof}

%
% OLD SECTION
%
% \subsubsection{Intersection of compatible forest automata.}
% Forest compatibility can be used to implement computation of semantic intersection of forest automata
% by reduction to the problem of computing intersection of symbolic tree automata over effective Boolean algebra over $\Data\cup\abcd\cup\boxes$  \cite{veanes}.   
% %
% Given two forest automata $\fa= \tuple{\tas,\valuation}$ and $\fa' = \tuple{\tas',\valuation}$ 
% (with the same valuation and the same number of components) 
% it returns the forest automaton 
% $\fa\syminter\fa' = \tuple{\ta_1\syminter\ta_1,\ldots,\ta_n\syminter\ta_n,\valuation}$.
% The tree automaton $\ta_i\syminter\ta_i'$ is computed as the intersection of symbolic tree automata over the effective Boolean algebra over $\Data\cup\abcd\cup\boxes$. 
% To implement the intersection computation, it implements conjunction of boxes using $\syminter$ over forest automata.
% Notice that since the hierarchy of boxes in forest automata form a strict hierarchy, the depth of recursion is bounded and the algorithm terminates. 
%
% \begin{lemma}
% If $\fa$ and $\fa'$ are forest compatible, then 
% $\semof{\fa_1}\cap\semof{\fa_2} = \semof{\fa\syminter\fa'}$. 
% \end{lemma}
% \footnote{
% We note that intersection of box compatible automata can be also computed, by a similar algorithm,
% but the forest automata operator does normalisation of both automata and then computes the union of $\syminter$ between all pairs $\fa$, $\fa''$ where $\fa''$ arises from $\fa'$ by permutation of tree components that are not referenced by variables. This note is probably useless, right ...
% }
% \footnote{
% By the way, entialment checking of two folding equivalent forest automata can be probably done exactly by the symbolic automata algorithm that uses intersection and itself too on the symbolic labels too.
% But this is not crucial for this paper.
% }


%*******************************************************************************
\vspace{-2.0mm}
\section{Implementation of the Forward Run}\label{sec:fwd_run}
\vspace{-1.0mm}
%*******************************************************************************
%The main goal of this section is to describe the operations that are used to
%implement the forward symbolic execution over FAs. However, before that, we need
%to introduce one more notion that will subsequently allow us to implement the
%backward execution by inverting the operations used in the forward execution.
%%
%In particular, apart from the already introduced box compatibility, we need to
%introduce a further notion of component compatibility.
%%
%It is defined as follows.

This section describes the operations that are used to
implement the forward symbolic execution over FAs. 
%
%It is defined as follows.
%
%
% Namely, to be able to invert the operations used in a~forward run $\fwrun =
% \sconf_0\sop_1\cdots\sop_n\sconf_n$ (i.e., to compute the localized weakest
% preconditions over the run) and to compute an interpolant~$\interp_i$ of
% a~spurious run, which we need for refinement, we will require the backward run
% $\bwrun = \bwsconf_0 \cdots \bwsconf_n$ to compute $\bwsconf_j$ that is both
% box-compatible and component-compatible with $\sconf_j$ for every $i\leq j\leq
% n$.
%
% Box compatibility is important for the operation of intersection to be
% semantically precise, as discussed in Section~\ref{sec:intersection}, and also
% as a~prerequisite of component compatibility. Component compatibility is needed
% to invert the operations used in the forward run.
%
%\paragraph{Component decomposition.}
%For a forest automaton $\fa = \tuple{\tas,\valuation}$, its \emph{component
%semantics} is
%$\semcompof{\fa}=\semof{\tuple{\tas,\valuation\cup\valuation_\rootvar}}$ where
%$\valuation_\rootvar$ is the mapping $\{\rootvar_1\mapsto
%1,\ldots,\rootvar_n\mapsto n\}$.
%%
%% $\rootvar_i$'s are fresh \emph{root variables} 
%%
%%\tomas{Stress even more that the root variables point explicitly to each root.
%%Stress that this is meaningful when the roots need not be cut-points? I was
%%quite confused here for a while---I just hope it is for the case of having
%%non-cut-point roots.} \lukas{hm, maybe it is}
%%
%Here, the \emph{root variables} $\rootvar_i$ are fresh variables that are set to
%point to the roots of the tree components in $\langof{\fa}$. 
%%
%Then, $\semcompof{\fa}$ contains the same heaps as $\semof\fa$ but with the
%roots of the components from $\langof{\fa}$ explicitly marked by the root
%variables.
%%
%In other words, the root variables track how the forest decomposition of heaps
%in $\langof{\fa}$ partitions the heaps from~$\semof{\fa}$. 
%%
%The elements from $\semcompof{\fa}$ are called \emph{component decompositions}.
%%
%For a~set~$S$ of component decompositions, we can come back to the standard semantics
%by removing the root variables, which is denoted by~$\semofcd{S}$.
%%
%We say that two forest automata~$\fa$ and~$\fa'$ are \emph{component-compatible} iff
%$\semof{\fa}\cap\semof{\fa'} = \semofcd{\semcompof\fa\cap\semcompof{\fa'}}$.
%%
%Intuitively, it means that the heaps in the semantic intersection have the same
%sub-heaps encoded by the components of the FAs at the same
%positions.
%
To be able to implement the backward run, we will need to maintain
compatibility between the forward run and the so-far constructed part
of the backward run.
%
Therefore, we will present the operations used in the forward run mainly from
the point of view of their effect on the representation  of heaps (in the sense
of Section~\ref{sec:intersection}).
%
Then, in Section~\ref{sec:bwd_run}, we will show how this effect is inverted in
the backward run such that, when starting from compatible
configurations, the inverted operations preserve compatibility of the
configurations in the backward run with their forward run counterparts.

% we get to compatible configurations again, and
% hence compatibility is preserved in the backward run.


%Now, we are finally ready to describe the operations used in the forward run.
%We are now ready to describe the operations used in the forward run.
%
We omit most details of the way the operations are implemented on the level of manipulations with rules and states of FAs. 
%We mostly omit their detailed implementation on the level of manipulations with
%rules and states of FAs. 
%since it is not important for this paper; instead,
%we refer the reader to~\cite{forester12,jiridiza} for details.
We refer the reader to~\cite{forester12,jiridiza} for the details.
%
We note that when we talk about removing a~component or inserting a component
in an FA, this also includes renaming references and updating
assignments of variables.
%
When a component is inserted at position~$i$, all references to~$\rr j$ with
$j>i$ are replaced by~$\rr{i+1}$, including the assignment~$\asgn$ of variables.
%
When a~component is removed from position~$i$, all references to $\rr j$ with $j > i$ are
replaced by references to~$\rr{j-1}$. 


% To revert the operations, we will sometimes need to remember some operation
% from the forward run in the backward run.
% We make that information visible in a~form of a~parameter $\mathit{par}$ of the
% operation, which will be in the form $\sop[\mathit{par}]$.

%which are generalization that consists of regular abstraction, normalization, and folding, 
%and operations that implement program statements.

%
%To explain the computation of localized preconditions while preserving the forest compatibility invariant,
%we will present the operations divided into smaller instructions,
%which affect forest compatibility.
%
%In the previous section we describe it on level of forest automata languages.
%To enable predicate learning described in the previous section we need to perform
%a backward run on level of compatible forest decomposition represented by automata
%from the forward and backward run.
%Therefore we provide with more detailed description of what happens in forward run
%with FA. The we will describe how we revert the operations from forward run in backward run.

%------------------------------------------------------------------------------
\paragraph{Splitting.}
Splitting has already been discussed in Section~\ref{sec:analysis}.
It splits the symbolic execution into several branches such that the union of
the FAs after the split is semantically equal to the original~FA.
%
The split is usually performed when transforming an~FA into several FAs that
have only one variant of a~root rule of some of their components.
%
From the point of view of a~single branch of the ART,
splitting is an operation, denoted further as $\splitting$, that transforms an
FA $\fa$
into an FA~$\fa'$ s.t. $\semof{\fa'}\subseteq\semof\fa$ and 
$\represof{\fa'}\subseteq\represof\fa$.
Therefore, $\fa$ is compatible with~$\fa'$.

%------------------------------------------------------------------------------
%\paragraph{Operations Modifying Component Semantics}
\paragraph{Operations modifying component decomposition.}
This class of operations is used to implement transformation of FAs to the dense form and as
pre-processing steps before the operations of folding, unfolding, and symbolic
implementation of program statements.
%
They do not modify the semantics of forest automata, 
but change the component decomposition of the represented heaps.
%Folding and unfolding of boxes and implementations of program commands need preprocessing of the forest automata so that their component semantics satisfies certain properties. The preprocessing is done by a set of operations that modify the component semantics, while not modifying the box semantics.
%
\begin{itemize}
%\item[\emph{Component Removal.}]
%Removing the $i$th component requires also replacing all references to $j$th components for $j>i$ by references to $j-1$th component, in the languages of the tree automata as well as in the valuation of variables.
%Removing appear in a forward run as $\removing{i}$.
%Normalization does not change forest automata semantically, 
%but affects the component decomposition of their heaps.
%

%Splitting is done when an operation such as $\code{x = y\text{\texttt{->}}sel}$ is performed.
%Since a forest automaton can represent a set of heaps this operation could cause that
%their forest decomposition differ. E.g. consider a cyclic singly linked list
%of arbitrary length where \code{y} points to a head of list.
%Then the noted operation would result to (a) at least two tree components for
%length longer than one or (b) one tree component for list of length one.
%Forest automata are not capable of representation of such different heaps.
%Therefore we create (split) more copies of automaton, one for each possible tree decomposition.
%The symbolic execution is then split to the separated branches for particular
%forest automata and each branch continues independently.
% \item[\emph{Connecting of components.} ] 
\item \emph{Connecting of components.}
%\tomas{This name sounds extremely strange to me. Perhaps Connecting a Component?}
When the $j$-th component $\ta_j$ of a forest automaton $\fa$ accepts trees with false roots, 
then $\ta_j$ can be connected to the component that refers to it. 
%
Indeed, as such roots are not cut-points, 
a~reference $\rr j$ to them can appear only in a~single component, say $\ta_k$, 
and at most once in every tree from its language (because a~false root
can have at most one incoming edge). 
%
For simplicity, assume that $\ta_j$ has only one root state $q$ that does
not appear on the right-hand sides of rules. 
%
The connection is done by adding the states and rules of~$\ta_j$ to $\ta_k$, replacing the reference~$\rr j$ in the rules of $\ta_k$ by~$q$.
%From the language point of view, the trees of $\ta_j$ are thus 
%reference $\bar j$ 
%connected to roots of the trees of $\ta_i$.  
%
The $j$-th component is then removed from~$\fa$.
%
The previous sequence of actions is denoted as the operation $\connecting{j,k,q}$ below. 
%
%
%It is done by replacing the reference $\bar i$ at the right-hand side of a leaf rule by the root state $q$ of $\ta_i$.  
%The $i$th component is removed by $\removing{i}$.
%The connection then appears in the forward run
%as the operation $\connecting{q,i}$. 
%\lukas{state maybe not needed to remember}
% \item [\emph{Cutting of a component.}] 
\item \emph{Cutting of a component.}
Cutting divides a~component  with an index~$j$ into two. 
The part of the $j$-th component containing the root will accept tree prefixes
of the original trees, and the~new $k$-th component will accept their remaining
sub-trees.
%of them is accepting subtrees of the trees accepting by the original one, and the other one is accepting tree prefixes that have a reference to the sub-tree component at the place where the sub-tree was connected.  
The cutting is done at a state $q$ of $\ta_j$, which appears exactly once in
each run (the FA is first transformed to satisfy this). 
Occurrences of~$q$ at the right-hand sides of rules are replaced by the reference
$\rr k$ to the new component, and $q$ becomes the root state of the new
component. 
We denote this operation by $\cutting{j,k,q}$.
%The information about $q$ and $i$ together with the assumption about $q$ will allow us to revert it in the backward run. 
% \item [\emph{Swapping of components.}]
\item \emph{Swapping of components.}
  The operation $\swapping{j,k}$ swaps the
  $j$-th and the $k$-th component (and renames references and assignments
  accordingly). 
\end{itemize}

%%%%   \subsection{Normalization}
%%%%   Calling normalisation is important because (1) 
%%%%   it facilitates the entailment checking \cite{cav} used to detect the fixpoint of the symbolic execution, 
%%%%   (2) it merges tree automata components, keeping their number small, which is important for efficiency reasons, and 
%%%%   (3) it empowers regular abstraction, which has more opportunities to overapproximate if the heaps are decomposed to a small number of large components.   
%%%%   %On forest automata representations with less tree components, because it is applied to tree components in isolation, and having larger pieces of configurations within a single component gives it more opportunities to overapproximate.
%%%%   %
%%%%   A detailed description of normalization can be found in \cite{cav,jiri,martin}. 
%%%%   It can be implemented as a sequence of operations of three kinds:
%%%%   \begin{itemize}
%%%%   \item [\emph{Splitting.}] As discussed in Section~\ref{}, it splits the symbolic execution into several branches. 
%%%%   From a point of view of single branch/forward run, 
%%%%   it appears as an operation $\splitting$ which transforms a forest automaton $\fa$ into $\fa'$ such that, $\semof\fa'\subseteq\semof\fa$, 
%%%%   and which is box and component compatible with $\fa$ because splitting does not influence the decomposition and component semantics.
%%%%   %Normalization does not change forest automata semantically, 
%%%%   %but affects the component decomposition of their heaps.
%%%%   %
%%%%   
%%%%   %Splitting is done when an operation such as $\code{x = y\text{\texttt{->}}sel}$ is performed.
%%%%   %Since a forest automaton can represent a set of heaps this operation could cause that
%%%%   %their forest decomposition differ. E.g. consider a cyclic singly linked list
%%%%   %of arbitrary length where \code{y} points to a head of list.
%%%%   %Then the noted operation would result to (a) at least two tree components for
%%%%   %length longer than one or (b) one tree component for list of length one.
%%%%   %Forest automata are not capable of representation of such different heaps.
%%%%   %Therefore we create (split) more copies of automaton, one for each possible tree decomposition.
%%%%   %The symbolic execution is then split to the separated branches for particular
%%%%   %forest automata and each branch continues independently.
%%%%   \item[\emph{Connecting.}] 
%%%%   When the root of an $i$th component $\ta_i$ of a forest automaton $\fa$ does not semantically correspond to a cut-point, 
%%%%   then the component is merged with other components. 
%%%%   From the language point of view, 
%%%%   the trees from $\langof{\ta_i}$ are connected as sub-trees to trees accepted by the other components at their leaves with a reference to $i$th component. 
%%%%   %
%%%%   It is done by replacing the reference $\bar i$ at the right-hand side of a leaf rule by the root state $q$ of $\ta_i$.  
%%%%   The connection then appears in the forward run
%%%%   as the operation $\connecting{q,i}$. 
%%%%   \lukas{state maybe not needed to remember}
%%%%   %The information about $q$ and $i$ together with the assumption about $q$ will allow us to revert it in the backward run. 
%%%%   \item [\emph{Swapping.}] 
%%%%   Tree automata components are swapped to achieve canonic ordering. 
%%%%   The operation appears as $\swapping{i,j}$, 
%%%%   where $i,j$ are indices of the swapped components. 
%%%%   \end{itemize}

%------------------------------------------------------------------------------
\paragraph{Folding of boxes.}
The folding operation assumes that the concerned FA is first transformed into the form
$\fa = \tuple{\boxtas \ta_1' \cdots \ta_m',\asgn}$ by a sequence of splitting,
cutting, and swapping.
%
% where all trees of $\langof{\ta_\iport}$ and $\langof{\ta_\oport}$ are of depth~$1$. 
%
The tuple of TAs $\boxtas$ will then be folded into a new box $\botox$
with~$\ta_\iport$ as its input component and~$\ta_\oport$ as its output.
Moreover, the operation is given sets of selectors~$S_{\iport},
S_{\oport}$ of roots of components in~$\ta_\iport$ and~$\ta_\oport$ that are to
be folded into~$\botox$.
%
The box~$\botox =
\tuple{\boxtasin,\{\iport\mapsto 1,\oport\mapsto n\}}$
arises from~$\fa$ \-by taking\linebreak$\boxtas$
and by removing selectors that are not in $S_{\iport}$ and $S_{\oport}$
from root rules of $\ta_\iport$ and~$\ta_\oport$ to obtain $\ta_\iport^\botox$ and
$\ta_\oport^\botox$ respectively.
%, which results into $\ta_1'$ and $\ta_n$'. 
% Particularly, the roots of $\ta_\iport$ and $\ta_\oport$ are stripped from all
% successors but those 
% reached by selectors from sets $S_\iport$ and $S_\oport$ of selectors, respectively. 
%
%Intuitively, the box $\botox$ will enclose only selectors leading from its
%input and output ports that are from the two sets, the rest will be left outside
%the box.
%

Folding returns the forest automaton $\fa' = \tuple{\ta'_{\iport}
\ta'_{\oport} \ta'_1 \cdots \ta'_m, \asgn'}$ that arises from $\fa$ as follows.
All successors of the roots accepted in $\ta_\iport$ and $\ta_\oport$
reachable over selectors from $S_\iport$ and $S_\oport$
are removed in $\ta'_\iport$ and $\ta'_\oport$ respectively (since they are enclosed in~$\botox$).
The root of the trees of $\ta'_\iport$ gets an additional edge labelled by
$\botox$, leading to the reference $\rr n$ (the output port),
and the components $\ta_2 \cdots \ta_{n-1}$ are removed (since they are also enclosed in~$\botox$).
%
This operation is denoted as $\folding{n,S_{\iport},S_{\oport},\botox}$.
%
% $\fa' = \folding{n,S_{\iport},S_{\oport},\botox}(\fa)$ such that 
%$\semof{\fa'} = \semof{\fa}$
%For every $\heap'\in\langof{\fa'}$, 
%there is $\heap\in\langof\fa$ 
%such that $\heap'\unfoldof{(u,\botox,v)}{blah}\heap$,
%$u$ is the $i$-th root in the forest decomposition of $\heap$ accepted by $\fa$
%and also the $j$-th root in the forest decomposition of $\heap'$ accepted by $\fa'$.
%Algorithms for learning boxes and folding are described in \cite{}.
%%%

%------------------------------------------------------------------------------
\paragraph{Unfolding of boxes.} 
Unfolding is called as a preprocessing step before operations that implement
program statements
in order to expose the selectors accessed by the statement. 
It is called after a sequence of cutting, splitting, and swapping
that changes the forest automaton into the form 
$\fa' = \tuple{\ta_\iport'\ta_\oport'\ta_1'\cdots\ta_m',\asgn'}$ where
%
% all trees of $\langof{\ta_\iport'}$ and $\langof{\ta_\oport'}$, are of
% depth~$1$, and
%
trees of $\ta'_\iport$ have a~reference $\overline 2$ to $\ta_\oport'$ accessible by an 
edge going from the root and labelled by the box~$\botox$ that is to be unfolded.
%
Furthermore, assume that the box $\botox$ is of the form
$\tuple{\boxtasin,\{\iport\mapsto 1,\oport\mapsto n\}}$
%
and 
%
the input and the output ports have outgoing selectors from the sets 
$S_\iport$ and $S_\oport$ respectively. 
%
The operation returns the forest automaton 
$\fa$ that arises from~$\fa'$ by 
%$\tuple{\ta_\iport'',\tas,\ta_\oport'',\{\iport\mapsto 1,\oport\mapsto n+1\}}$
%
inserting components $\boxtasin$ in between $\ta'_\iport$ and $\ta'_\oport$, 
removing the $\botox$ successor of the root in~$\ta_\iport'$,
merging $\ta_\iport^\botox$ with $\ta_\iport'$, and $\ta_\oport^\botox$
with $\ta_\oport'$.
% The merging on the language level consists of merging roots of the trees.
The merging on the TA level consists of merging root transitions of the TAs.
%
We denote this operation as $\unfolding{n,S_{\iport},S_{\oport},\botox}$.

%It is an operation $\unfolding{i,j,\botox}$ which for a given $\fa$ 
%returns a forest automaton $\fa' = \unfolding{i,j,\botox}(\fa)$ such that 
%$\semof{\fa'} = \semof{\fa}$. 
%For every $\heap'\in\langof{\fa'}$,
%there is $\heap\in\langof\fa$ such that $\heap\unfoldof{(u,\botox,v)}{blah}\heap'$,
%$u$ is the $i$-th root in the forest decomposition of $\heap$ accepted by $\fa$
%and also the $j$-th root in the forest decomposition of $\heap'$ accepted by $\fa'$.
%See \cite{jiri,cav} for details on unfolding.
%
%Before the unfolding is called, 
%the box to be unfolded must appear on an edge leading from the root of some of its tree components. 
%This is done by a sequence of splitting? and cutting. 

%Algorithms for learning boxes and folding are described in \cite{}.
%They can be implemented on the level of operations as follows. 
%By a sequence of splitting, cutting, and swapping, 
%the forest $\fa$ is first transformed into a form
%$\tuple{\tas,\ta_1',\ldots,\ta_m',\valuation}$ where $\ta'_1$ and $\ta_m'$ have only one root rule. 
%%
%The box $\botox$ to be folded is then made from
%$\tuple{\ta_1',\ldots,\ta_m',\{\iport\mapsto 1,\oport\mapsto m\}}$. 
%Particularly, the root rule $\vec a(\vec q)$ of $\ta_1'$ is modified
%by removing certain positions $P_1$ from the vectors $\bar a$ and $\bar q$, 
%and similarly for some positions $P_m$ of the root rule of the automaton $\ta_m$. 
%(the box will hide certain selectors on the positions from $P_1$ of its input node, and certain selectors at $P_m$ of its output node).
%%
%The operation returns the forest automaton 
%$\tuple{\tas,\ta_1',\ldots,\ta_m',\valuation}$ by
%removing removing all positions but those from $P_1$ from the root rule of $\ta_1'$ and then appending symbol $B$ to the vector of symbols 
%and a reference to the vector of states $\ta_m'$.
%Removing removing all positions but those from $P_m$ from the root rule of $\ta_m'$,
%and removing components $\ta_2'$ to $\ta_{m-1}'$.
%%
%This operation appears in forward run as $\folding{n,P_1,P_m,\botox}$.
%
%The swapping and splitting was described within normalisation. 
%Cutting splits a tree automata component into two, one of them is accepting subtrees of the trees accepting by the original one, and the other one is accepting tree prefixes that have a reference to the sub-tree component at the place where the sub-tree was connected.  
%Cutting then appears as the symbolic operation $\cutting{i,j}$ where $i$ is the index of the prefix component and $j$ is the index of the sub-tree component. 

%requires the input of the folded graph be a root in the forest decomposition of the forest automaton.
%To achieve this,
%it must be sometimes  preceded by the operation of \emph{cutting}.
%It is an operation $\cutting{i}$ which cuts the $i$th tree component into two halves, from which the root half stays at the $i$th position and the bottom half is appended at the end of the list of the components.

%------------------------------------------------------------------------------
\paragraph{Symbolic execution of program statements.}
We will now discuss our symbolic implementation of the most essential statements
of a C-like programming language. 
%They are 
%$\code{x = malloc()}$, 
%$\code{x = y\text{\texttt{->}}sel}$,
%$\code{y\text{\texttt{->}}sel = x}$,
%$\code{y \datarel x}$,
%$\code{x = y}$ or $\code{x = NULL}$, and
%$\code{free(y)}$.
%%
%Symbolic implementations of the statements use four operations. 
%%
%We use $\xroot$ and $\yroot$ to denote
%		the root states of $\xta$ and $\yta$, respectively. 	    
%
%
%The commands always access only selectors of nodes pointed to by variables.
%These are either exposed in root rules of the tree automata of the variable, in which case folding is not needed, or folded within a box. It is either a box in the root rule of $\valuation(x)$ or it may be a box
%within leaf rule which ends by a reference to the $\valuation(x)$. 
%In the latter case, 
%the occurrence of the box is first isolated into a separate tree component which contains the only the rule with the box. 
%
%It is unfolding, 
%which is to extract selectors of memory cells accessed by the statement from boxes, 
%then splitting, which is is necessary to keep the forest automata well define (??) 
%due to forest automata not being closed under union,
%and cutting.
%After preprocessing by unfolding and splitting and cutting, which have no semantic effect,
%the transformation changing the semantics is finally applied.
%We discuss the three in a more detail.
%
%
%Therefore we create (split) more copies of automaton, one for each possible tree decomposition.
%The symbolic execution is then split to the separated branches for particular
%forest automata and each branch continues independently.
%
%\paragraph{Abstract statement}
%
We assume that the operations are applied on an FA~$\fa = \tuple{\tas,\valuation}$.
		\begin{itemize}
		   \item $\code{x := malloc()}$: A new $(n+1)$-th component 
		  $\ta_{\mathit{new}}$ is appended to $\fa$ s.t. it contains one state and one transition with all
		  selector values set to $\asgnof \undef$.
      The assignment~$\asgnof{\code{x}}$ is set to $\rr{n+1}$. 
		  %The operation basically adds one node $v$ to heaps from
		  %language of $\fa$ and sets $\asgnheapof{\code{x}}$ to $v$ for each heap $h$.

		  \item $\code{x := y\text{\texttt{->}}sel}$ and $\code{y\text{\texttt{->}}sel := x}$:
		% If $\valuationof{\code y} = \valuationof\undef$, then $\code{x = y\text{\texttt{->}}sel}$ moves to the error location.
		If $\valuationof{\code y} = \valuationof\undef$, the operation moves to the error location.
        Otherwise, by splitting, cutting, and unfolding, $\fa$ is transformed into the
        form where $\ta_{\asgnof{\code{y}}}$ has only one root rule and the rule
        has a $\code{sel}$-successor that is a~root reference $\rr j$. 
        The statement
$\code{x := y\text{\texttt{->}}sel}$ then changes $\valuationof{\code{x}}$ to $\rr j$, and
$\code{y\text{\texttt{->}}sel := x}$ changes the reference $\rr j$ in $\ta_{\asgnof{\code y}}$ to $\valuationof{\code x}$.

%$ \cval$We then only 
%          If $q_i$ is a root reference (say,
%		  $j$), it is sufficient to change the value of $\valuation(\code{x})$ to $j$.
%		  Otherwise, we split $\yta$ at the $i$-th position (creating $\ta_k$) and assign $k$ %to
%		  $\valuation(\code{x})$. This operation does not change language of a forest automaton
%		  but it can change forest decompositions of heaps. This is caused by possibility of
%		  creating a new cutpoint by redirection of variable $\code{x}$.

%		  \item[$\code{y\text{\texttt{->}}sel = x}$] 
%If $q_i$ is a state, then we split
%		  $\yta$ at the $i$-th position. Then we put a reference to ${\valuation(\code{x})}$ to the
%		  $i$-th position in the right-hand side of the root transition of $\yta$; this
%		  is done both if $q_i$ is a state and if $q_i$ is a root reference. The operation
%		  changes heaps from language of FA by redirecting the edges corresponding to
%		  the $\code{sel}$ selector.

      \item $\code{assume(x \datarel y)}$ where $\datarel\ \in \{\code{==},
        \code{{!}{=}}\}$:
        This statement tests the equality of $\valuation(\code{x})$ and $\valuation(\code{y})$
        and stops the current branch of the forward run if the result does not match $\datarel$.
      \item $\code{assume(x\text{\texttt{->}}data \datarel y\text{\texttt{->}}data)}$
        where $\datarel$ is some data comparison:
        We start by unfolding and splitting $\fa$ into the form where
        $\ta_{\valuation(\code{x})}$ and $\ta_{\valuation(\code{y})}$ have only
        one root rule with exposed $\code{data}$ selector.
        The data values at the $\code{data}$ selectors are then compared and
        the current branch of the forward run is stopped if they do not satisfy~$\datarel$.
        The operation moves to the error locations if $\asgnof{\code x}$ or
        $\asgnof{\code x}$ are equal to~$\asgnof \undef$.
% \lukas{in the initial conf, everybody is defined and has the same value as undef, except null}
%with $\datarel$ and the forward run is stopped if the test returns false.  

%The is implemented by splitting the $\fa$ into all variants such that in each of them, both $\ta_\valuation{\code{x}}$ and  
%$\ta_\valuation{\code{y}}$ have a unique root rule and then removing the variants where the 
%		  Assume that both states are data ones.
%		  If $data_y \datarel data_x$ holds (or does not hold), we return \emph{true} (or \emph{false}).
%		  Otherwise, we copy $\tuple{\valuation, \fa}$ into two abstract configurations:
%		  $\tuple{\valuation, \fa_{\mathit{true}}}$ for the $\emph{true}$ branch and
%		  $\tuple{\valuation, \fa_{\mathit{false}}}$ for the $\emph{false}$ branch
%		  and continue from each branch separately. Operation does not change language of FA
%		  neither accepted forest decomposition.

		  \item $\code{free(x)}$: The component $\ta_{\asgnof{\code{x}}}$ is removed, 
          and all references to $\asgnof{\code{x}}$ are replaced by~$\asgnof \undef$.
%First, we split $\yta$ at all $j$-th positions, $1 \leq j
%		  \leq m$, that appear in its root transition, then we remove $\yta$ from $\fa$
%		  and set $\valuation(\code{y})$ to undefined. In language of FA, the change is reflected
%		  by elimination of node $\asgnheapof{\code{x}}$.
		\end{itemize}

\noindent
The updates are followed by checking that all components are reachable from
program variables in order to detect garbage.
If some component is not reachable, the execution either moves to the
error location, or---if the analysis is set to ignore memory leaks---removes the
unreachable component and continues with the execution.

%------------------------------------------------------------------------------
\paragraph{Regular Abstraction.} 
%Regular abstraction is implemented as one of the abstractions described in
%Section~\ref{sec:abstraction}, which over-approximate the language of the
%individual components.
%It is preceded by a~transformation to the dense form 
%by connecting and splitting the FA.

Regular abstraction is described in
Section~\ref{sec:abstraction}.
It is preceded by a~transformation to the dense form 
by connecting and splitting the FA.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\vspace{-2.0mm}
\section{Inverting Operations in the Backward Run}\label{sec:bwd_run}
\vspace{-1.0mm}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

We now present how we compute the weakest localized preconditions (\emph{inversions} for short) of the operations from Section~\ref{sec:fwd_run} in the backward run.
As mentioned in  Section~\ref{sec:fwd_run}, 
it is crucial that compatibility with the forward run is preserved. 
Let $\sconf_i = \sop(\sconf_{i-1})$ appear in the forward run and
$\bwsconf_{i}$ be an already computed configuration in the backward run
s.t.~$\sconf_i$ and $\bwsconf_i$ are compatible.
We will describe how to compute $\bwsconf_{i-1}$ such that it is also
compatible with~$\sconf_{i-1}$.

Inverting most operations is straightforward.
The operation $\cutting{j,k,q}$ is inverted by $\connecting{k,j,q_k}$ where $q_k$ is the root state of $\ta_k$,
$\swapping{j,k}$ is inverted by $\swapping{k,j}$, and $\splitting$ is not inverted, i.e., $\bwsconf_{i-1} = \bwsconf_i$.

One of the more difficult cases is 
$\connecting{j,k,q}$. %$\bwsconf_{i-1}$ is computed as follows. 
Assume for simplicity that $k$ is the index of the last component of $\sconf_{i-1}$.
%
Connecting can be inverted by cutting, but prior to that, we need to find
\emph{where} the $k$-th component of $\bwsconf_i$ should be cut.
To find the right place for the cut, we will
use the fact that the places of connection are marked by the
state~$q$ in the FA $\sconf_i$ from the forward run.
%
We use the tree automata product $\isectta$ from
Section~\ref{sec:intersection}, which
propagates the information about occurrences of $q$ to $\bwsconf_{i}$,
to compute the product of the $k$-th
component of $\sconf_{i}$ and the $k$-th component of~$\bwsconf_i$.
%
We replace the $k$-th component of $\bwsconf_i$ by the product, 
which results in an intermediate FA~$\bwsconf_i'$.
%
The product states with the first component $q$ now mark the places where the forward run connected the components (they were leaves referring to the $k$-th component).
%
This is where the backward run will cut the components to revert the connecting. 
%
Before that, though, we replace the mentioned product states with $q$ by a new state~$q'$.
This replacement does not change the language because $q$ was appearing
exactly once in every run (because in the forward run, it is the root state of the connected component that does not appear on the right-hand sides of rules), therefore, 
a product state with $q$ can appear at most once in
every run of the product too.
%
Finally, we compute $\bwsconf_{i-1}$ as $\cutting{k,j,q'}(\bwsconf_i')$.

Folding is inverted by unfolding and vice versa. Namely, 
$\folding{n,S_{\iport},S_{\oport},\botox}$ is inverted by 
$\unfolding{n,S_{\iport},S_{\oport},\botox}$ and  
$\unfolding{n,S_{\iport},S_{\oport},\botox}$ is inverted by 
$\folding{n,S_{\iport},S_{\oport},\botox'}$ where the box $\botox'$ folded in
the backward run might be semantically smaller than $\botox$ (since the
backward run is returning with a subset of configurations of the forward run). 

Regular abstraction is inverted using the intersection construction from\ Section~\ref{sec:intersection}. 
That is, if $\sop_i$ is a~regular abstraction, 
then $\bwsconf_{i-1} = \bwsconf_{i} \isectfa\sconf_{i-1}$.

Inversions of abstract statements compute the FA $\bwsconf_{i-1} =
\tuple{\bar\ta'_1 \cdots \bar\ta'_n, \bar\asgn'}$
from~$\bwsconf_{i} = \tuple{\bar\ta_1 \cdots \bar\ta_m, \bar\asgn}$ and
$\sconf_{i-1} = \tuple{\ta_1 \cdots \ta_n, \asgn}$ as follows:
%
\vspace{-2.0mm}
\begin{itemize}
  \item $\code{x = malloc()}$: We obtain $\bwsconf_{i-1}$ from $\bwsconf_{i}$
    by removing the $j$-th TA, for $\bar\asgn(\code{x}) = \rr j$.
    The value of $\bar\asgn'(\code{x})$ is set to $\asgn(\code{x})$.
	%	The operation
	%	corresponds to removing a node added to heaps of $\fa$ in forward run.

  \item $\code{x := y\text{\texttt{->}}sel}$:
Inversion is done by setting $\bar\asgn'(\code{x})$ to the value of
$\asgn(\code{x})$ fr\-om~$\sconf_{i-1}$.
% is set to the value it has in $\sconf_{i-1}$.
%
%We remember a value $a$ of
%	  $\valuation(\code{x})$ before an execution of this instruction in forward run.
%		The value $a$ is assigned again to $\valuation(\code{x})$ in backward run.
%		The reversion of the operation could effect forest decomposition of accepted forest
%		since changing target of $\code{x}$ may lead to removing a cut-point from heaps of $\fa$.
%		Therefore it is necessary to merge which no longer represents a tree component.
%		After merging we should obtain an FA from backward run with the
%		same number of tree automatao an FA from forward run has.

  \item $\code{y\text{\texttt{->}}sel := x}$:
The target of the $\code{sel}$-labelled edge from the root of
$\ta_{\bar\asgn'(\code{y})}$ is set to its target in $\ta_{\asgn(\code{y})}$.
%$\asgn{the value it has in $\sconf_{i-1}$. 
%A target of $i$-th of $\yroot$ selector is changed
%	  back to a state which it points before an execution of this operation in forward run.
%	  As in the previous case the revrsion of this operation can change forest decomposition
%	  of a heap and we may need perform merging tree automata.
% \item[$\code{y \datarel x}$ \rm{and} $\code{y\text{\texttt{->}}data \datarel x\text{\texttt{->}}data}$]
%$\bwsconf_{i-1} = \bwsconf_{i}$ because the test do not actually modify the configuration (they only stop some branches of the symbolic execution)
 \item $\code{assume(...)}$: Tests do not modify FAs and as we are returning with a~subset of configurations from the forward run, they do not need to be inverted,
 i.e., $\bwsconf_{i-1} =~\bwsconf_{i}$.
%, because it does not modify the FA. 
%(it only stops some branches of the symbolic execution)
  \item $\code{free(x)}$:
First, the component of $\sconf_{i-1}$ at the index $\asgnof{\code x}$, which was
removed in the forward run, is inserted at the same position in $\bwsconf_{i}$, and
$\bar\asgn'(\code{x})$ is set to that position.
%
Then we must invert the rewriting of root references pointing to $\asgn(\code{x})$ to $\asgnof{\undef}$ done by the forward run.
For this, we compute the $\isectta$ forest automata product from Section~\ref{sec:intersection} with $\sconf_{i-1}$, but modified so that 
instead of discarding reached pairs $(\asgnof\undef,\valuation(\code{x}))$, 
it replaces them by $\valuation(\code{x})$.
%
Intuitively, the references to $\code x$ are still present at $\sconf_{i-1}$,
so their occurrences in the product mark the occurrences of references to $\undef$ 
that were changed to point to $\undef$ by $\code{free(\code x)}$. The modified product therefore 
redirects  
the marked root references to $\undef$ back to $\code{x}$.

%.$ to mark which occurences of references to $\undef$ are those the were pointing to $\code{x}$.
%For this, at every position $j$ other than  $\valuation(\code{x})$, we replace the $j$-th component 
%by its product with the $j$-th component in $\sconf_{i-1}$. 
%(which has the original positions of references to $\valuation(\code{x})$). 
%In the product construction, we replace reachable pairs $(\asgnof\undef,\valuation(\code{x}))$ by $\valuation(\code{x})$ instead of discarding them.  
%%
%by a tree automata product construction, we identify places
%We take the TA removed by this transformer in the forward
%	  run and return it to the correct position in $\yta$. Then we perform an
%	  intersection of FA from forward and backward run to match which $\undef$
%	  should be changed back to a reference to the renewed TA.
%	  A reversion of the operation returns to heaps parts represented by
%	  freed TA.
%	  \comment[mh]{Maybe, describe how undefs in FA from backward run are matched
%	  with references in FA from forward run. However everything is already very imprecise
%	  so one more simplification cannot be harmful.}
\end{itemize}

\vspace{-5.0mm}
%------------------------------------------------------------------------------
\paragraph{The role of compatibility in the backward run.}
Inversions of regular abstraction, component connection, and $\code{free(x)}$, use the TA product construction~$\isectta$ from Section~\ref{sec:intersection}.
%
The precision of all intersection and product computations in the backward run
depends on the compatibility of the backward and forward run.
%
Inverting the program statements also depends on the compatibility of the backward and forward run. 
Particularly, inversions of $\code{x := y\text{\texttt{->}}sel}$ and
$\code{y\text{\texttt{->}}sel := x}$ use indices of components from $\sconf_{i-1}$. They therefore
depend on the property that heaps from $\bwsconf_{i}$ are decomposed into components in the same way.
%
%The inversion of $\code{free(x)}$ depends on compatibility as well because the product
%construction used to mark references to $\asgnof \undef$ that should be pointing to~$\asgnof{\code x}$ is
%computed component-wise.
%\lukas{well, why?}. 
%
The compatibility is achieved by inverting every step of folding and unfolding,
and every operation of connecting, cutting, and swapping of components.


%%% \textbf{OLD STUFF}

%Let us now describe the notion of abstract transformers from the set~$\abstransfs$ formally.
%An abstract transformer~$\abstrans$ is a~function $\abstrans: \fas \to 2^\fas$.
%The reason why the result of $\abstransof \fa$ is, in general, a~set of FAs
% instead of a~single FA, is that FAs are not closed under union~\cite{forester12}.
%\td{OL: blah}
%\td{OL: maybe we want to say that abstract transformers are precise}
%Abstract transfomers model semantics of concrete program operations.
%They transform forest automata during a symbolic execution in the same way
%as related concrete program operations transform a graph.
%The function $\concrop{st}$ is related to an operation \texttt{op} of the analysed program.
%This function models semantics of \texttt{op} in the concrete domain in such way that $\concrop{st}$
%transforms an io-graph representing the heap configuration before and after the execution of
%the concrete operation \texttt{op}.
%The abstract transformers $\tau_{\texttt{op}}$ are defined for each concrete
%operation \texttt{op} reflecting the semantics of~$\concrop{st}$.
%They transform a FA $S$ representing the heap in abstract domain to a resulting FA $S' = \tau_{\texttt{op}}(S)$
%such that $\bigcup_{F' \in S'} \llbracket F' \rrbracket = \{\concrop{sf} \mid g_{sf} \in \llbracket F \rrbracket \wedge F \in S~\}$.
%%The abstract transformer is applied separately to each forest $F \in S$.
%
%\td{OL: verbatim from ACTA-data}
%For each operation $\code{op}$ in the intermediate representation of the
%analysed program corresponding to the function $f_{\code{op}}$ on concrete
%configurations $\tuple{\valuation, \heap}$, we define an abstract transformer
%$\abstrans$ on abstract configurations $\tuple{\valuation, \fa}$ such that the
%result of $\abstrans(\tuple{\valuation, \fa})$ denotes the set
%$\{f_{\code{op}}(\tuple{\valuation,\heap}) \mid \heap \in \langof{\fa} \}$.
%The abstract transformer $\abstrans$ is applied separately for each pair
%$\tuple{\valuation, \fa}$ in an abstract configuration. Note that all our
%abstract transformers $\abstrans$ are exact.

% TODO co je za problem bez splitu a jak to lze obejit? a jak to soucasny problem resi?
% TODO unfolding a folding jejich reverze (je nutna ke kompatibilite poctu komponent)
% TODO kompatibilita na urovni stromovych dekompozici (is implied by splitting)
% Below, we present the abstract transformers---the rest of
% the transformers is analogous. For simplicity
% of the presentation, we will use the following form of TAs.
% We assume that (a)~the root state of a TA does not appear
% on the right-hand side of any transition, and (b)~it occurs on
% the left-hand side of exactly one transition.
% 
% We introduce now some common notation and operations for the below
% presented transformers.  We use $\xta$ and $\yta$ to denote the TA pointed by variables
% $\code{x}$ and $\code{y}$, respectively, and $\xroot$ and $\yroot$ to denote
% the root states of these TAs. Let $\trans{\yroot}{q_1, \dots, q_i, \dots, q_m} :
% c$ be the unique transition from $\yroot$.  
%The operation of \emph{splitting} a TA $\yta$ at the $i$-th position, for $1 \leq i \leq m$, is described by the following sequence of operations:
% 
%\begin{enumerate}
%
%  \item First, a new TA $\ta_{k}$ is appended to $\fa$ such that $\ta_{k}$ is a~copy of $\yta$ but with $q_i$ as the root state.
%
%  \item Second, the root transition in $\yta$ is changed to $\trans{\yroot}{q_1,
%\dots, \overline{k}, \dots, q_m} : c'$ where $c'$ is obtained from $c$ by
%replacing any local constraint of the form $0 \datarel_{\code{r}x} i$ by the global
%constraint $\yroot \datarel_{\code{r}x} \rootof{\ta_{k}}$.  
%   \item Global data constraints are
% adapted as follows: For each constraint $q \datarel_{\code{r}x} p$ where $q$ is in
% $\yta$ such that $q \neq \yroot$, a~new constraint $q' \datarel_{\code{r}x} p$ is added,
% where $q'$ is the version of $q$ in $\ta_k$.
% Likewise, for each constraint $q \datarel_{\code{r}x} p$ where $p$ is in $\yta$ such
% that $p \neq \yroot$, a new constraint $q \datarel_{\code{r}x} p'$ is added (again, $p'$ is the version of $p$ in $\ta_k$). Finally, for
% each constraint of the form $p \datarel_{\code{ra}} \yroot$, a new constraint $p
% \datarel_{\code{ra}} \rootof{A_k}$ is added.
%\end{enumerate}
%An example of the splitting step is given in Example~\ref{ex:transformer} below.
% We assume that $\code{sel}$ is the $i$-th selector in a label and targets the state $q_i$.
% Before performing the actual update, we check whether the operation to be
% performed tries to dereference a~pointer to $\nullconst$ or to an undefined
% value, in which case we stop the analysis and report an error. Otherwise, we
% continue by performing one of the following actions, depending on the
% particular statement. %Let we show how to compute post abstract configuration $\tuple{\valuation^{\mathit{post}}, \fa^{\mathit{post}}}$
%for each statement from a previous configuration  $\tuple{\valuation^{\mathit{pre}}, \fa^{\mathit{pre}}}$. 
%for each statement from a previous configuration  $\code{preConf}$. The abstract transformer are shortly described as below: 
%The detail of abstract transformer for each statement is 
%described in Fig.~\ref{fig:AbstractTransfomer1}.In the figures, we show how to compute post abstract configuration $\code{postConf}$
%for each statement from a previous configuration  $\code{preConf}$. 

% i am not sure its nessesary to have this figure
%\begin{description}
% TODO: Vic high level popis, co se deje s grafem.
%   \item[$\code{x = malloc()}$] We extend $\fa$ with a new TA
%  $\ta_{\mathit{new}}$ containing one state and one transition where all
%  selector values are undefined and assign $\valuation(\code{x})$ to the index
%  of $\ta_{\mathit{new}}$ in $\fa$. % TODO: Add a node with everything undefined
%
%  \item[$\code{x = y\text{\texttt{->}}sel}$] If $q_i$ is a root reference (say,
%  $j$), it is sufficient to change the value of $\valuation(\code{x})$ to $j$.
%  Otherwise, we split $\yta$ at the $i$-th position (creating $\ta_k$) and assign $k$ to
%  $\valuation(\code{x})$. % 
%
%  \item[$\code{y\text{\texttt{->}}sel = x}$] If $q_i$ is a state, then we split
%  $\yta$ at the $i$-th position. Then we put a reference to ${\valuation(\code{x})}$ to the
%  $i$-th position in the right-hand side of the root transition of $\yta$; this
%  is done both if $q_i$ is a state and if $q_i$ is a root reference.
%
%  \item[$\code{y \datarel x}$] (where $\datarel\ \in \{<, \leq, ==, \geq, >\}$)
%  Assume that both states are data ones.
%  If $data_y \datarel data_x$ holds (or does not hold), we return \emph{true} (or \emph{false}).
%  Otherwise, we copy $\tuple{\valuation, \fa}$ into two abstract configurations:
%  $\tuple{\valuation, \fa_{\mathit{true}}}$ for the $\emph{true}$ branch and
%  $\tuple{\valuation, \fa_{\mathit{false}}}$ for the $\emph{false}$ branch
%  and continue from each branch separately. % Mergnout s poslednim
%
%  \item[$\code{x = y}$ or $\code{x = NULL}$] We simply update $\valuation$
%  accordingly.
%
%  \item[$\code{free(y)}$] First, we split $\yta$ at all $j$-th positions, $1 \leq j
%  \leq m$, that appear in its root transition, then we remove $\yta$ from $\fa$
%  and set $\valuation(\code{y})$ to undefined.
%
%  % \item[$\code{x\text{\texttt{->}}sel \neq NULL}$] We remove root transitions where $\code{NULL}$ appears in the target position of $\code{sel}$ in the right-hand side
%  
%  \end{description}
%%% 
%%% After the update, we check that all TAs in $\fa$ are
%%% referenced, either by a variable or from a root reference, otherwise we report
%%% an emergence of garbage. Once the garbage is reported we remove it from $\fa$
%%% and continue symbolic execution.
%%% 
%%% In backward run, splitting is not explicitly (with the exception of the unfolding step)
%%% reverted since it is sufficient to go back only with one of FA created by splitting
%%% to check spuriousness of counterexample. The unfolding is reverted by folding the box again.
%%% If a node of a represented graph is no longer a cut-point after the folding we perform
%%% a normalization of $\fa$ to synchronize number of TA in FA from backward and forward run.
%%% The described transformers are reverted in the following manner:
%%% 
%%% \vspace{2mm}
%%% 
%%% % {\color{white}
%%% % \begin{example}\label{example:2}
%%% % \end{example}}
%%% % \vspace{-12mm}
%%% \begin{figure}[ht]
%%% % \vspace{11mm}
%%% \[
%%% \begin{array}{l}
%%% \fa = \tuple{\ta_1\,\ta_2, \constr}\\
%%% \sigma(\code{root}) = 1, \sigma(\code{x}) = 2\\
%%% \ta_1: \left \{
%%% \begin{array}{ll}
%%%     \transover{\finalstate{q_\code{r}}}{\bstsym}{q_1,\rr{2}} &:  0 \succ_{\code{ra}} 1, 0 \prec_{\code{ra}} 2 \\
%%%     \transover{q_1}{\bstsym}{\nullconst,q_2} &:  0 \prec_{\code{ra}} 2\\
%%%     \transover{q_2}{\bstsym}{\nullconst,\nullconst}
%%% \end{array}
%%% \right.
%%% \vspace{1mm}
%%% \\
%%% \ta_2:
%%% \left\{
%%% \begin{array}{ll}
%%% \transover{\finalstate{q_\code{x}}}{\bstsym}{\nullconst,q_3} &: 0 \prec_{\code{ra}} 2 \\
%%% \transover{q_3}{\bstsym}{\nullconst,\nullconst} & \\
%%% \end{array}
%%% \right.
%%% \vspace{1mm}
%%% \\
%%% % \ta_3:
%%% % \begin{array}{ll}
%%% % 		\transover{\finalstate{q_\code{nN}}}{\bstsym}{\nullconst,\nullconst} \\
%%% % \end{array}\\
%%% \constr = \left\{
%%% \begin{array}{l}
%%%   q_\code{x} \succ_{\code{ra}} q_\code{r},
%%%   q_3 \succ_{\code{ra}} q_\code{r},\\
%%%   q_\code{r} \succ_{\code{ra}} q_\code{x},
%%%   q_1 \prec_{\code{ra}} q_\code{x},
%%%   q_2 \prec_{\code{ra}} q_\code{x}
%%% \end{array}
%%%   \right\}
%%% \end{array}
%%% \]
%%% \caption{An example of an abstract configuration that is a possible
%%% representation of the concrete configuration shown in
%%% Fig.~\ref{fig:bst-graph}(b).}
%%% \label{prog}
%%% \end{figure}
%%% 
%%% %-------------------------------------------------------------------------------
%%% \begin{example}%{Example~\ref{example:2}.}
%%% \lukas{Can this example be reused if we kick out data?}
%%% %-------------------------------------------------------------------------------
%%% % \begin{figure}[t]
%%% %   \begin{minipage}[b]{5.6cm}
%%% %     \vspace{-2mm}
%%% %     \input{figs/bst_forest_exp2.tex}
%%% %     \vspace{-1mm}
%%% %   \end{minipage} 
%%% %   \caption{An example of a single \emph{shape} configuration.}
%%% %   \label{fig:bst-configuration}
%%% % \end{figure}
%%% %
%%% Fig.~\ref{prog} illustrates an abstract configuration $\langle
%%% \sigma,\fa\rangle$ that is a possible representation of the concrete
%%% configuration $\langle \sigma,H\rangle$ shown in Fig.~\ref{fig:bst-graph}(b).
%%% \qed
%%% \end{example}
%%% 
%%% %We use $\finalstate{q}$ to denote that $q$ is a root state. 
%%% %The global constraint $q_\code{x} \succ_{\code{ra}} q_\code{nN}$ state that the data value of the node pointed by $\code{x}$ is larger than data values of all nodes in the tree $t_3$
%%% %A memory node referenced by $\code{newNode}$ is going to be added as the left child of the leaf referenced by $\code{x}$, which
%%% %is reachable from the root by the sequence of selectors
%%% %$\code{left}\cdot \code{right}$. The data values along the path from $\code{root}$ to $\code{x}$ must be in the proper relations with the data value of $%\code{newNode}$,in order for the tree to stay sorted also after the addition. The data
%%% %value of $\code{newNode}$ must be smaller than that of the root (i.e.,
%%% %$q_\code{r} \succ_{\code{ra}} q_\code{nN}$), larger than that of its left child (i.e.,
%%% %$q \prec_{\code{ra}} q_\code{nN}$), and smaller than that of $\code{x}$ (i.e.,
%%% %$q_\code{x} \succ_{\code{ra}} q_\code{nN}$). These relations and also
%%% %$q \prec_{\code{ra}} q_\code{x}$ have been accumulated during the tree traversal.
%%% 
%%% \medskip



%!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
\enlargethispage{4mm}
%!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!



%*******************************************************************************
\vspace{-3.0mm}
\section{Regular Abstractions over Forest Automata}\label{sec:abstraction}
\vspace{-1.0mm}
%*******************************************************************************

Now, we will formalize the notion of abstract regular model checking
and the related height and predicate language abstraction mentioned in
Section \ref{subsection:armc}.
%
Given a tree automaton $\ta=(Q, q_0, \Delta)$, its abstraction 
%
% TV: Why `using \alpha`? 
%
% using $\abstra$
%
is TA $\abstraof \ta =( Q/_{\eqrel},[q_0]_{\eqrel{}},\Delta_{\eqrel{}} )$
where $\eqrel$ is an equivalence relation on $Q$, $Q/_{\eqrel}$ is the set of
$\eqrel$'s equivalence classes, $[q_0]_{\eqrel{}}$ denotes the equivalence class
of $q_0$,  and $\Delta_{\eqrel{}}$ arises from $\Delta$ by replacing
occurrences of states in transitions by their equivalence classes.
%
%a function $\alpha: Q \rightarrow Q/_{\eqrel{\ta}}$ such that $\alpha(q) = \eqclass{q}{\ta}$
%where $\eqrel{\ta} \subseteq Q \times Q$ is an equivalence relation computed according to one of
%the principles dRfined below.
%By $\alpha(\ta)=( Q_{\eqrel{\ta}},[q_0]_{\eqrel{\ta}},\Delta_{\eqrel{\ta}} ) $, we denote
%the tree automaton obtained by applying $\alpha$ to~$\ta$.
%
%Using the equivalences defined by finite height or predicate abstraction, 
%defined below, it is guaranteed that 
It holds that $|Q/_{\eqrel}| \leq |Q|$ and
$\langof \ta \subseteq \langof{\abstra(\ta)}$.
%

\emph{Finite height abstraction} 
%The range of abstraction function is the set of the equivalence classes of the relation $\heqrel{\ta}$.
 is a function $\abstra_h$ that merges states 
 with languages equivalent
up to a~given tree height~$h$.
Formally, it merges states of~$\ta$ according to the equivalence relation $\heqrel{\ta}$ defined as follows:
$q_1 \heqrel{\ta} q_2 \defarrow \langlen{\ta}{q_1} = \langlen{\ta}{q_2}$ where
$\langlen{\ta}{q}$ is the language of tree prefixes of trees from of $L(\ta,q)$  
 up to the height $h$.
%
%
%In ARTMC, the symbolic execution usually starts with $n=1$, and in the case of
%detected spurious counterexample, the refinement is simply done by increasing the constant $n$. 
%However the refinement does not guarantee that the detected spurious counterexample will not
%be detected again in the next run.
%
\emph{Predicate language abstraction}
is a function $\predabstra \predset$ parametrized by a set of predicate languages $\predset=\{\pred_1, \ldots, \pred_n\}$
represented by tree automata.
%
States are merged according to the equivalence $q \peqrel q'$ which holds for the two states if
their languages $L(A,q)$ and $L(A,q')$ intersect with the same subset of predicate languages from $\predset$.
%
%that is, merging is done according to the equivalence $\peqrel$
%such that $q \peqrel q'$ if $P_q = P_{q'}$.
%The The abstraction labels a state $q\in Q$ of TA $A=(Q,q_0,\delta)$ by a subset $P_q \subseteq \predset$ of predicates languages that intersect $L(A,q)$.
%States are merged if they are labeled by the same subset of predicates, that is,
%according to the equivalence $\peqrel$
%such that $q \peqrel q'$ if $P_q = P_{q'}$.
%Formally, $\forall q_1,q_2 \in Q: q_1 \peqrel q_2 \defarrow
%(\forall \pred \in \predset: \langstate{A}{q_1} \cap \pred \neq \emptyset
%\Leftrightarrow \langstate{A}{q_2} \cap \pred \neq \emptyset)$.
%We use $\alpha[\predset]$ to denote the abstraction parametrized by the set of predicates
%$\predset$.


%$\mathcal{L}(\alpha[\predset'](F_i)) \cap \mathcal{L}(I_i) = \emptyset$---i.e. the abstraction will not
%The new set of predicates is defined as $\predset'=\predset \cup
%\{(Q,q,\Delta)
%\mid q\in Q\}$---i.e. taking the languages of all states of the automaton $I_i$.
%This technique guarantee that if  
%$\mathcal{L}(F_i) \cap \mathcal{L}(I_i) = \emptyset$ then 
%$\mathcal{L}(\alpha[\predset'](F_i)) \cap \mathcal{L}(I_i) = \emptyset$---i.e. the abstraction will not
%introduce any tree from the interpolant language and hence the source of the spurious
%counterexample is eliminated by the refinement.

%The symbolic execution usually starts with an~empty set $\predset$ and uses the CEGAR
%\cite{cegar}
%principle to learn new predicates. The new predicates are established based on the
%automaton $I_i=(Q,q_0,\Delta)$ representing the interpolant computed by the backward run (the situation is
%similar to the case of FA described in Sec \ref{sec:CEXanalysis}).
%The new set of predicates is defined as $\predset'=\predset \cup
%\{(Q,q,\Delta)
%\mid q\in Q\}$---i.e. taking the languages of all states of the automaton $I_i$.
%This technique guarantee that if  $\mathcal{L}(F_i) \cap \mathcal{L}(I_i) = \emptyset$ then 
%$\mathcal{L}(\alpha[\predset'](F_i)) \cap \mathcal{L}(I_i) = \emptyset$---i.e. the abstraction will not
%introduce any tree from the interpolant language and hence the source of the spurious
%counterexample is eliminated by the refinement.


\vspace{-1mm}
%------------------------------------------------------------------------------
\paragraph{Abstraction on forest automata.}
We extend the abstractions from ARTMC to FAs by applying the abstraction over TAs to the components of the FAs.
%in a component-wise way.
%This means that the abstraction is applied to each tree automaton of
%FA in the current symbolic state separately.
Formally, let $\abstra$ be a tree automata abstraction.
For an FA $\fa =\tuple{\tas, \valuation}$,
we define $\abstraof \fa = \tuple{\abstraof{\ta_1}\cdots\abstraof{A_n},\asgn}$. 
%
Additionally, in the case of predicate abstraction,
which uses automata intersection to annotate states by predicate languages,
we use the intersection operator $\isectfa$ from Section~\ref{sec:intersection},
which descends recursively into boxes, and it is thus more precise from the point
of view of the semantics of FAs.
%
%The states are merged only in one tree automaton and not across the different
%tree automata of FA using the proposed 
%method.\footnote{However, merging the states of different tree automata can be more
%efficient.} 
Since the abstraction only over-approximates languages of the individual components,
it holds that 
$\semof{\fa}\subseteq\semof{\abstraof \fa}$
%$\langof{\fa}\subseteq\langof{\abstraof \fa}$, and
% $\decsof{\fa}\subseteq\decsof{\abstraof \fa}$, and
% $\semcompof{\fa}\subseteq\semcompof{\abstraof \fa }$
and
$\represof{\fa}\subseteq\represof{\abstraof \fa }$---and so $\fa$ and $\abstraof \fa$ are compatible. 
%
%, and
%Note that $\sigma$ is not changed, neither  order of
%the forests and a~set of used boxes, hence $\semof{F_1}\subseteq\semof{\alpha(F_1)}$ and
%the FA $F_1$ and $\alpha(F_1)$ are forest compatible.

\vspace{-1mm}
%------------------------------------------------------------------------------
\paragraph{Abstraction refinement.}

The finite height abstraction may be refined by simply increasing the height
$h$. 
%
Advantages of finite height abstraction include its relative simplicity and the
fact that the refinement does not require counterexample analysis.  
%
A~disadvantage is 
%
% TV: THE BELOW IS WRONG! One can take as h the size of the biggest TA found.
%
% that it does not give any guarantees of excluding a specific
% counterexample, and 
%
that the refinement by increasing the height is quite rough.
Moreover, the cost of computing in the abstract domain rises quickly with increasing
the height of the abstraction as exponentially more concrete configurations may be explored
before the abstraction closes the analysis of a~particular branch.
%
% , getting exponentially more of them.
%
The finite height abstraction was used---in a specifically fine-tuned
version---in the first versions of \forester{}~\cite{forester12,boxes13}, which
successfully verified a number of benchmarks, but the refinement was not
sufficiently flexible to prove some more challenging examples. 

Predicate abstraction, upon which we build in this work, offers the needed additional flexibility.  
It can be refined by adding new predicates to $\predset$ and it gives strong guarantees about excluding counterexamples.
%When the new predicates are extracted as interpolants from spurious counterexample runs of the abstract computation, it gives strong guarantees about   
%about excluding the spurious counterexamples. 
%
In ARTMC, interpolants in the form of tree automata $\interp_i$ are extracted from spurious counterexamples in the way described in Section~\ref{sec:CEXanalysis}.
%
The interpolant is then used to refine the abstraction so that the spurious run is excluded from the program's ART.
%It represents a set of configurations introduced by abstraction due to which an error is reached by a spurious forward run. The refinement is then used to exclude the spurious run. 

%Specifically, 
The guarantees shown to hold in \cite{artmc12} on the level of TAs are 
the following.  
Let $\ta$ and $\interp = (Q,q_0,\Delta)$ be two TAs and 
let $\predset(\interp) = \{\langof{\interp,q}\mid q\in Q\}$ denote the set of languages of states of $\interp$.
%
Then, if $\langof{\ta} \cap \langof{\interp} = \emptyset$, it is guaranteed that 
$\langof{\predabstraof{\predset(\interp)}{\ta}} \cap \langof{\interp} = \emptyset$.
That is, when the abstraction is refined with languages of all states of
$\interp$, it will
exclude $\langof{\interp}$---unless applied on a~TA whose language is already
intersecting~$\langof{\interp}$. 

%!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
\enlargethispage{5mm}
%!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!


We can generalize the result of \cite{artmc12} to forest automata in the
following way,
implying the progress guarantees of CEGAR described in Section~\ref{sec:CEXanalysis}.
For a~forest automaton $\fa = \tuple{\tas,\valuation}$, let $\predset(\fa) =  \ourbigcup_{i=1}^n\predset({A_i})$.
% \vspace{-1mm}
\begin{lemma}
Let $\fa$ and $\interp$ be FAs s.t.~$\interp$ is compatible with $\predabstraof{\predset}{\fa}$ and
$\semof\fa\cap\semof{\interp} = \emptyset$.
Then
$\semof{\predabstraof{\predset\cup\predset(\interp)}{\fa}} \cap \semof{\interp} = \emptyset$.
\end{lemma}
% \vspace{-0mm}
%
We note that the lemma still holds if $\predset(\interp)$ is replaced by
$\predset({A_i})$ only where $A_i$ is the $i$-th component of $\interp$ and $\langof{A_i \isectfa A_i'} = \emptyset$ for the $i$-th component $A_i'$ of $\predabstraof{\predset}{\fa}$. 


%% In our analysis, we use the interpolant $I_i$ found at the $i$th point of the forward run, as described in Section~\ref{sec:CEXanalysis}, to refine the abstraction.
%% %
%% %When a spurious counterexample is detected, then there is a
%% %configuration represented by FA 
%% $F_i=(A_1,\dots,A_n,\portoff{})$ and the interpolant
%% represented by the FA $I_i=(B_1,\dots,B_n,\portoff{})$ computed by the backward run
%% (cf.\ Sec \ref{sec:CEXanalysis}).  Note that $F_i$  and $I_i$ are box-compatible and component
%% compatible 
%% (c.f. Section\ \ref{sec:fwd_run}).
%% 
%% %Then new set of predicates $\predset'$ is
%% %defined as $\predset' = \predset \cup \bigcup_{0<i\leq n} \{(Q_i,q,\Delta_i)
%% %\mid B_i=(Q_i,q_i^0,\Delta_i)\ \wedge\ q\in Q_i\}$.
%% 
%% %\comment[ar]{Tady zduraznuji, ze $F_i$ a $I_i$ jsou box-compatible a component compatible.
%% %Pokud se bude jeste menit nazvoslovi, tak je to treba doladit.}
%% %\comment[ar]{Pokud component compatibility implikuje box compatibilitu, tak je mozne lemma
%% %zjednodusit}
%% \begin{lemma}\label{lemma:pred-refinement}
%% Let $F=(A_1,\dots,A_n,\valuation)$ and $F'=(A_1',\dots,A_n',\valuation')$ 
%% be two box and component compatible 
%% FAs such that $\semof{F} \cap \semof{F'} = \emptyset$.
%% %
%% %Then for any $\predset \supseteq L^{A_1'}\cup\cdots\cup L^{A_n'}$, 
%% Then for any $\predset \supseteq \bigcup_{i=1}^nL^{A_1'}$, 
%% it holds that
%% $\semof{\alpha[\predset](\fa)} \cap \semof{\fa'} =
%% \emptyset$.
%% \end{lemma}
%\begin{lemma}\label{lemma:pred-refinement}
%Let $F_i=(A_1,\dots,A_n,\portoff{})$ and $I_i=(B_1,\dots,B_n,\portoff{})$ be two box-compatible
%and component compatible
%FAs such that $\semof{F_i} \cap \semof{I_i} = \emptyset$.
%Then for $\predset=\bigcup_{0<i\leq n} \{(Q_i,q,\Delta_i)
%\mid B_i=(Q_i,q_i^0,\Delta_i)\ \wedge\ q\in Q_i\}$  and each $\predset'$ holds that
%$\semof{\alpha[\predset \cup \predset']F_i} \cap \semof{I_i} =
%\emptyset$
%\end{lemma}

%% \proof{$F_i$ and $I_i$ are box-compatible and component compatible.
%% Due to the component compatibility, the relation $\isbij$ computed within the intersection (c.f. Section \ref{sec:isect_alg}) 
%% is equal to identity and
%% the intersection between these FAs is simply
%% performed component-wise. The fact that 
%% $\semof{F_i} \cap \semof{I_i} = \emptyset$ implies that there exists some $0<i\leq n$ such that
%% $\mathcal{L}(A_i) \cap \mathcal{L}(B_i) = \emptyset$. And adding $\predset_i = \{(Q_i,q,\Delta_i)
%% \mid B_i=(Q_i,q_i^0,\Delta_i)\ \wedge\ q\in Q_i\}$  to any set of predicates $\predset'$ guarantee that
%% $\mathcal{L}(\alpha^{TA}[\predset_i \cup \predset'](A_i)) \cap \mathcal{L}(B_n) = \emptyset$ (see \cite{artmc12} for
%% proof). Therefore the intersection of $\alpha[\predset_i \cup \predset'](F_i)$ with $I_i$ will stay
%% empty for any $\predset'$, becaurse there is empty intersection of  their $i^{th}$ components.
%% }

%Note that  predicate language abstraction  
%can be simply employed for nested box-compatible FAs. One just have to replace the ordinary TA
%intersection inside the predicate labeling by the nested intersection defined in  Section
%\ref{sec:isect_alg}. The lemma \ref{lemma:pred-refinement} will stay valid for nested FAs.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\vspace{-3.0mm}
\section{Experiments}\label{sec:exps}
\vspace{-1.3mm}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

We have implemented our counterexample analysis and abstraction refinement as an
extension of~\forester{} and evaluated it on a~set of C programs manipulating
singly- and doubly-linked list, trees, skip-lists, and their combinations. We
were able to analyse all of them fully automatically without any need to supply
manually crafted predicates nor any other manual aid. The test cases are described in
detail in App.~\ref{sec:testcases}.

%!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
\enlargethispage{5mm}
%!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!


%\begin{table}[bt]
%=======
%We implemented our method in \forester{}. The experiments were
%performed on a~PC with Intel Core i5@2.50 GHz CPU,
%8 GiB of memory, with Debian \texttt{sid} installed.
%Our benchmarks consist of programs manipulating singly- and
%doubly-linked list, and tree structures.
%We are able to analyse all the mentioned data
%structures fully automatically without the need to supply any manually crafted predicates.
%The benchmarks are in detail described in App.~\ref{sec:testcases}.

\begin{table}[t]
  % \vspace*{-2mm}
	\centering
	\scriptsize
	\caption{Results of experiments.}
	\makebox[\linewidth]{
	\begin{tabular}{| l | l | r | r | r | r || l | l | r | r | r | r | r |}
        \hline
		Program & Status & LoC & Time [s] & Refnm& Preds & Program & Status & LoC & Time [s] & Refnm & Preds \\
        \hline
        \hline
		SLL (delete) & \safe & $33$ & $0.02$ &  $0$ & $0$ & DLL (rev) & \safe & $39$ &  $0.70$ & $0$  & $0$ \\
        \hline
		SLL (bubblesort) & \safe & $42$ & $0.02$ &  $0$ & $0$ & CDLL & \safe & $32$ &  $0.02$  & $0$  & $0$ \\
        \hline
		SLL (insersort) & \safe & $36$ & $0.04$ & $0$ & $0$ & DLL (insersort) & \safe & $42$ &  $0.56$  & $0$  & $0$ \\
        \hline
		SLLOfCSLL & \safe & $47$ & $0.02$ & $0$ & $0$ & DLLOfCDLL & \safe & $54$ &  $1.76$  & $0$  & $0$ \\
        \hline
		\rowcolor{rowgray}
		\textbf{SLL01}    & \safe & $70$ & $1.20$   &  $1$ & $1$ & \textbf{DLL01} & \safe & $73$ &  $0.65$  & $2$  & $2$ \\
        \hline
		\rowcolor{rowgray}
		\textbf{CircularSLL} & \safe & $49$ & $3.57$   &  $3$  & $3$ & \textbf{CircularDLL} & \safe  & $52$ &  $37.22$ & $18$ & $24$ \\
        \hline
		\rowcolor{rowgray}
		\textbf{OptPtrSLL}   & \safe & $59$ & $1.90$ & $3$ & $3$ & \textbf{OptPtrDLL} & \safe & $62$ &  $1.87$  & $5$ & $5$ \\
        \hline
		\rowcolor{rowgray}
		\textbf{QueueSLL}    & \safe & $71$ & $11.32$  &  $10$ & $10$ & \textbf{QueueDLL} & \safe  & $74$ &  $44.68$ & $14$ & $14$ \\
		\rowcolor{rowgray}
        \hline
		\textbf{GBSLL}       & \safe & $64$ & $0.84$   &  $3$ & $3$ & \textbf{GBDLL} & \safe & $71$ &  $1.89$  & $4$ & $4$ \\
        \hline
		\rowcolor{rowgray}
		\textbf{GBSLLSent}   & \safe  & $68$ & $0.85$   &  $3$ & $3$ & \textbf{GBDLLSent} & \safe & $75$ &  $2.19$  & $4$ & $4$ \\
        \hline
		\rowcolor{rowgray}
		\textbf{RGSLL}       & \safe & $72$ & $14.41$  &  $22$  & $38$ & \textbf{RGDLL} & \safe & $76$ &  $78.76$ & $26$ & $26$ \\
        \hline
		\rowcolor{rowgray}
		\textbf{WBSLL}       & \safe & $62$ & $0.84$   &  $5$  & $5$ & \textbf{WBDLL} & \safe & $71$ &  $1.37$  & $7$ & $7$ \\
        \hline
		\rowcolor{rowgray}
		\textbf{SortedSLL}   & \safe & $76$ & $227.12$ &  $15$ & $15$ & \textbf{SortedDLL} & \safe & $82$ &  $36.67$ & $11$ & $11$ \\
        \hline
		\rowcolor{rowgray}
		\textbf{EndSLL}      & \safe  & $45$ & $0.07$   &  $2$  & $2$ & \textbf{EndDLL} & \safe & $49$ &  $0.10$  & $3$ & $3$ \\
        \hline
		\rowcolor{rowgray}
		\textbf{TreeRB} & \unsafe & $130$ &  $0.08$  & $0$  & $0$ & \textbf{TreeWB} & \unsafe & $125$ &  $0.05$  & $0$ & $0$ \\
        \hline
		TreeCnstr & \safe & $52$ & $0.31$  & $0$  & $0$ & \cellcolor{rowgray}\textbf{TreeCnstr} & \cellcolor{rowgray}\unsafe & \cellcolor{rowgray} $52$ & \cellcolor{rowgray} $0.03$  & \cellcolor{rowgray} $0$ & \cellcolor{rowgray} $0$ \\
        \hline
		TreeOfCSLL & \safe & $109$ &  $0.57$  & $0$  & $0$ & \cellcolor{rowgray}\textbf{TreeOfCSLL}  & \cellcolor{rowgray}\unsafe & \cellcolor{rowgray} $109$ & \cellcolor{rowgray} $0.56$  & \cellcolor{rowgray} $1$ & \cellcolor{rowgray} $3$ \\
        \hline
		TreeStack & \safe & $58$ &  $0.20$  & $0$  & $0$ & \cellcolor{rowgray}\textbf{TreeStack} & \cellcolor{rowgray}\unsafe & \cellcolor{rowgray} $58$ & \cellcolor{rowgray} $0.01$  & \cellcolor{rowgray} $0$ & \cellcolor{rowgray} $0$ \\
        \hline
		TreeDsw   & \safe & $72$ & $1.87$  & $0$  & $0$ & \cellcolor{rowgray}\textbf{TreeDsw} & \cellcolor{rowgray}\unsafe & \cellcolor{rowgray} $72$ & \cellcolor{rowgray} $0.02$  & \cellcolor{rowgray} $0$ &  \cellcolor{rowgray} $0$ \\
		\hline
		TreeRootPtr & \safe & $62$ &  $1.43$  & $0$  &  $0$ & \cellcolor{rowgray}\textbf{TreeRootPtr} & \cellcolor{rowgray}\unsafe & \cellcolor{rowgray} $62$ & \cellcolor{rowgray} $0.17$  & \cellcolor{rowgray} $2$ & \cellcolor{rowgray} $6$\\
        \hline
		SkipList    & \safe & $84$ & $3.36$  & $0$  & $0$ & \cellcolor{rowgray}\textbf{SkipList} & \cellcolor{rowgray}\unsafe & $\cellcolor{rowgray} 84$ & \cellcolor{rowgray} $0.08$  & \cellcolor{rowgray} $1$  & \cellcolor{rowgray} $1$ \\
        \hline
		% SkipList-3nd    & $97$ & $0.17$  & $1$  & N & x & $1$ & & & & & & & \\
        % \hline
	\end{tabular}
	}
	\label{tab:times}
  % \vspace{-4mm}
  % \vspace{-8mm}
\end{table}

We present our experimental results in Table~\ref{tab:times}.
% The times in the table are averages of ten measurements (\forester{} chooses its path through ART nondeterministicaly, which can result in slightly variable execution times).
The table gives for each test case its name, information whether the program is safe or
contains an error, the number of lines of code, the time needed for the analysis,
the number of refinements, and, finally, the number of predicates learnt during
the abstraction refinement.
%
 The experiments were
performed on a~computer with Intel Core i5@2.50\,GHz CPU and
8\,GiB of memory running the Debian Sid OS with the Linux kernel.

Some of the test cases consider dynamic data structures without any data stored
in them, some of them data structures storing finite-domain data. Such data can
be a~part of the data structure itself, as, e.g., in red-black trees, they can
arise from some finite data abstraction, or they are also sometimes used to
mark some selected nodes of the data structure when checking the way the data
structure is changed by a given algorithm (e.g., one can check whether an
arbitrarily chosen successive pair of nodes of a~list marked red and green is
swapped when the list is reversed---see e.g.~\cite{artmc12}).

%As the results show, some of our test cases do not need the abstraction to be refined.
As the results show, some of our test cases do not need refinement.
This is because the predicate abstraction is \emph{a priori} restricted in order to preserve the forest automata ``interconnection graph''~\cite{boxes13},
which roughly corresponds to the reachability relation among variables and
cut-points in the heaps represented by a~forest automaton (an approach used
already with the finite height abstraction in former versions of \forester).

Table~\ref{tab:times} also provides a comparison with the previous version of \forester{} from~\cite{boxes13}.
In particular, the highlighted cases are not manageable by that versions of \forester{}.
These cases can be split into two classes.
In the first class there are safe programs where the initial abstraction is too
coarse and introduces spurious counterexamples, and the abstraction thus needs
to be refined.
The other class consists of programs 
containing a~real error (which could not be confirmed without the backward run).
The times needed for analysis are comparable in both versions of \forester.

To illustrate a typical learnt predicate, let us consider the test case \emph{GBSLL}.
This program manipulates a list with nodes storing two data values, green and blue, for which it holds
that a green node is always followed by a blue one. The program also contains a tester code to test this property.
\forester{} first learns two predicates describing particular violations of the property:
(1)~a~green node is at the end of the list and
(2)~there are two green nodes in a~row.
After that, \forester{} derives a~general predicate representing all lists with the needed invariant, i.e, a~green node is followed by a~blue one.
The program is then successfully verified. 
%The ability to learn shape as well as data properties (as well as properties
%relating shape with data) using a uniform mechanism is one the features of our
%method which distinguishes it from most of the related work.

Another example comes from the analysis of the program \emph{TreeCSLL}, which
creates and deletes a tree where every tree node is also the head of a circular
list.
%
It contains an undefined pointer dereference error in the deletion of the
circular lists. 
%
\forester{} first finds a spurious error (an undefined pointer dereference too)
in the code that creates the circular lists.
%
In particular, the abstraction introduces a case in which a tree node that is
also the head of a list needs not be allocated, and an attempt of accessing its
next selector causes an undefined pointer dereference error. 
%
This situation is excluded by the first refinement, after which the error within
the list deletion is correctly reported.
%
Notice that, in this case, the refinement learns a property of the shape, not a
property over the stored data values. 
%
% The ability to learn shape as well as data properties (as well as properties
% relating shape with data) using a uniform mechanism is one the features of our
% method which distinguishes it from most of the related work.
%
The ability to learn shape as well as data properties (as well as properties
relating shape with data) using a uniform mechanism is one the features of our
method which distinguishes it from most of the related work.

%!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
\enlargethispage{5mm}
%!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

%------------------------------------------------------------------------------
\vspace*{-2mm}
\section{Discussion and Future Work}
\vspace*{-1mm}
%------------------------------------------------------------------------------

Both the described forward and backward symbolic execution are quite fast.
% , and \forester{} scales well. 
We believe that the efficiency of the backward run (despite the need of computing expensive automata products) is to a large degree because it inverts unfolding (by folding). 
Backward run is therefore carried out with configurations encoded in a~compact folded form. 

\forester{} was not able to terminate on a few tree benchmarks.  
For a program manipulating a red-black tree using the rebalancing procedures, 
the initial forward run did not terminate.  
For another tree-based implementation of a set that includes a tester code checking full functional correctness, the CEGAR did not learn the right
predicates despite many refinements.
%
The non-termination of the forward run is probably related to the initial
restrictions of the predicate abstraction. Restricting the abstraction seems to be harmful especially in the case of tree structures. 
If the abstraction remembers unnecessary fine information about tree branches, the analysis will explore exponentially many variants of tree structures with different branches satisfying different properties.
%
The scenario where CEGAR seems to be unable to generalize is related to the splitting of the symbolic execution. The symbolic runs are then too specialised and CEGAR learns a large number of too specialised predicates from them (which are sometimes irrelevant to the ``real'' cause of the error). 
%

A closer examination and resolution of these issues is a part of our future
work. Allowing the abstraction more freedom is mostly an implementation issue,
although nontrivial to achieve in the current implementation of \forester{}.
Resolving the issue of splitting requires to cope with the domain of forest
automata not being closed under union. This is possible, e.g., by modifying the
definition of the FA language, which currently uses the Cartesian product of
sets of trees, so that it would connect tree components based on reachability
relation between them (instead of taking all elements of the Cartesian product).
Another possibility would be to use sets of forest automata instead of
individual ones as the symbolic representation of sets of heaps.  

%properties of refinement on the level of properties of the shape,
%not over the data. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Conclusions}
\label{ch:conclusion}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

The goal of this thesis is to enhance the existing techniques for shape analysis to
enable verification of more complex software.
To achieve the main goal, we set the following three sub-goals:
	  \begin{enumerate*}[label=(\alph*)]
		\item to design techniques for counterexample validation and refinement
			of predicate languages abstraction over forest automata,
		\item to design new automata for accepting graphs with bounded tree width,
		\item to design new efficient algorithms for (tree) automata manipulation.
	  \end{enumerate*}
The report also provided a description of the related work containing
the state of the art techniques in the scope of the mentioned goals.

Since the first goals has already been achieved, a more detailed
description (based on the paper \cite{holik:2017}) was given.
The techniques from the paper were implemented in the \forester\ tool.
The tool is based on the results achieved in \cite{forester12}.
It participated in the last three editions of SV-COMP \cite{www:svcomp} in the memory safety related categories.
Although the tool has not won any category, it successfully solved the hard
test cases such as the skip-lists of the second and the third level, or verification
of data structures with properties which have not been soundly and automatically verified by
any other tool.
There are three publications related to the \forester{} participations in the competition
co-authored by the author of the proposed thesis \cite{tacas15, tacas16, tacas17}.

The remaining work of the proposed thesis consists of the second and the third sub-goal.
The work on the second goal is currently in process and the first
results should be ready during the following year.
As it was mentioned in Section \ref{section:autoalgs} the work on the third
sub-goal started as a development of a library for easy prototyping
of algorithms for symbolic automata.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\bibliographystyle{splncs03}
\bibliography{literature}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\vfill
\eject

\appendix

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Description of the Test Cases}\label{sec:testcases}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

This section describes the test cases used in the experimental evaluation in Section~\ref{sec:exps}.
% The list data structures in all examples have a pointer called \emph{next} pointing
% to the next node in the linked list.
Note that we use a limited set of integer values since we do not support
integer abstraction.
SLL and DLL denote singly- and doubly-linked lists respectively.

The cases described in the following list satisfy some (regular-expressible)
invariant, which we check in our analysis.
Moreover, we also verify memory safety properties (absence of $\nil$/undefined pointer
dereference, invalid free, and presence of garbage) in all test cases.
%
\begin{itemize}
  \item \emph{(SLL/DLL)01}: The nodes of the list may or may not point to
    an external node, which, if present, is unique for each list item.
    We check the invariant that each node has a pointer set to $\nil$ or
		to an address of an external node.
	\item \emph{Circular(SLL/DLL)}: A circular linked list consisting of nodes with integer values.
		The head of the list has the dedicated value~$0$. The rest of nodes with their integer values
		form a~non-decreasing sequence. We verify that the successor of an arbitrary node
		can have a smaller value only when the next node is the head of the list.
	\item \emph{OptPtr(SLL/DLL)}: Each node of the list has an integer value, a pointer to the next node,
		and an optional pointer to an external node. When constructing the list, an integer value of every node
		is chosen nondeterministically. When the integer value $0$ or $1$ is chosen, the optional pointer points
		to the node itself. On the other hand, when $2$ is chosen, a new external node is allocated and
		its address is assigned to the optional pointer. We verify the relation of integer values and optional pointers for all nodes.
	\item \emph{Queue(SLL/DLL)}: We create a list with nodes containing the integers 0, 1, 2, and~3.
		The list can form sequences $0$, $01$, $012$, $0123^*$. A particular sequence is created
		during construction of the list nondeterministically. We remember which sequence was actually created
		by an auxiliary integer variable. Then we traverse the list and check that
		the sequence formed by the list corresponds to the value of the auxiliary variable.
	\item \emph{GB(SLL/DLL)}: We create a list containing green and blue nodes. The colors
		arbitrarily alternate but it holds that a green node is always followed by a~blue node.
	\item \emph{GB(SLL/DLL)Sen}: This case is similar to the previous one but instead of
		terminating the list with the $\nil$ value, the list is terminated using a~dedicated sentinel node.
	\item \emph{RG(SLL/DLL)}: The list contains an arbitrary prefix of white nodes,
		one red node followed by a green one, and an arbitrary suffix of white nodes.
		The list is reversed and it is checked whether the green node is followed by the red node.
	\item \emph{WB(SLL/DLL)}: Exactly one blue node is inserted into a list of white nodes
		of an arbitrary length. Then the list is traversed and it is checked that the number of blue
		nodes is one.
	\item \emph{Sorted(SLL/DLL)}: This test case contains a sorted list of nodes with integer values $0$ and $1$.
		A node with value $1$ is added at an arbitrary position that keeps the order of nodes in the list.
		Finally, it is checked that the list is still ordered.
	\item \emph{End(SLL/DLL)}: The last element of list has a special integer value.
	\item \emph{SkipList}: Construction and traversal of a skip list.
	\item \emph{TreeRB}: We construct a red black tree and then go through the tree
		checking (regular) invariants of this data structure. The created tree has an arbitrary height,
		and the nodes may have both, one, or no child allocated. A transposition of nodes needed to
		preserve the data structure's invariants is done continuously during construction of the tree when a new node is added.
		This operation is complex since it requires relocation of nodes in several levels of trees.
		The nodes also have to have parent pointers due to the transposition.
	\item \emph{TreeWB}: We construct a tree that has all nodes white except exactly one blue node.
		The blue node is at an arbitrary position. We traverse the tree and check
		that there is a~single blue node.
	\item \emph{TreeWBAllPaths}: A tree with all nodes being white is constructed
		nondeterministically. We transform the created tree to the form where
		each path from the root to any leaf contains exactly one blue
		node. The blue nodes are placed arbitrarily in the tree with respect to
		the described invariant of the structure. Then we start an arbitrary number of
		arbitrary walks from the root of tree to a leaf and check that each
		of these walks contains exactly one blue node.
\end{itemize}

The following test cases from our benchmark are checked only for memory safety properties.
\begin{itemize}
	\item \emph{TreeCnstr}: The construction of an arbitrary binary tree.
	\item \emph{TreeDsw}: We construct a binary tree and perform the Deutsch-Schorr-Waite traversal.
	\item \emph{TreeCSLL}: We construct a binary tree where each node points to a circular singly linked list
		of an arbitrary length. Then we traverse the whole tree and all nested lists.
	\item \emph{TreeRootPtr}: The construction and traversal of a binary tree with nodes containing root pointers.
	\item \emph{TreeStack}: The construction of a binary tree which is subsequently destroyed using stack
		implemented by a singly-linked list.
\end{itemize}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\end{document}
